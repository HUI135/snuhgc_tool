import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
import plotly.express as px
import smtplib
from email.mime.text import MIMEText
import scipy
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import requests
import plotly.figure_factory as ff
import plotly.graph_objects as go
import time
from scipy.stats import chi2_contingency, ttest_ind, levene, kruskal, shapiro, f_oneway
from lifelines import KaplanMeierFitter, CoxPHFitter
from lifelines.statistics import logrank_test
import hmac
import hashlib
import base64
import datetime
import boto3
from botocore.client import Config
# from pgmpy.estimators import HillClimbSearch, BicScore
# import networkx as nx
from causallearn.search.ConstraintBased.PC import pc
from causallearn.utils.GraphUtils import GraphUtils
import matplotlib.pyplot as plt
import networkx as nx
import openpyxl
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sendgrid import SendGridAPIClient
from sendgrid.helpers.mail import Mail
import os
import tempfile
import traceback
import re
# from causallearn.utils.GraphUtils import graph_to_adjacency_matrix

# wide format
st.set_page_config(layout="wide")

############################
######### Homepage #########
############################

PASSWORD = "snuhgchc"  # Change this to your desired password

# ì´ë¯¸ì§€ì™€ ì œëª© í‘œì‹œ í•¨ìˆ˜
def display_header():
    image_url = 'http://www.snuh.org/upload/about/hi/15e707df55274846b596e0d9095d2b0e.png'
    title_html = "<h1 style='display: inline-block; margin: 0;'>ğŸ¥ GC DataRoom</h1>"
    contact_info_html = """
    <div style='text-align: left; font-size: 20px; color: grey;'>
    ì˜¤ë¥˜ ë¬¸ì˜: í—¬ìŠ¤ì¼€ì–´ì—°êµ¬ì†Œ ë°ì´í„° ì—°êµ¬ì› ê¹€í¬ì—° (hui135@snu.ac.kr)</div>
    """

    col1, col2 = st.columns([1, 4])
    with col1:
        st.image(image_url, width=200)
    with col2:
        st.markdown(title_html, unsafe_allow_html=True)
        st.markdown(contact_info_html, unsafe_allow_html=True)
    st.divider()

# Initialize session state keys
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False  # Default: not logged in
if "loading_complete" not in st.session_state:
    st.session_state.loading_complete = False  # Loading state
if "header_displayed" not in st.session_state:
    st.session_state.header_displayed = False  # Track header display status

# ë¡œê·¸ì¸ í•¨ìˆ˜
def login():
    """Handles user login."""
    if not st.session_state.logged_in:  # Show login form only if not logged in
        st.sidebar.title("ë¡œê·¸ì¸")
        password = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
        if password == PASSWORD:
            st.sidebar.success("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            st.session_state.logged_in = True
            st.session_state.loading_complete = False  # Reset loading state
            st.session_state.header_displayed = False  # Reset header status
            return True
        elif password:
            st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    return True

# Persistent Header
def display_persistent_header():
    """Display header once and persist across interactions."""
    display_header()  # Always call header display function
    st.session_state.header_displayed = True

# Main App Logic
if login():  # If logged in, show the rest of the app
    # ë¡œë”© ìƒíƒœì—ì„œ Headerë¥¼ í‘œì‹œ
    if not st.session_state.loading_complete:
        display_persistent_header()  # Header í‘œì‹œ during loading
        with st.spinner("Loading..."):
            time.sleep(3)  # Simulate loading time
        st.session_state.loading_complete = True  # Mark loading as complete
        st.session_state.header_rendered = True  # Track header rendering during loading

    # ë¡œê·¸ì¸ í›„ ìƒíƒœì—ì„œ Headerë¥¼ ìœ ì§€
    if not st.session_state.header_rendered:  # Prevent duplicate Header rendering
        display_persistent_header()
        st.session_state.header_rendered = True  # Mark Header as rendered

    # Sidebar with functionality options after login
    st.sidebar.empty()  # Clear the sidebar
    st.sidebar.title("ê¸°ëŠ¥ ì„ íƒ")
    page = st.sidebar.selectbox(
        "âœ”ï¸ ì‚¬ìš©í•˜ì‹¤ ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
        ["-- ì„ íƒ --", "ğŸ”” ì‚¬ìš©ì„¤ëª…ì„œ", "â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ", "ğŸ“ í”¼ë´‡ ë³€í™˜", "ğŸ“ ë°ì´í„° ì½”ë”©", "ğŸ“ íŒë…ë¬¸ ì½”ë”©", "ğŸ“Š ì‹œê°í™”", "ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±", "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„", "ğŸ’» ìƒì¡´ë¶„ì„", "â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"],
        index=0  # Default to "-- ì„ íƒ --"
    )

    # Page-specific content
    if page == "-- ì„ íƒ --":
        # Checkbox for updates
        toggle = st.checkbox("**ğŸ“… 24.12.11 ğŸ“…** Update ì‚¬í•­ ìì„¸íˆë³´ê¸°")

        if toggle:
            # Toggle í™œì„±í™” ì‹œ Markdown ì¶œë ¥
            st.markdown("""
            ### ì£¼ìš” ì—…ë°ì´íŠ¸ ì‚¬í•­
            - (ì˜ˆì‹œ) **ğŸ“ í”¼ë´‡ ë³€í™˜** : ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€
            - (ì˜ˆì‹œ) **ğŸ“Š ì‹œê°í™”** : ê¸°ëŠ¥ ì¶”ê°€ - íŒŒì´ ì°¨íŠ¸ ìƒì„±

            **ì„¸ë¶€ ì˜¤ë¥˜ ìˆ˜ì •**
            - (ì˜ˆì‹œ) ì˜¤ë¥˜ ìˆ˜ì • : `There are multiple radio elements with the same auto-generated ID`
            - (ì˜ˆì‹œ) íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ : `There are multiple radio elements with the same auto-generated ID`
            - (ì˜ˆì‹œ) ì‹œê°í™” ê¸°ëŠ¥ ë¬¸ì œ : `TypeError: pie() got an unexpected keyword argument 'x'`
            """)
        else:
            # Toggle ë¹„í™œì„±í™” ì‹œ Info ì¶œë ¥
            st.info(" **í™˜ì˜í•©ë‹ˆë‹¤!** ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì›í•˜ì‹œëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", icon='ğŸ’¡')
            
    elif page == "ğŸ”” ì‚¬ìš©ì„¤ëª…ì„œ":
        st.session_state.header_displayed = False
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ””  ì‚¬ìš©ì„¤ëª…ì„œ</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ê¸°ëŠ¥ ì‚¬ìš©ì„¤ëª…ë²•ì„ ì˜ìƒì„ í†µí•´ ì‚´í´ë³´ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        st.markdown("<h4 style='color:grey;'>ì–´ë–¤ ê¸°ëŠ¥ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?</h4>", unsafe_allow_html=True)
        selected = st.selectbox("âœ”ï¸ ì‚¬ìš©ì„¤ëª…ì„œë¥¼ ë³´ì‹¤ ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=["-- ì„ íƒ --", "â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ", "ğŸ“ í”¼ë´‡ ë³€í™˜", "ğŸ“ ë°ì´í„° ì½”ë”©", "ğŸ“ íŒë…ë¬¸ ì½”ë”©", "ğŸ“Š ì‹œê°í™”", "ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±", "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„", "ğŸ’» ìƒì¡´ë¶„ì„"])
        if selected == "-- ì„ íƒ --":
            st.write()
        elif selected == "ğŸ“ íŒë…ë¬¸ ì½”ë”©":
            st.video("https://youtu.be/uE45G40TnTE")

    elif page == "ğŸ“ í”¼ë´‡ ë³€í™˜":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ í”¼ë´‡ ë³€í™˜</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;í™˜ìì˜ ì—¬ëŸ¬ ë‚´ì› ê²°ê³¼ê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ì—´ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ í™˜ìì˜ ì—¬ëŸ¬ ë‚´ì› ë°ì´í„°ê°€ í–‰ìœ¼ë¡œ ì¶•ì ë˜ì–´ìˆëŠ” ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:", type=["csv", "xlsx"])


        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.session_state.df = df
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ í”¼ë´‡ ë³€í™˜")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì •ë³´ì…ë ¥</h4>", unsafe_allow_html=True)

                # ìœ ì €ì—ê²Œ í”¼ë²—í•  ê¸°ì¤€ ì—´ ì„ íƒ (selectboxì— '-- ì„ íƒ --' ì¶”ê°€)
                id_column = st.selectbox("âœ”ï¸ í™˜ìë¥¼ êµ¬ë¶„í•  ID í˜¹ì€ RID ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["-- ì„ íƒ --"] + list(df.columns))
                if id_column == "-- ì„ íƒ --":
                    st.write(" ")
                    st.stop()

                date_column = st.selectbox("âœ”ï¸ ë°©ë¬¸ì„ êµ¬ë¶„í•  Date ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["-- ì„ íƒ --"] + list(df.columns))
                if date_column == "-- ì„ íƒ --":
                    st.write(" ")
                    st.stop()

                # ë‚ ì§œ ë³€í™˜ ë° ì •ë ¬
                try:
                    # ë‚ ì§œ ë³€í™˜ ë° ìœ íš¨ì„± ê²€ì‚¬
                    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')  # Ensure valid date conversion

                    # ë³€í™˜ëœ ë‚ ì§œ ì—´ì˜ ìœ íš¨í•œ ë‚ ì§œ ê°œìˆ˜ í™•ì¸
                    if df[date_column].isnull().all():
                        st.error("ë‚ ì§œ ì—´ì— ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ì—¬ ë³€í™˜ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()  # ë” ì´ìƒì˜ ì½”ë“œ ì‹¤í–‰ì„ ì¤‘ë‹¨
                    else:
                        # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ í–‰ ì‚­ì œ
                        df = df.dropna(subset=[date_column])  # Drop rows with invalid dates
                        df = df.sort_values(by=[id_column, date_column]).reset_index(drop=True)
                except Exception as e:
                    st.error("ë‚ ì§œ ì—´ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
                df = df.dropna(subset=[date_column])  # Drop rows with invalid dates
                df = df.sort_values(by=[id_column, date_column]).reset_index(drop=True)

                # ì—´ ë²ˆí˜¸ ë¶™ì´ê¸°
                df['row_number'] = df.groupby(id_column).cumcount() + 1
                df_pivot = df.pivot(index=id_column, columns='row_number')
                df_pivot.columns = [f"{col}_{num}" for col, num in df_pivot.columns]

                df_pivot.reset_index(inplace=True)

                # ê²°ê³¼ í‘œì‹œ
                st.divider()
                st.header("ğŸ“ í”¼ë´‡ ë³€í™˜ ê²°ê³¼", divider='rainbow')

                total_len = len(df)  # Total number of rows
                unique_len = df[id_column].nunique()  # Number of unique IDs (patients)

                # Counting the number of patients who visited once, twice, and three times
                visit_counts = df[id_column].value_counts()
                once_len = (visit_counts == 1).sum()
                twice_len = (visit_counts == 2).sum()
                third_len = (visit_counts == 3).sum()
                max_len = visit_counts.max()
                avg_len = round(visit_counts.mean(), 2)

                # Displaying the results using Streamlit markdown
                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- ì „ì²´ ë°ì´í„°ì—ëŠ” ì´ '{total_len:,}'ê°œì˜ í–‰ì´ ìˆìœ¼ë©°, ì´ ì¤‘ '{unique_len:,}'ëª…ì˜ í™˜ì ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- í•œ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{once_len:,}'ëª…, ë‘ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{twice_len:,}'ëª…, ì„¸ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{third_len:,}'ëª…ì…ë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- í™˜ìì˜ ìµœëŒ€ ë‚´ì› íšŸìˆ˜ëŠ” '{max_len}'ì´ë©°, í‰ê·  ë‚´ì› íšŸìˆ˜ëŠ” '{avg_len}'íšŒì…ë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                # Simulate a long-running process
                def long_running_process():
                    # Replace this loop with your actual computation or loading process
                    for i in range(100):
                        time.sleep(0.1)  # Example processing time for each step

                with st.spinner("Loading... 30ì´ˆ ê°€ëŸ‰ì˜ ë¡œë”©ì´ ì†Œìš”ë©ë‹ˆë‹¤."):
                    long_running_process()  # Run your process here instead of time.sleep()

                st.success("ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.write(" ")

                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.df_pivot = df_pivot
                st.markdown("<h4 style='color:grey;'>í”¼ë´‡ ë°ì´í„°</h4>", unsafe_allow_html=True)
                st.dataframe(df_pivot)

                st.write(" ")
                st.markdown("<h4 style='color:grey;'>í”¼ë´‡ ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)

                # Display the file format selection radio button for original data download
                export_format_original = st.radio("âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=["CSV", "Excel"], key="export_format_original")

                # Handle original data download
                if export_format_original:
                    if export_format_original == "CSV":
                        csv = st.session_state.df_pivot.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label="CSV ë‹¤ìš´ë¡œë“œ",
                            data=csv,
                            file_name="pivot_data.csv",
                            mime='text/csv'
                        )
                    elif export_format_original == "Excel":
                        buffer = BytesIO()
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            st.session_state.df_pivot.to_excel(writer, index=False)
                        buffer.seek(0)
                        st.download_button(
                            label="Excel ë‹¤ìš´ë¡œë“œ (ì›ë³¸ ìë£Œ)",
                            data=buffer,
                            file_name="pivot_data.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

                # Initialize session state for df_pivot and button states if they are not already present
                if "df_pivot" not in st.session_state:
                    st.session_state.df_pivot = df_pivot  # Load df_pivot data if not already loaded
                if "filter_button_pressed" not in st.session_state:
                    st.session_state.filter_button_pressed = False
                if "plot_button_pressed" not in st.session_state:
                    st.session_state.plot_button_pressed = False
                if "download_button_pressed" not in st.session_state:
                    st.session_state.download_button_pressed = False
                if "download_filtered_button_pressed" not in st.session_state:
                    st.session_state.download_filtered_button_pressed = False

                # í”¼ë²—ì— ì‚¬ìš©ëœ ì—´ ì œì™¸
                excluded_columns = [id_column, date_column]

                # ì‹œê°í™”
                if st.session_state.get("df_pivot") is not None:
                    st.divider()
                    st.header("ğŸ“ í”¼ë´‡ ë°ì´í„° ì‹œê°í™”", divider="rainbow")

                    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì—ì„œ ì œì™¸ëœ ì—´ì„ ì œê±°í•˜ì—¬ ì„ íƒ ê°€ëŠ¥í•œ ì—´ ìƒì„±
                    original_columns = [col for col in st.session_state.df.columns if col not in excluded_columns]
                    selected_column_base = st.selectbox("âœ”ï¸ ì‹œê°í™”í•  ë³€ìˆ˜ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["-- ì„ íƒ --"] + original_columns)

                    if selected_column_base != "-- ì„ íƒ --":
                        # ì›ë³¸ dfì—ì„œ ì„ íƒí•œ ì—´ì— ëŒ€í•´ row_numberë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”¼ë²—ëœ ì—´ì„ ì„ íƒ
                        visit_columns = [
                            f"{selected_column_base}_{i}" for i in range(1, max_len+1)
                        ]

                        # visit_columns í•„í„°ë§: ìœ íš¨í•œ ì—´ë§Œ í¬í•¨ (df_pivotì—ì„œ í•´ë‹¹ ì—´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸)
                        valid_visit_columns = [col for col in visit_columns if col in st.session_state.df_pivot.columns]

                        if valid_visit_columns:
                            # ê° ë°©ë¬¸ íšŒì°¨ë³„ í‰ê·  ê³„ì‚°
                            mean_values = st.session_state.df_pivot[valid_visit_columns].mean()

                            # Function to plot average LabResult changes across visits
                            def plot_average_changes(mean_values):
                                # ë°©ë¬¸ íšŒì°¨ ì¶”ì¶œ (ex: '_1', '_2', '_3' -> '1', '2', '3')
                                visit_numbers = [int(col.split('_')[-1]) for col in mean_values.index]
                                avg_values = mean_values.values

                                fig = go.Figure()
                                fig.add_trace(go.Scatter(
                                    x=visit_numbers,
                                    y=avg_values,
                                    mode='lines+markers',
                                    name=f"Average {selected_column_base}",
                                    marker=dict(symbol='circle', size=10)
                                ))

                                fig.update_xaxes(title_text="Visits", dtick=1)
                                fig.update_yaxes(title_text=f"Average {selected_column_base}")
                                fig.update_layout(
                                    height=600,
                                    width=900,
                                    title_text=f"Average {selected_column_base} Trends Across Visits",
                                    showlegend=True
                                )
                                return fig

                            # Generate and display the plot
                            fig = plot_average_changes(mean_values)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning("ì„ íƒí•œ ë³€ìˆ˜ì™€ ê´€ë ¨ëœ ì—´ì´ í”¼ë´‡ ë°ì´í„°í”„ë ˆì„ì— ì—†ìŠµë‹ˆë‹¤.")

                # Filter button in a row
                if st.session_state.get("df_pivot") is not None:
                    # Display a divider and a section header
                    st.divider()
                    st.header("ğŸ“ í”¼ë´‡ ë°ì´í„° í•„í„°ë§", divider="rainbow")
                    num = st.selectbox("âœ”ï¸ ìµœëŒ€ ë‚´ì› íšŸìˆ˜ë¥¼ níšŒë¡œ í•„í„°ë§í•©ë‹ˆë‹¤:", ["-- ì„ íƒ --"] + list(range(1, max_len)))

                    if num != "-- ì„ íƒ --":
                        # Determine columns to keep based on the selected max visit count
                        columns_to_keep = [col for col in st.session_state.df_pivot.columns
                                        if not any(col.endswith(f"_{i}") for i in range(num + 1, max_len + 1))]

                        # Filter the DataFrame based on selected columns
                        df_pivot_filtered = st.session_state.df_pivot[columns_to_keep]
                        st.session_state.df_pivot_filtered = df_pivot_filtered

                        # Display the filtered DataFrame
                        st.dataframe(df_pivot_filtered, use_container_width=True)

                        st.write(" ")
                        st.markdown("<h4 style='color:grey;'>í”¼ë´‡(í•„í„°) ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)

                        export_format_filtered = st.radio("âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=["CSV", "Excel"], key="export_format_filtered")

                        # Handle filtered data download
                        if export_format_filtered:
                            if export_format_filtered == "CSV":
                                csv = st.session_state.df_pivot_filtered.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ (í•„í„° ìë£Œ)",
                                    data=csv,
                                    file_name="pivot_data_filtered.csv",
                                    mime='text/csv'
                                )
                            elif export_format_filtered == "Excel":
                                buffer = BytesIO()
                                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                    st.session_state.df_pivot_filtered.to_excel(writer, index=False)
                                buffer.seek(0)
                                st.download_button(
                                    label="Excel ë‹¤ìš´ë¡œë“œ (í•„í„° ìë£Œ)",
                                    data=buffer,
                                    file_name="pivot_data_filtered.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )

            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥

    elif page == "ğŸ“ ë°ì´í„° ì½”ë”©":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ ë°ì´í„° ì½”ë”©</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì½”ë”©ì´ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ì›í•˜ì‹œëŠ” ì½”ë”©ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ ì½”ë”©ì„ ìˆ˜í–‰í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:", type=["csv", "xlsx"])

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ ë°ì´í„° ì½”ë”©")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    # ì—´ ì„ íƒì°½
                    st.divider()
                    st.header("ğŸ“ ë°ì´í„° ì½”ë”©", divider='rainbow')
                    st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;
                            font-size: 14px;
                            line-height: 1.4;
                            text-align: left;
                        }
                        </style>
                        <div class="custom-callout">
                            <p><strong>í•˜ë‹¨ì— ìƒì„±í•  ì½”ë”© ì—´ì˜ ì´ë¦„ì„ ì…ë ¥ í›„, ì¡°ê±´ì„ ì…ë ¥í•˜ë©´ ì½”ë”©ì´ ì´ë¤„ì§‘ë‹ˆë‹¤. ì¡°ê±´ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²½ìš°, 0ìœ¼ë¡œ ì½”ë”©ë©ë‹ˆë‹¤.</strong></p>
                            <p>ğŸ”” ì£¼ì˜!) ê°„ë‹¨í•œ ì½”ë”© ê¸°ëŠ¥ë§Œì„ ì œê³µí•˜ë¯€ë¡œ, ê·¸ì™¸ì˜ ì½”ë”©ì´ í•„ìš”í•˜ì‹  ê²½ìš° ë¬¸ì˜ë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.</p>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )

                    st.write(" ")
                    st.write(" ")

                    columns = df.columns.tolist()
                    columns.insert(0, "-- ì„ íƒ --")

                    # ì„ íƒëœ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…
                    st.session_state.df = df  # Ensure df is stored initially
                    columns = df.columns.tolist()

                    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
                    if "codes" not in st.session_state:
                        st.session_state.codes = []  # ì½”ë”© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
                    if "conditions" not in st.session_state:
                        st.session_state.conditions = {}  # ì½”ë“œë³„ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
                    if "conditions_complete" not in st.session_state:
                        st.session_state.conditions_complete = {}  # ì½”ë“œë³„ ì™„ë£Œëœ ì¡°ê±´ ì„¤ëª…

                    # UI êµ¬ì„±
                    st.markdown("<h4 style='color:grey;'>ì½”ë“œ ì¶”ê°€</h4>", unsafe_allow_html=True)

                    # ìƒˆë¡œìš´ ì—´ ì´ë¦„ ì…ë ¥
                    new_column_name = st.text_input("â–¶ï¸ ìƒì„±í•  ë°ì´í„° ì—´ì˜ ì´ë¦„ì„ ì…ë ¥ í›„ ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”:")
                    st.session_state.new_column_name = new_column_name

                    if new_column_name:
                        if new_column_name not in df.columns:
                            df[new_column_name] = np.nan  # ê¸°ë³¸ì ìœ¼ë¡œ NaNìœ¼ë¡œ ì±„ì›€
                            st.markdown(f"ì½”ë”© ê²°ê³¼ê°€ ì €ì¥ë  ì—´: **{new_column_name}**", unsafe_allow_html=True)

                    def add_condition_ui(code):
                        """ì¡°ê±´ ì„¤ì • UI ìƒì„± í•¨ìˆ˜"""
                        st.divider()
                        st.markdown(f"<h5 style='color:grey;'>âœ… ì½”ë“œ {code}ì— ëŒ€í•œ ì¡°ê±´ ì„¤ì •</h5>", unsafe_allow_html=True)

                        # ì¡°ê±´ ì¶”ê°€/ì‚­ì œ ë²„íŠ¼
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button(f"â• ì¡°ê±´ ì¶”ê°€", key=f"add_condition_{code}"):
                                st.session_state.conditions[code].append(
                                    {"column": None, "operator": None, "value": None, "logic": f"AND ì¡°ê±´ {len(st.session_state.conditions[code])}"}
                                )
                        with col2:
                            if st.button(f"âŒ ì¡°ê±´ ì‚­ì œ", key=f"remove_condition_{code}"):
                                if len(st.session_state.conditions[code]) > 1:  # ìµœì†Œ 1ê°œì˜ ì¡°ê±´ì€ ìœ ì§€
                                    st.session_state.conditions[code].pop()

                        # ì¡°ê±´ UI ìƒì„±
                        for idx, cond in enumerate(st.session_state.conditions[code], start=1):
                            st.markdown(f"âœ”ï¸ ì¡°ê±´ {idx}")
                            columns = st.columns([2, 2, 2, 2] if idx > 1 else [2, 2, 2])

                            # For condition 2 and beyond, allow the user to select AND/OR between all previous conditions
                            if idx > 1:
                                # Create the list of previous conditions for logic selection
                                condition_list = [f"ì¡°ê±´ {i}" for i in range(1, idx)]  # ['ì¡°ê±´ 1', 'ì¡°ê±´ 2', ..., 'ì¡°ê±´ N-1']
                                condition_string = ', '.join(condition_list)  # Join into a string like 'ì¡°ê±´ 1, ì¡°ê±´ 2, ...'
                                
                                # Define the logic options for the current condition
                                logic_combination = [
                                    f"AND ({condition_string})",  # AND between the previous conditions
                                    f"OR ({condition_string})"    # OR between the previous conditions
                                ]
                                
                                cond["logic"] = columns[0].selectbox(
                                    "- ë…¼ë¦¬",
                                    options=logic_combination,
                                    key=f"logic_{code}_{idx}",
                                )

                            cond["column"] = columns[-3].selectbox(
                                "- ì‚¬ìš©í•  ì—´",
                                options=["-- ì„ íƒ --"] + df.columns.tolist(),
                                key=f"col_{code}_{idx}",
                            )
                            cond["value"] = columns[-2].number_input(
                                "- ê°’",
                                step=1,
                                key=f"value_{code}_{idx}",
                            )
                            cond["operator"] = columns[-1].selectbox(
                                "- ì—°ì‚°",
                                options=["ì´ìƒ", "ì´í•˜", "ë¯¸ë§Œ", "ì´ˆê³¼", "ê°™ìŒ", "ê°™ì§€ ì•ŠìŒ"],
                                key=f"operator_{code}_{idx}",
                            )

                    # UI êµ¬ì„±
                    new_code_name = st.number_input("â–¶ï¸ ì¶”ê°€í•  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", min_value=0, max_value=100, step=1, format="%d")
                    if st.button("ì½”ë“œ ì¶”ê°€"):  # í™•ì¸ ë²„íŠ¼ ì¶”ê°€
                        if new_code_name:  # ì…ë ¥ëœ ì½”ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                            if new_code_name not in st.session_state.codes:
                                st.session_state.codes.append(new_code_name)
                                st.success(f"ì½”ë“œ {new_code_name}ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            else:
                                st.warning(f"ì½”ë“œ {new_code_name}ëŠ” ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            st.warning("ì½”ë“œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")

                    # ì…ë ¥ëœ ì½”ë“œ ëª©ë¡ í‘œì‹œ ë° ì‚­ì œ ê¸°ëŠ¥
                    if st.session_state.codes:
                        st.write(" ")
                        st.write(" ")
                        st.markdown("<h5>í˜„ì¬ ì…ë ¥ëœ ì½”ë“œ ëª©ë¡:</h5>", unsafe_allow_html=True)
                        codes_to_keep = st.session_state.codes.copy()
                        for code_name in st.session_state.codes:
                            col1, col2 = st.columns([4, 1])
                            with col1:
                                st.markdown(f"<strong><span style='color:#526E48;'>âœ… ì½”ë“œ: {code_name}</span>", unsafe_allow_html=True)
                            with col2:
                                if st.button(f"âŒ ì‚­ì œ", key=f"delete_{code_name}"):
                                    codes_to_keep.remove(code_name)  # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì½”ë“œ ì œê±°
                        st.session_state.codes = codes_to_keep

                    # ì½”ë”© ì‹œì‘ ë²„íŠ¼
                    if st.session_state.codes:  # Only show if there is at least one code
                        if st.button("ì…ë ¥ ì™„ë£Œ"):
                            # ì‚­ì œ í›„ ë‚¨ì€ ì½”ë“œë“¤ë¡œ ì¡°ê±´ ì„¤ì • ì‹œì‘
                            st.session_state.remaining_codes = st.session_state.codes.copy()
                            for code in st.session_state.remaining_codes:
                                if code not in st.session_state.conditions:
                                    st.session_state.conditions[code] = [
                                        {"column": None, "operator": None, "value": None, "logic": None},  # ì¡°ê±´ 1
                                        {"column": None, "operator": None, "value": None, "logic": "AND ì¡°ê±´ 1"},  # ì¡°ê±´ 2
                                    ]

                    # ì¡°ê±´ ì„¤ì • UI
                    if "remaining_codes" in st.session_state and st.session_state.remaining_codes:
                        for code in st.session_state.remaining_codes:
                            add_condition_ui(code)

                        # ë¯¸ì²˜ë¦¬ í•­ëª© ì²˜ë¦¬ ì˜µì…˜
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ì½”ë”©ë˜ì§€ ì•Šì€ ê·¸ ì™¸ í•­ëª© ì²˜ë¦¬ ë°©ë²•</h4>", unsafe_allow_html=True)

                        fill_option = st.radio("âœ”ï¸ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ("ì „ë¶€ 0ìœ¼ë¡œ", "ì „ë¶€ 99ë¡œ", "ì „ë¶€ ê³µë°±ìœ¼ë¡œ"))

                        # ì½”ë”© ì™„ë£Œ ë²„íŠ¼
                        if st.button("ğŸš€ ì½”ë”© ì¢…ë£Œ"):
                            # ë°ì´í„° í”„ë ˆì„ ë³µì‚¬
                            coded_df = df.copy()

                            # ê¸°ë³¸ê°’ ì„¤ì •
                            if fill_option == "ì „ë¶€ 0ìœ¼ë¡œ":
                                default_fill = 0
                            elif fill_option == "ì „ë¶€ 99ë¡œ":
                                default_fill = 99
                            elif fill_option == "ì „ë¶€ ê³µë°±ìœ¼ë¡œ":
                                default_fill = None

                            coded_df[new_column_name] = default_fill  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€

                            # ì‚¬ìš©ëœ ì—´ ì¶”ì 
                            used_columns = set()

                            for code in st.session_state.remaining_codes:
                                conditions = st.session_state.conditions[code]
                                condition_query = []

                                # ì¡°ê±´ ë³€í™˜
                                for idx, cond in enumerate(conditions):
                                    if cond["column"] and cond["column"] != "-- ì„ íƒ --":
                                        column = cond["column"]
                                        operator = cond["operator"]
                                        value = cond["value"]

                                        if operator == "ì´ìƒ":
                                            query = f"({column} >= {value})"
                                        elif operator == "ì´í•˜":
                                            query = f"({column} <= {value})"
                                        elif operator == "ë¯¸ë§Œ":
                                            query = f"({column} < {value})"
                                        elif operator == "ì´ˆê³¼":
                                            query = f"({column} > {value})"
                                        elif operator == "ê°™ìŒ":
                                            query = f"({column} == {value})"
                                        elif operator == "ê°™ì§€ ì•ŠìŒ":
                                            query = f"({column} != {value})"
                                        else:
                                            continue

                                        if "logic" in cond and cond["logic"] and "NOT" in cond["logic"]:
                                            query = f"not {query}"  # NOT ì¡°ê±´ ì ìš©

                                        condition_query.append(query)
                                        used_columns.add(column)  # ì‚¬ìš©ëœ ì—´ ì¶”ê°€

                                # ëª¨ë“  ì¡°ê±´ì„ ì¡°í•©í•˜ì—¬ ì ìš© (AND / OR ì ìš©)
                                if condition_query:
                                    # Use 'AND' or 'OR' based on logic
                                    final_query = None
                                    for idx, query in enumerate(condition_query):
                                        if idx == 0:
                                            final_query = query
                                        else:
                                            logic = conditions[idx - 1]["logic"]  # Get the logic for the previous condition
                                            if logic == f"AND ì¡°ê±´ {idx}":
                                                final_query = f"({final_query}) & ({query})"  # Use & for AND
                                            elif logic == f"OR ì¡°ê±´ {idx}":
                                                final_query = f"({final_query}) | ({query})"  # Use | for OR

                                    # Apply the final query to code the column
                                    coded_df.loc[coded_df.query(final_query).index, new_column_name] = code

                            # ê²°ê³¼ ì €ì¥
                            st.session_state.coded_df = coded_df
                            st.session_state.preview_df = coded_df[list(used_columns) + [new_column_name]]

                            st.success("ì½”ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì‚´í´ë³´ì„¸ìš”.")

                        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ë‹¤ìš´ë¡œë“œ
                        if "preview_df" in st.session_state:
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ì½”ë”© ê²°ê³¼</h4>", unsafe_allow_html=True)
                            st.dataframe(st.session_state.preview_df, use_container_width=True)

                            # íŒŒì¼ í˜•ì‹ ì„ íƒ
                            if "export_format" not in st.session_state:
                                st.session_state.export_format = "CSV"

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ì½”ë”© ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                            st.write("ğŸ”” ì—…ë¡œë“œí•˜ì‹  ë°ì´í„°ì— ìƒˆë¡œ ì¶”ê°€ëœ ì½”ë”© ì—´ì´ í¬í•¨ëœ í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                            
                            export_format = st.radio(
                                "âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                options=["CSV", "Excel"],
                                key="export_format",
                                index=["CSV", "Excel"].index(st.session_state.export_format)
                            )

                            # CSV ë‹¤ìš´ë¡œë“œ
                            if export_format == "CSV":
                                csv = st.session_state.coded_df.to_csv(index=False).encode("utf-8")
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name=f"{new_column_name}_table.csv",
                                    mime="text/csv",
                                    key="csv_download_button"
                                )

                            # Excel ë‹¤ìš´ë¡œë“œ
                            elif export_format == "Excel":
                                buffer = BytesIO()
                                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                                    st.session_state.coded_df.to_excel(writer, index=False)
                                buffer.seek(0)  # Reset buffer position
                                st.download_button(
                                    label="Excel ë‹¤ìš´ë¡œë“œ",
                                    data=buffer,
                                    file_name=f"{new_column_name}_table.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key="excel_download_button"
                                )


            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")

    elif page == "ğŸ“ íŒë…ë¬¸ ì½”ë”©":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ íŒë…ë¬¸ ì½”ë”©</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;íŒë…ë¬¸ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ì›í•˜ì‹œëŠ” ì½”ë”©ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ì„ í¬í•¨í•œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:", type=["csv", "xlsx"])

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ íŒë…ë¬¸ ì½”ë”©")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    # Ensure session state initialization
                    if "phrases_by_code" not in st.session_state:
                        st.session_state.phrases_by_code = {}
                    if "df" not in st.session_state:
                        st.session_state.df = None

                    # íŒë…ë¬¸ ì—´ ì„ íƒì°½
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ ì„ íƒ</h4>", unsafe_allow_html=True)
                    columns = df.columns.tolist()
                    columns.insert(0, "-- ì„ íƒ --")

                    selected_column = st.selectbox("âœ”ï¸ ì½”ë”©í•  íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=columns)

                    # 'coding' ì—´ ì¶”ê°€ ë° ì„ íƒëœ ì—´ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    if selected_column != "-- ì„ íƒ --":
                        if "coding" not in df.columns:
                            df["coding"] = None  # ê¸°ë³¸ì ìœ¼ë¡œ NaNìœ¼ë¡œ ì±„ì›€
                        st.session_state.df = df  # Ensure df is stored in session state
                        st.session_state.selected_column = selected_column  # Store selected column in session state
                    else:
                        st.stop()  # Stop further rendering if no column is selected

                    # íŒë…ë¬¸ ì½”ë”© UI
                    st.divider()
                    st.header("ğŸ“ íŒë…ë¬¸ ì½”ë”©", divider="rainbow")
                    st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;
                            font-size: 14px;
                            line-height: 1.4;
                            text-align: left;
                        }
                        </style>
                        <div class="custom-callout">
                            <p><strong>í•˜ë‹¨ì— ì½”ë“œì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ ì‹œ, í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ íŒë…ë¬¸ í–‰ì€ í•¨ê»˜ ì…ë ¥ëœ ì½”ë“œë¡œ ì½”ë”©ì´ ì´ë¤„ì§‘ë‹ˆë‹¤.</p>
                            </div>
                        </div>
                        """,
                        unsafe_allow_html=True,
                    )

                    st.write(" ")
                    st.write(" ")

                    # ì…ë ¥í•œ ì½”ë“œë¥¼ ì²˜ë¦¬
                    current_code = st.number_input("â–¶ï¸ ì¶”ê°€í•  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", min_value=0, max_value=100, step=1, format="%d")

                    if current_code:
                        try:
                            current_code = int(current_code)
                        except ValueError:
                            # st.error("ì˜¬ë°”ë¥¸ ìˆ«ì í˜•ì‹ì˜ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            st.stop()

                        # Initialize phrases_by_code for the given code
                        if current_code not in st.session_state.phrases_by_code:
                            st.session_state.phrases_by_code[current_code] = []

                        # í…ìŠ¤íŠ¸ì™€ ì¡°ê±´ ì…ë ¥
                        col1, col2 = st.columns(2)
                        with col1:
                            input_text = st.text_input("â–¶ï¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", key="text_input")
                        with col2:
                            preceding_text = st.text_input("â–¶ï¸ ì œì™¸í•  ì„ í–‰ í…ìŠ¤íŠ¸ ì¡°ê±´(ì„ íƒ):", key="preceding_text")

                        if st.button("â• ì¶”ê°€"):
                            if input_text.strip():
                                st.session_state.phrases_by_code[current_code].append(
                                    {"text": input_text.strip(), "preceding_text": preceding_text.strip() if preceding_text else None}
                                )
                                st.success("í…ìŠ¤íŠ¸ ë° ì¡°ê±´ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

                    # 4. í˜„ì¬ ì…ë ¥ëœ í…ìŠ¤íŠ¸ì™€ ì¡°ê±´ í‘œì‹œ ë° ì‚­ì œ ë²„íŠ¼ ì¶”ê°€
                    if st.session_state.phrases_by_code:
                        st.write("")
                        st.markdown("<h4>í˜„ì¬ ì…ë ¥ëœ ì½”ë“œ ë° í…ìŠ¤íŠ¸</h4>", unsafe_allow_html=True)
                        for code, phrases in st.session_state.phrases_by_code.items():
                            st.write(f"**âœ… ì½”ë“œ {code}**")
                            for idx, entry in enumerate(phrases):
                                text = entry["text"]
                                preceding_text = entry.get("preceding_text")  # Get preceding text or None

                                col1, col2 = st.columns([4, 1])
                                with col1:
                                    # Write text with or without preceding condition
                                    if preceding_text:  # Include preceding condition only if it exists
                                        st.write(f"- `{text}` ( ì œì™¸ ì„ í–‰ ì¡°ê±´: `{preceding_text}` )")
                                    else:
                                        st.write(f"- `{text}`")
                                with col2:
                                    # Unique key for delete button
                                    if st.button("ì‚­ì œ", key=f"delete_{code}_{idx}"):
                                        st.session_state.phrases_by_code[code].pop(idx)
                                        # Trigger UI update by modifying session state
                                        st.session_state["rerun_trigger"] = not st.session_state.get("rerun_trigger", False)

                    # 4. ì½”ë”© ìš°ì„ ìˆœìœ„ ì„¤ì • UI
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ì½”ë”© ìš°ì„ ìˆœìœ„ ì„¤ì •</h4>", unsafe_allow_html=True)

                    priority_option = st.radio(
                        "âœ”ï¸ ìš°ì„ ìˆœìœ„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                        ["ì˜¤ë¦„ì°¨ìˆœ (ë‚®ì€ ì½”ë“œë¶€í„°)", "ë‚´ë¦¼ì°¨ìˆœ (ë†’ì€ ì½”ë“œë¶€í„°)", "ì‚¬ìš©ì ì •ì˜"],
                        index=0,
                        key="priority_option"
                    )

                    custom_priority = None
                    if priority_option == "ì‚¬ìš©ì ì •ì˜":
                        custom_priority_input = st.text_area(
                            "ğŸ“‹ ì‚¬ìš©ì ì •ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 2,1,3):",
                            key="custom_priority_input"
                        )
                        try:
                            custom_priority = list(map(int, custom_priority_input.split(",")))
                        except ValueError:
                            st.warning("ì˜¬ë°”ë¥¸ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")


                    # 5. ì½”ë”©ë˜ì§€ ì•Šì€ í•­ëª© ì²˜ë¦¬ ë°©ì‹ ì„ íƒ
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ì½”ë”©ë˜ì§€ ì•Šì€ í•­ëª© ì²˜ë¦¬ ë°©ë²•</h4>", unsafe_allow_html=True)
                    fill_option = st.radio(
                        "âœ”ï¸ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ì „ë¶€ 0ìœ¼ë¡œ", "ì „ë¶€ 99ë¡œ", "ì „ë¶€ ê³µë°±ìœ¼ë¡œ"], key="fill_option"
                    )

                    # 6. ì½”ë”© ì‘ì—… ì¢…ë£Œ ë° ì²˜ë¦¬
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ì½”ë”© ê²°ê³¼</h4>", unsafe_allow_html=True)

                    # ì½”ë”© ì¢…ë£Œ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ
                    if st.button("ğŸš€ ì½”ë”© ì¢…ë£Œ"):
                        # Ensure DataFrame exists in session state
                        if "df" not in st.session_state or st.session_state.df is None:
                            st.error("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                            st.stop()

                        df = st.session_state.df.copy()

                        # Ensure selected_column is set
                        if "selected_column" not in locals() or selected_column not in df.columns:
                            st.error("ì½”ë”©í•  ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            st.stop()

                        # Initialize a new column to store the coding reason
                        df["coding_reason"] = ""

                        # Normalize column data
                        df[selected_column] = df[selected_column].fillna("").astype(str).str.lower()

                        # Sort phrases based on priority option
                        if priority_option == "ì˜¤ë¦„ì°¨ìˆœ (ë‚®ì€ ì½”ë“œë¶€í„°)":
                            sorted_phrases = sorted(st.session_state.phrases_by_code.items(), key=lambda x: x[0], reverse=True)
                        elif priority_option == "ë‚´ë¦¼ì°¨ìˆœ (ë†’ì€ ì½”ë“œë¶€í„°)":
                            sorted_phrases = sorted(st.session_state.phrases_by_code.items(), key=lambda x: x[0], reverse=False)
                        elif priority_option == "ì‚¬ìš©ì ì •ì˜" and custom_priority:
                            # Map custom priority
                            priority_map = {code: idx for idx, code in enumerate(custom_priority)}
                            sorted_phrases = sorted(
                                st.session_state.phrases_by_code.items(),
                                key=lambda x: priority_map.get(x[0], float("inf")), reverse=True
                            )
                        else:
                            sorted_phrases = sorted(st.session_state.phrases_by_code.items(), key=lambda x: x[0], reverse=True)

                        # Process codes in sorted order
                        for code, phrases in sorted_phrases:
                            for entry in phrases:
                                # Retrieve 'text' and 'preceding_text'
                                text = entry.get("text", "").strip().lower()
                                preceding_text = entry.get("preceding_text", "").strip().lower() if entry.get("preceding_text") else ""

                                if not text:  # Skip empty text entries
                                    continue

                                # Match conditions
                                matches_condition = df[selected_column].str.contains(text, na=False)

                                # Apply preceding exclusion condition if exists
                                if preceding_text:
                                    exclusion_condition = df[selected_column].str.contains(fr"{preceding_text}\s*{text}", na=False)
                                    matches_condition = matches_condition & ~exclusion_condition

                                # Apply the code only if matches_condition is True
                                df.loc[matches_condition, "coding"] = code

                                # Store the reason (phrase) for the coding in the new column
                                # Remove any backslashes before adding the reason
                                clean_text = text.replace("\\", "")  # Remove backslashes
                                df.loc[matches_condition, "coding_reason"] = df.loc[matches_condition, "coding_reason"] + f" ({clean_text})"

                        # Handle uncoded rows based on user selection
                        if fill_option == "ì „ë¶€ 0ìœ¼ë¡œ":
                            df["coding"].fillna(0, inplace=True)
                        elif fill_option == "ì „ë¶€ 99ë¡œ":
                            df["coding"].fillna(99, inplace=True)
                        elif fill_option == "ì „ë¶€ ê³µë°±":
                            df["coding"].fillna(np.nan, inplace=True)

                        # Store coded DataFrame in session state
                        st.session_state.coded_df = df

                        # Set coding completion flag
                        st.session_state.coding_complete = True  # Set this flag to indicate that coding is done

                        # Display processing status
                        with st.spinner("ì½”ë”© ì²˜ë¦¬ ì¤‘..."):
                            time.sleep(2)

                        # Display success message and resulting DataFrame
                        st.success("ì½”ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", icon="âœ…")
                        st.dataframe(st.session_state.coded_df, use_container_width=True)

                    # Initialize export_format in session_state if it doesn't exist yet
                    if "export_format" not in st.session_state:
                        st.session_state.export_format = "CSV"  # Default value

                    # 7. ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                    if "coded_df" in st.session_state and st.session_state.get("coding_complete", False):
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ì½”ë”© ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                        
                        export_format = st.radio(
                            "âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            options=["CSV", "Excel"],
                            key="export_format",
                            index=["CSV", "Excel"].index(st.session_state.export_format)
                        )

                        # CSV ë‹¤ìš´ë¡œë“œ
                        if export_format == "CSV":
                            csv = st.session_state.coded_df.to_csv(index=False).encode("utf-8")
                            st.download_button(
                                label="CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv,
                                file_name=f"coded_data.csv",
                                mime="text/csv",
                                key="csv_download_button"
                            )

                        # Excel ë‹¤ìš´ë¡œë“œ
                        elif export_format == "Excel":
                            buffer = BytesIO()
                            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                                st.session_state.coded_df.to_excel(writer, index=False)
                            buffer.seek(0)  # Reset buffer position
                            st.download_button(
                                label="Excel ë‹¤ìš´ë¡œë“œ",
                                data=buffer,
                                file_name=f"coded_data.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="excel_download_button"
                            )

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ“Š ì‹œê°í™”":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“Š ì‹œê°í™”</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ì‹œê°í™”í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write("")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ ì‹œê°í™”ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“Š ì‹œê°í™”")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Select visualization format
                    st.header("ğŸ“Š Univariable ë°ì´í„° ì‹œê°í™”", divider='rainbow')
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜: ì„±ë³„(ë‚¨/ì—¬), ì§ˆí™˜ë ¥(ìœ /ë¬´)ì™€ ê°™ì´ ê³ ìœ í•œ ê°’ì´ë‚˜ ë²”ì£¼ ìˆ˜ê°€ ì œí•œëœ ë³€ìˆ˜</p>
                        <p>- ì—°ì†í˜• ë³€ìˆ˜: í‚¤, ëª¸ë¬´ê²Œ, í˜ˆì•¡ê³¼ ê°™ì´ ìˆ«ìë¡œ ì¸¡ì •ë˜ë©°, ì¼ì • ë²”ìœ„ ì•ˆì—ì„œ ì–´ë– í•œ ê°’ë„ ì·¨í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )

                    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
                    def get_categorical_columns(df):
                        categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                        low_cardinality_numerical = [
                            col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5
                        ]
                        return categorical_columns + low_cardinality_numerical

                    # ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ (ê³ ìœ  ê°’ì´ 4 ì´ìƒì¸ ì—°ì†í˜• ë³€ìˆ˜ë§Œ í•„í„°ë§)
                    def get_continuous_columns(df):
                        available_columns = [
                            col for col in df.select_dtypes(include=['float64', 'int64']).columns 
                            if df[col].nunique() >= 5
                        ]
                        return available_columns

                    # ì‹œê°í™”
                    st.text("")
                    st.text("")
                    plot_type = st.radio("âœ”ï¸ ê·¸ë˜í”„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                        ('ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart', 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot'))
                    st.text("")

                    st.session_state.df = df

                    # ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ
                    if plot_type in ['ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart']:
                        categorical_columns = get_categorical_columns(df)
                        # `-- ì„ íƒ --`ì„ ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì¶”ê°€
                        categorical_columns.insert(0, "-- ì„ íƒ --")  
                        selected_categorical_column = st.selectbox("âœ”ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ", categorical_columns, index=0, key="categorical_column_selection")  # Set index=0 to show "-- ì„ íƒ --"

                    # ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ
                    if plot_type in ['ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot']:
                        continuous_columns = get_continuous_columns(df)
                        # `-- ì„ íƒ --`ì„ ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì¶”ê°€
                        continuous_columns.insert(0, "-- ì„ íƒ --")  
                        selected_continuous_column = st.selectbox("âœ”ï¸ ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ", continuous_columns, index=0, key="continuous_column_selection")  # Set index=0 to show "-- ì„ íƒ --"

                    # Creating visualizations based on user's selection
                    if plot_type:  # ì‚¬ìš©ìê°€ ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•˜ë©´ ì‹¤í–‰
                        if plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                            if selected_categorical_column != "-- ì„ íƒ --":
                                # Data preparation
                                count_data = df[selected_categorical_column].value_counts().reset_index()
                                count_data.columns = [selected_categorical_column, 'Count']  # Specify appropriate column names
                                # Create Barplot
                                fig = px.bar(count_data,
                                            x=selected_categorical_column,
                                            y='Count',
                                            labels={selected_categorical_column: selected_categorical_column, 'Count': 'Count'},
                                            color_discrete_sequence=["#FFBDBD", "#BBDDEE"])  # Specify color
                                st.plotly_chart(fig)

                        elif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart':
                            if selected_categorical_column != "-- ì„ íƒ --":
                                # Data preparation
                                count_data = df[selected_categorical_column].value_counts().reset_index()
                                count_data.columns = [selected_categorical_column, 'Count']  # Specify appropriate column names
                                # Create Pie chart
                                fig = px.pie(
                                    count_data,
                                    names=selected_categorical_column,  # Categories for the pie slices
                                    values='Count',         # Values (count) for the pie slices
                                    labels={selected_categorical_column: selected_categorical_column, 'Count': 'Count'},  # Optional: Custom labels
                                    color_discrete_sequence=["#FFBDBD", "#BBDDEE"]  # Specify color
                                )
                                # Display the plot
                                st.plotly_chart(fig)

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram':
                            if selected_continuous_column != "-- ì„ íƒ --":
                                if df[selected_continuous_column].dtype in ['int64', 'float64']:
                                    fig = ff.create_distplot([df[selected_continuous_column].dropna()], [selected_continuous_column], bin_size=0.1)
                                    fig.update_layout(showlegend=False)
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Histogramì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot':
                            if selected_continuous_column != "-- ì„ íƒ --":
                                if df[selected_continuous_column].dtype in ['int64', 'float64']:
                                    fig = px.box(df, x=selected_continuous_column, color_discrete_sequence=["#BBDDEE"])  # Specify color
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Boxplotì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        else:
                            st.write("ë¨¼ì € ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                            
                    st.divider()

                    # Select visualization format
                    st.header("ğŸ“Š Multivariable ë°ì´í„° ì‹œê°í™”", divider='rainbow')
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜: ì„±ë³„(ë‚¨/ì—¬), ì§ˆí™˜ë ¥(ìœ /ë¬´)ì™€ ê°™ì´ ê³ ìœ í•œ ê°’ì´ë‚˜ ë²”ì£¼ ìˆ˜ê°€ ì œí•œëœ ë³€ìˆ˜</p>
                        <p>- ì—°ì†í˜• ë³€ìˆ˜: í‚¤, ëª¸ë¬´ê²Œ, í˜ˆì•¡ê³¼ ê°™ì´ ìˆ«ìë¡œ ì¸¡ì •ë˜ë©°, ì¼ì • ë²”ìœ„ ì•ˆì—ì„œ ì–´ë– í•œ ê°’ë„ ì·¨í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜</p>
                        <p>â­ ê·¸ë£¹ì—´ ë³€ìˆ˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )

                    st.text("")
                    st.text("")
                    # ì‹œê°í™” ì„ íƒ
                    plot_type = st.radio("âœ”ï¸ ê·¸ë˜í”„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                        ('ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart', 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot', 'ì—°ì†í˜• ë³€ìˆ˜: Correlation Heatmap'),
                                        key="plot_type_selection")  # Provide a unique key
                    st.text("")

                    # ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ
                    if plot_type in ['ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart']:
                        categorical_columns = get_categorical_columns(df)
                        # `-- ì„ íƒ --`ì„ ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì¶”ê°€
                        categorical_columns.insert(0, "-- ì„ íƒ --")  
                        selected_column_1 = st.selectbox("âœ”ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ", categorical_columns, index=0, key="categorical_variable")
                        selected_column_2 = st.selectbox("âœ”ï¸ ê·¸ë£¹ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", categorical_columns, index=0, key="group_variable")
                        # ê·¸ë£¹ë³€ìˆ˜ëŠ” ë°˜ë“œì‹œ ë²”ì£¼í˜•ì´ì–´ì•¼ í•¨
                        if selected_column_2 != "-- ì„ íƒ --":
                            if df[selected_column_2].dtype != 'category':
                                # ìë™ìœ¼ë¡œ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜
                                df[selected_column_2] = df[selected_column_2].astype('category')

                    # ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ
                    if plot_type in ['ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot']:
                        continuous_columns = get_continuous_columns(df)
                        # `-- ì„ íƒ --`ì„ ì²« ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ì¶”ê°€
                        continuous_columns.insert(0, "-- ì„ íƒ --")  
                        categorical_columns = get_categorical_columns(df)
                        categorical_columns.insert(0, "-- ì„ íƒ --")  
                        selected_column_1 = st.selectbox("âœ”ï¸ ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ", continuous_columns, index=0, key="continuous_variable")
                        selected_column_2 = st.selectbox("âœ”ï¸ ê·¸ë£¹ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", categorical_columns, index=0, key="group_variable")

                        # ê·¸ë£¹ë³€ìˆ˜ëŠ” ë°˜ë“œì‹œ ë²”ì£¼í˜•ì´ì–´ì•¼ í•¨
                        if selected_column_2 != "-- ì„ íƒ --":
                            if df[selected_column_2].dtype != 'category':
                                # ìë™ìœ¼ë¡œ ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜
                                df[selected_column_2] = df[selected_column_2].astype('category')

                    # Creating visualizations based on user's selection
                    if plot_type:  # ì‚¬ìš©ìê°€ ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•˜ë©´ ì‹¤í–‰
                        if plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Data preparation: Group by selected_column_2 and count selected_column_1
                                count_data = df.groupby([selected_column_2, selected_column_1]).size().reset_index(name='Count')
                                count_data = count_data.sort_values(by=selected_column_2)

                                # Create Barplot
                                fig = px.bar(
                                    count_data,
                                    x=selected_column_1,
                                    y='Count',
                                    color=selected_column_2,
                                    barmode='group',  # Change to 'group' for side-by-side bars
                                    labels={selected_column_1: selected_column_1, 'Count': 'Count'},
                                    color_discrete_sequence=px.colors.qualitative.Set2  # Use a qualitative color palette
                                )

                                # Display the plot
                                st.plotly_chart(fig)

                        elif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart':
                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Data preparation: Group by selected_column_2 and count selected_column_1
                                count_data = df.groupby([selected_column_2, selected_column_1]).size().reset_index(name='Count')
                                count_data = count_data.sort_values(by=selected_column_2)

                                # Get unique values in selected_column_2 for separate pie charts
                                unique_groups = count_data[selected_column_2].unique()

                                # Create a pie chart for each unique group in selected_column_2
                                for group in unique_groups:
                                    group_data = count_data[count_data[selected_column_2] == group]

                                    # Create Pie Chart
                                    fig = px.pie(
                                        group_data,
                                        names=selected_column_1,  # Categories for the pie slices
                                        values='Count',            # Values for the pie chart
                                        title=f"{selected_column_2}ì—´ì˜ {group}ì— ëŒ€í•œ íŒŒì´ ì°¨íŠ¸",  # Title indicating the group
                                        color_discrete_sequence=px.colors.qualitative.Set2  # Use a qualitative color palette
                                    )

                                    # Display the plot
                                    st.plotly_chart(fig)

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram':
                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Check if selected_column_1 is continuous
                                if df[selected_column_1].dtype in ['int64', 'float64']:
                                    # Check if selected_column_2 is categorical
                                    if df[selected_column_2].dtype != 'category':
                                        df[selected_column_2] = df[selected_column_2].astype('category')

                                    # Prepare data for distplot
                                    # Get sorted unique categories from selected_column_2
                                    sorted_categories = sorted(df[selected_column_2].cat.categories)

                                    data_to_plot = [
                                        df[df[selected_column_2] == category][selected_column_1].dropna().tolist()
                                        for category in sorted_categories
                                    ]

                                    # Create Distplot
                                    fig = ff.create_distplot(data_to_plot,
                                                            group_labels=sorted_categories,  # Use sorted categories for labels
                                                            bin_size=0.1)

                                    # Display the plot
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Histogramì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot':
                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Check if selected_column_1 is continuous
                                if df[selected_column_1].dtype in ['int64', 'float64']:
                                    # Check if selected_column_2 is categorical
                                    if df[selected_column_2].dtype != 'category':
                                        df[selected_column_2] = df[selected_column_2].astype('category')

                                    sorted_categories = df[selected_column_2].cat.categories.tolist() if df[selected_column_2].dtype == 'category' else df[selected_column_2].unique().tolist()
                                    sorted_categories.sort()

                                    # Create Box Plot
                                    fig = px.box(
                                        df,
                                        x=selected_column_2,
                                        y=selected_column_1,
                                        color=selected_column_2,  # Color by selected_column_2
                                        color_discrete_sequence=px.colors.qualitative.Set2,  # Use a qualitative color palette
                                        title='Box Plot of {} by {}'.format(selected_column_1, selected_column_2),
                                        labels={selected_column_2: selected_column_2, selected_column_1: selected_column_1}  # Custom labels
                                    )

                                    # Sort the x-axis categories based on sorted_categories
                                    fig.update_layout(xaxis=dict(categoryorder='array', categoryarray=sorted_categories))

                                    # Display the plot
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Boxplotì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”:")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜: Correlation Heatmap':
                            # For correlation heatmap, we don't need a group variable
                            # Filter numerical columns with > 5 unique values
                            numeric_columns = [col for col in df.select_dtypes(include=['int64', 'float64']).columns if df[col].nunique() >= 5]
                            
                            if len(numeric_columns) > 1:
                                st.warning("íˆíŠ¸ë§µì€ ì—°ì†í˜• ë³€ìˆ˜ë§Œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. \n ê³ ìœ  ê°’ì´ 10ê°œ ì´í•˜ì¸ ë³€ìˆ˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ê°„ì£¼í•˜ì—¬ ìë™ ì œì™¸ë©ë‹ˆë‹¤.", icon="ğŸš¨")
                                corr = df[numeric_columns].corr()

                                # Plotly interactive correlation matrix
                                fig = px.imshow(round(corr, 3), text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
                                st.plotly_chart(fig)
                            else:
                                st.warning("íˆíŠ¸ë§µì„ êµ¬í˜„í•  ì—°ì†í˜• ë³€ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        else:
                            st.write("ë¨¼ì € ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ íŠ¹ì„±í‘œ ìƒì„±ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:")
        st.warning("ì—…ë¡œë“œ ì‹œ, ë‚ ì§œí˜• íƒ€ì…ì˜ ì—´ì€ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ì œì™¸ë©ë‹ˆë‹¤.", icon="ğŸš¨")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Select visualization format
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° Nìˆ˜ íŒŒì•…</h4>", unsafe_allow_html=True)
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” unique ê°’ì´ 3ê°œ ì´í•˜ì¸ ê²½ìš°ë¡œë§Œ íƒìƒ‰ë©ë‹ˆë‹¤.</p>
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„  n(percentage) í˜•íƒœê°€, ì—°ì†í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„  mean[IQR] í˜•íƒœê°€ ë„ì¶œë©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )

                    def is_date_column(column):
                        """Function to determine if a column should be considered as a date column."""
                        return pd.api.types.is_datetime64_any_dtype(column) or pd.api.types.is_object_dtype(column) or column.name.lower().endswith("date")

                    def bs_count(sample):
                        # Categorical columns with 2 or 3 unique values, excluding potential date columns
                        cat_col = [col for col in sample.columns if sample[col].nunique() <= 3 and not is_date_column(sample[col])]

                        # Two unique values
                        cat_table2 = pd.DataFrame()
                        cat_col2 = [col for col in cat_col if sample[col].nunique() == 2]

                        for col in cat_col2:
                            counts = sample[col].value_counts().sort_index()
                            percentages = (sample[col].value_counts(normalize=True) * 100).round(1).sort_index()

                            for level in counts.index:
                                var_name = f"{col}_{level}"
                                count_value = counts[level]
                                percent_value = percentages[level]
                                merged_value = f"{count_value:,.0f} ({percent_value:.1f})"
                                cat_table2 = pd.concat([cat_table2, pd.DataFrame({'Variable': [var_name], 'Count': [merged_value]})], ignore_index=True)

                        # Three unique values
                        cat_table3 = pd.DataFrame()
                        cat_col3 = [col for col in cat_col if sample[col].nunique() == 3 and not is_date_column(sample[col])]

                        for col in cat_col3:
                            counts = sample[col].value_counts().sort_index()
                            percentages = (sample[col].value_counts(normalize=True) * 100).round(1).sort_index()

                            for level in counts.index:
                                var_name = f"{col}_{level}"
                                count_value = counts[level]
                                percent_value = percentages[level]
                                merged_value = f"{count_value:,.0f} ({percent_value:.1f})"
                                cat_table3 = pd.concat([cat_table3, pd.DataFrame({'Variable': [var_name], 'Count': [merged_value]})], ignore_index=True)

                        # Numerical values
                        num_table = pd.DataFrame(columns=['Variable', 'Count'])
                        num_col = [col for col in sample.columns if col not in cat_col and not is_date_column(sample[col])]

                        for col in num_col:
                            means = sample[col].mean()
                            iqr = sample[col].quantile(0.75) - sample[col].quantile(0.25)
                            num_table = pd.concat([num_table, pd.DataFrame({'Variable': [col], 'Count': ['{:,.1f} [{:,.1f}]'.format(means, iqr)]})], ignore_index=True)

                        # Combine all tables
                        final_tab = pd.concat([cat_table2, cat_table3, num_table], axis=0, ignore_index=True)

                        # Extract original column names without levels for merging
                        # for col in cat_col2 + cat_col3:
                            # final_tab.loc[final_tab['Variable'].str.startswith(col), 'Base_Col'] = final_tab['Variable'].str.rsplit('_',n=1).str[0]

                        # num_colì˜ ì»¬ëŸ¼ë“¤ì— ëŒ€í•´, Variable ê°’ ìì²´ë¥¼ Base_Colë¡œ ìœ ì§€
                        # for col in num_col:
                            # final_tab.loc[final_tab['Variable'] == col, 'Base_Col'] = col

                        return final_tab


                    def bs_res_count(sample, response_col):
                        # Ensure the response column is categorical with only two categories
                        if sample[response_col].dtype.name != 'category':
                            sample[response_col] = sample[response_col].astype('category')

                        if sample[response_col].nunique() != 2:
                            raise ValueError("ì„ íƒí•  ì¢…ì†ë³€ìˆ˜ê°€ 2ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì ¸ì•¼í•©ë‹ˆë‹¤.")

                        # Remove rows with missing response column values
                        sample = sample.dropna(subset=[response_col])

                        # Identify categorical columns based on the number of unique values and the data type
                        cat_col = [col for col in sample.columns if (sample[col].nunique() <= 3) and not is_date_column(sample[col])]
                        for col in cat_col:
                            sample[col] = sample[col].astype('category')

                        if response_col in cat_col:
                            cat_col.remove(response_col)

                        # Analysis for categorical columns
                        results_cat = []
                        for col in cat_col:
                            # Drop rows with missing values in the column
                            cat_sample = sample.dropna(subset=[col])

                            # Calculate counts and percentages grouped by the response column
                            counts = cat_sample.groupby([response_col, col]).size().unstack(fill_value=0)
                            percentages = counts.div(counts.sum(axis=1), axis=0) * 100

                            # Create a combined table with count and percentage
                            for level in counts.columns:
                                row_data = {
                                    'Variable': f"{col}_{level}",
                                    # 'Statistic': None,
                                    'P-value': None
                                }
                                for group in counts.index:
                                    count_value = counts.loc[group, level]
                                    percent_value = percentages.loc[group, level]
                                    row_data[f'{response_col}_{group}'] = f"{count_value:,} ({percent_value:.1f})"
                                results_cat.append(row_data)

                            # Chi-square test for association between the column and response variable
                            crosstab = pd.crosstab(cat_sample[col], cat_sample[response_col], margins=False)
                            if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:  # Ensure at least 2x2 table
                                chi2_stat, chi2_p = chi2_contingency(observed=crosstab, correction=False)[:2]
                                for row in results_cat:
                                    if row['Variable'].startswith(col):
                                        # row['Statistic'] = round(chi2_stat, 3)
                                        row['P-value'] = '<0.001' if chi2_p < 0.001 else round(chi2_p, 3)

                        # Analysis for numerical columns
                        results_num = []
                        num_col = [col for col in sample.columns if col not in cat_col + [response_col] and not is_date_column(sample[col])]
                        for col in num_col:
                            # Drop rows with missing values in the numerical column
                            num_sample = sample.dropna(subset=[col])

                            # Test for normality across both groups using Shapiro-Wilk test
                            normality_results = []
                            for category in num_sample[response_col].cat.categories:
                                group_data = num_sample[num_sample[response_col] == category][col].dropna()
                                if len(group_data) >= 3:
                                    normality_results.append(shapiro(group_data)[1])
                                else:
                                    normality_results.append(0)  # Consider non-normal if the group has less than 3 observations

                            is_normal = all(p > 0.05 for p in normality_results)

                            # Calculate mean and IQR grouped by the response column
                            group_stats = num_sample.groupby(response_col).agg(
                                mean=(col, 'mean'),
                                q1=(col, lambda x: x.quantile(0.25)),
                                q3=(col, lambda x: x.quantile(0.75))
                            )
                            group_stats['iqr'] = group_stats['q3'] - group_stats['q1']

                            row_data = {
                                'Variable': col,
                                # 'Statistic': None,
                                'P-value': None
                            }
                            for group in group_stats.index:
                                mean_value = group_stats.loc[group, 'mean']
                                iqr_value = group_stats.loc[group, 'iqr']
                                row_data[f'{response_col}_{group}'] = f"{mean_value:.1f} [{iqr_value:.1f}]"
                            results_num.append(row_data)

                            # Perform the appropriate test based on normality
                            groups = [num_sample[num_sample[response_col] == category][col].dropna() for category in num_sample[response_col].cat.categories]
                            if len(groups) == 2:  # Ensure there are exactly two groups for t-test
                                if is_normal:
                                    # Check for equal variances using Levene's test
                                    _, p_levene = levene(*groups)
                                    equal_var = p_levene > 0.05

                                    # Perform t-test if data is normally distributed
                                    t_stat, t_p = ttest_ind(*groups, equal_var=equal_var)
                                    # row_data['Statistic'] = round(t_stat, 3)
                                    row_data['P-value'] = '<0.001' if t_p < 0.001 else round(t_p, 3)
                                else:
                                    # Perform Mann-Whitney U test if data is not normally distributed
                                    u_stat, u_p = kruskal(*groups)  # Using Kruskal-Wallis with 2 groups as Mann-Whitney U alternative
                                    # row_data['Statistic'] = round(u_stat, 3)
                                    row_data['P-value'] = '<0.001' if u_p < 0.001 else round(u_p, 3)

                        # Combine results and create a DataFrame
                        final_results = pd.DataFrame(results_cat + results_num)

                        # Reorder columns to match the desired format
                        response_cols = [col for col in final_results.columns if col.startswith(response_col)]
                        final_results = final_results[['Variable'] + response_cols + ['P-value']]

                        return final_results

                    def bs_res_count3(sample, response_col):
                        # Ensure the response column is categorical with three categories
                        if sample[response_col].dtype.name != 'category':
                            sample[response_col] = sample[response_col].astype('category')

                        if sample[response_col].nunique() != 3:
                            raise ValueError("ì„ íƒí•  ì¢…ì†ë³€ìˆ˜ê°€ 3ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì ¸ì•¼í•©ë‹ˆë‹¤.")

                        # Remove rows with missing response column values
                        sample = sample.dropna(subset=[response_col])

                        # Identify categorical columns based on the number of unique values and the data type
                        cat_col = [col for col in sample.columns if (sample[col].nunique() <= 3) and not is_date_column(sample[col])]
                        for col in cat_col:
                            sample[col] = sample[col].astype('category')

                        if response_col in cat_col:
                            cat_col.remove(response_col)

                        # Analysis for categorical columns
                        results_cat = []
                        for col in cat_col:
                            # Drop rows with missing values in the column
                            cat_sample = sample.dropna(subset=[col])

                            # Calculate counts and percentages grouped by the response column
                            counts = cat_sample.groupby([response_col, col]).size().unstack(fill_value=0)
                            percentages = counts.div(counts.sum(axis=1), axis=0) * 100

                            # Create a combined table with count and percentage
                            for level in counts.columns:
                                row_data = {
                                    'Variable': f"{col}_{level}",
                                    'P-value': None
                                }
                                for group in counts.index:
                                    count_value = counts.loc[group, level]
                                    percent_value = percentages.loc[group, level]
                                    row_data[f'{response_col}_{group}'] = f"{count_value:,} ({percent_value:.1f})"
                                results_cat.append(row_data)

                            # Chi-square test for association between the column and response variable
                            crosstab = pd.crosstab(cat_sample[col], cat_sample[response_col], margins=False)
                            if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:  # Ensure at least 2x3 table
                                chi2_stat, chi2_p = chi2_contingency(observed=crosstab, correction=False)[:2]
                                for row in results_cat:
                                    if row['Variable'].startswith(col):
                                        row['P-value'] = '<0.001' if chi2_p < 0.001 else round(chi2_p, 3)

                        # Analysis for numerical columns
                        results_num = []
                        num_col = [col for col in sample.columns if col not in cat_col + [response_col] and not is_date_column(sample[col])]
                        for col in num_col:
                            # Drop rows with missing values in the numerical column
                            num_sample = sample.dropna(subset=[col])

                            # Test for normality across all groups using Shapiro-Wilk test
                            normality_results = []
                            for category in num_sample[response_col].cat.categories:
                                group_data = num_sample[num_sample[response_col] == category][col].dropna()
                                if len(group_data) >= 3:
                                    normality_results.append(shapiro(group_data)[1])
                                else:
                                    normality_results.append(0)  # Consider non-normal if the group has less than 3 observations

                            is_normal = all(p > 0.05 for p in normality_results)

                            # Calculate mean and IQR grouped by the response column
                            group_stats = num_sample.groupby(response_col).agg(
                                mean=(col, 'mean'),
                                q1=(col, lambda x: x.quantile(0.25)),
                                q3=(col, lambda x: x.quantile(0.75))
                            )
                            group_stats['iqr'] = group_stats['q3'] - group_stats['q1']

                            row_data = {
                                'Variable': col,
                                'P-value': None
                            }
                            for group in group_stats.index:
                                mean_value = group_stats.loc[group, 'mean']
                                iqr_value = group_stats.loc[group, 'iqr']
                                row_data[f'{response_col}_{group}'] = f"{mean_value:.1f} [{iqr_value:.1f}]"
                            results_num.append(row_data)

                            # Perform the appropriate test based on normality
                            groups = [num_sample[num_sample[response_col] == category][col].dropna() for category in num_sample[response_col].cat.categories]
                            if len(groups) == 3:  # Ensure there are exactly three groups for ANOVA or Kruskal-Wallis
                                if is_normal:
                                    # Check for equal variances using Levene's test
                                    _, p_levene = levene(*groups)
                                    equal_var = p_levene > 0.05

                                    # Perform ANOVA if data is normally distributed
                                    f_stat, anova_p = f_oneway(*groups)
                                    row_data['P-value'] = '<0.001' if anova_p < 0.001 else round(anova_p, 3)
                                else:
                                    # Perform Kruskal-Wallis test if data is not normally distributed
                                    kw_stat, kw_p = kruskal(*groups)
                                    row_data['P-value'] = '<0.001' if kw_p < 0.001 else round(kw_p, 3)

                        # Combine results and create a DataFrame
                        final_results = pd.DataFrame(results_cat + results_num)

                        # Reorder columns to match the desired format
                        response_cols = [col for col in final_results.columns if col.startswith(response_col)]
                        final_results = final_results[['Variable'] + response_cols + ['P-value']]

                        return final_results


                    # Function to merge bs_count and bs_char
                    def merge_results(count_result, char_result):
                        # Merge based on the last occurrence of '_'
                        merged_result = pd.merge(count_result, char_result, how='left', on='Variable')
                        # Drop the auxiliary 'Base_Col' used for merging
                        return merged_result

                    st.write(" ")
                    count = bs_count(df)
                    st.dataframe(count[['Variable', 'Count']], use_container_width=True)

                    st.divider()
                    st.header("ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±", divider="rainbow")

                    # Let the user select whether the dependent variable has 2 or 3 categories
                    category_choice = st.radio(
                        "âœ”ï¸ ì¢…ì†ë³€ìˆ˜ê°€ ëª‡ ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì§€ëŠ”ì§€ ì„ íƒí•´ì£¼ì„¸ìš”:",
                        options=["2 ë²”ì£¼", "3 ë²”ì£¼"]
                    )
                    st.write()

                    if category_choice == "2 ë²”ì£¼":
                        st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;  /* Adjust padding */
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;  /* Font color */
                            font-size: 14px;  /* Font size */
                            line-height: 1.4; /* Line height */
                            text-align: left; /* Align text to the left */
                        }
                        </style>
                        <div class="custom-callout">
                            <p>- ì¢…ì†ë³€ìˆ˜ê°€ ê²°ì¸¡ì¸ í–‰ì€ ì œì™¸ í›„ countë©ë‹ˆë‹¤.</p>
                            <p>- ë“±ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Student t-ê²€ì •ì´ ì‚¬ìš©ë˜ë©°, ì´ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Welch's t-ê²€ì •ì´ ì ìš©ë©ë‹ˆë‹¤.</p>
                            <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— Chi-square ê²€ì •ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

                        </div>
                        """,
                        unsafe_allow_html=True
                        )
                        st.write(" ")
                        st.write(" ")

                        response_col = st.selectbox(
                            "âœ”ï¸ í†µê³„ì  ìœ ì˜ì„±ì„ ë³¼ ì¢…ì†ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 2],
                            index=0
                        )

                        if response_col != "-- ì„ íƒ --":
                            char = bs_res_count(df, response_col)
                            st.dataframe(char, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ìµœì¢… íŠ¹ì„±í‘œ</h4>", unsafe_allow_html=True)
                            merged = merge_results(count, char)
                            st.dataframe(merged, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>íŠ¹ì„±í‘œ ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                            export_format = st.radio("âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=["CSV", "Excel"])
                            if export_format == "CSV":
                                csv = merged.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name="bc_table.csv",
                                    mime='text/csv'
                                )
                            elif export_format == "Excel":
                                buffer = BytesIO()
                                try:
                                    # Use ExcelWriter with openpyxl
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        merged.to_excel(writer, index=False)

                                    # Move the buffer's position back to the start
                                    buffer.seek(0)

                                    # Offer the download button for Excel
                                    st.download_button(
                                        label="Excel ë‹¤ìš´ë¡œë“œ",
                                        data=buffer,
                                        file_name="bc_table.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                finally:
                                    buffer.close()
                        else:
                            st.write("")

                    elif category_choice == "3 ë²”ì£¼":
                        st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;  /* Adjust padding */
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;  /* Font color */
                            font-size: 14px;  /* Font size */
                            line-height: 1.4; /* Line height */
                            text-align: left; /* Align text to the left */
                        }
                        </style>
                        <div class="custom-callout">
                            <p>- ì¢…ì†ë³€ìˆ˜ê°€ ê²°ì¸¡ì¸ í–‰ì€ ì œì™¸ í›„ countë©ë‹ˆë‹¤.</p>
                            <p>- ë“±ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— ANOVA ê²€ì •ì´ ì‚¬ìš©ë˜ë©°, ì´ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Kruskal-Wallis ê²€ì •ì´ ì ìš©ë©ë‹ˆë‹¤.</p>
                            <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— Chi-square ê²€ì •ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

                        </div>
                        """,
                        unsafe_allow_html=True
                        )
                        st.write(" ")
                        st.write(" ")

                        response_col = st.selectbox(
                            "âœ”ï¸ í†µê³„ì  ìœ ì˜ì„±ì„ ë³¼ ì¢…ì†ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 3],
                            index=0
                        )

                        if response_col != "-- ì„ íƒ --":
                            char = bs_res_count3(df, response_col)
                            st.dataframe(char, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ìµœì¢… íŠ¹ì„±í‘œ</h4>", unsafe_allow_html=True)
                            merged = merge_results(count, char)
                            st.dataframe(merged, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>íŠ¹ì„±í‘œ ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                            export_format = st.radio("âœ”ï¸ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", options=["CSV", "Excel"])
                            if export_format == "CSV":
                                csv = merged.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name="bc_table.csv",
                                    mime='text/csv'
                                )
                            elif export_format == "Excel":
                                buffer = BytesIO()
                                try:
                                    # Use ExcelWriter with openpyxl
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        merged.to_excel(writer, index=False)

                                    # Move the buffer's position back to the start
                                    buffer.seek(0)

                                    # Offer the download button for Excel
                                    st.download_button(
                                        label="Excel ë‹¤ìš´ë¡œë“œ",
                                        data=buffer,
                                        file_name="bc_table.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                finally:
                                    buffer.close()
                        else:
                            st.write("")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ </h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ë¶„ì„ ì „ ë°ì´í„° ì¸ê³¼ê´€ê³„ë¥¼ íŒŒì•…í•´ë³´ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ ì¸ê³¼ê´€ê³„ë¥¼ ë³¼ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:", type=["csv", "xlsx"])

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    # st.session_state ì´ˆê¸°í™”
                    if "continuous_columns" not in st.session_state:
                        st.session_state.continuous_columns = []
                    if "categorical_columns" not in st.session_state:
                        st.session_state.categorical_columns = []
                    if "proceed_to_preprocessing" not in st.session_state:
                        st.session_state.proceed_to_preprocessing = False
                    if "causal_inference_ready" not in st.session_state:
                        st.session_state.causal_inference_ready = False
                    if "causal_inference_triggered" not in st.session_state:
                        st.session_state.causal_inference_triggered = False
                    if "random_seed" not in st.session_state:
                        st.session_state.random_seed = 111
                    if "causal_graph_rendered" not in st.session_state:
                        st.session_state.causal_graph_rendered = False

                    # íŒë…ë¬¸ ì—´ ì„ íƒì°½
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                    st.write("â–¶ï¸ ì¸ê³¼ê´€ê³„ë¥¼ ë³¼ ë³€ìˆ˜ ì—´ ì„ íƒ")

                    # ì„ íƒëœ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…
                    st.session_state.df = df  # Ensure df is stored initially

                    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
                    def get_categorical_columns(df):
                        categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                        low_cardinality_numerical = [
                            col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5
                        ]
                        return categorical_columns + low_cardinality_numerical

                    # ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ
                    # ê³ ìœ  ê°’ì´ 4 ì´ìƒì¸ ì—°ì†í˜• ë³€ìˆ˜ë§Œ í•„í„°ë§
                    available_columns = [
                        col for col in df.select_dtypes(include=['float64', 'int64']).columns 
                        if df[col].nunique() >= 5
                    ]

                    # multiselectë¡œ ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ
                    continuous_columns = st.multiselect(
                        "âœ”ï¸ ì—°ì†í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                        available_columns,  # ê³ ìœ  ê°’ì´ 4 ì´ìƒì¸ ì—´ë§Œ í‘œì‹œ
                        key="continuous_columns_selection"
                    )

                    # ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ
                    categorical_columns = st.multiselect(
                        "âœ”ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                        get_categorical_columns(df),
                        key="categorical_columns_selection"
                    )

                    # ì„ íƒí•œ ë³€ìˆ˜ ê¸°ë¡
                    st.session_state.X_columns = continuous_columns + categorical_columns

                    # ì„ íƒ ì™„ë£Œ ë²„íŠ¼
                    if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                        if len(continuous_columns) + len(categorical_columns) > 1:
                            st.session_state.continuous_columns = continuous_columns
                            st.session_state.categorical_columns = categorical_columns
                            st.session_state.proceed_to_preprocessing = True
                            st.success("ë³€ìˆ˜ ì„ íƒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.", icon="âœ…")
                        else:
                            st.warning("ë³€ìˆ˜ë¥¼ ë‘ ê°œ ì´ìƒ ì„ íƒí•˜ì…”ì•¼ í•©ë‹ˆë‹¤.", icon="âš ï¸")

                    # 2. ì „ì²˜ë¦¬ ë‹¨ê³„
                    if st.session_state.get("proceed_to_preprocessing", False):
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                        # ë°ì´í„° ë¶„ë¦¬
                        X_continuous = df[st.session_state.continuous_columns]
                        X_categorical = df[st.session_state.categorical_columns]

                        # ê²°ì¸¡ê°’ ìœ ë¬´ í™•ì¸
                        continuous_missing = X_continuous.isnull().any().any()
                        categorical_missing = X_categorical.isnull().any().any()

                        # ê²°ì¸¡ê°’ ì²˜ë¦¬ í•„ìš” ì—¬ë¶€ í™•ì¸
                        if not continuous_missing and not categorical_missing:
                            st.success("ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", icon="âœ…")
                            st.session_state.causal_inference_ready = True  # ë°”ë¡œ ê´€ê³„ ì¶”ë¡  ê°€ëŠ¥
                        else:
                            # ê²°ì¸¡ ì²˜ë¦¬ ë¡œì§
                            continuous_missing_value_strategies = {}
                            categorical_missing_value_strategies = {}

                            # ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬ ì„ íƒ
                            for column in st.session_state.continuous_columns:
                                missing_count = df[column].isna().sum()
                                if missing_count > 0:
                                    st.error(f"ì„ íƒí•˜ì‹  ì—°ì†í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                    strategy = st.selectbox(
                                        f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"continuous_{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        continuous_missing_value_strategies[column] = strategy

                            # ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬ ì„ íƒ
                            for column in st.session_state.categorical_columns:
                                missing_count = df[column].isna().sum()
                                if missing_count > 0:
                                    st.error(f"ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                    strategy = st.selectbox(
                                        f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"categorical_{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        categorical_missing_value_strategies[column] = strategy

                            # ê²°ì¸¡ ì²˜ë¦¬ ë²„íŠ¼
                            if st.button("ê²°ì¸¡ ì²˜ë¦¬"):
                                for column, strategy in continuous_missing_value_strategies.items():
                                    if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                        X_continuous = X_continuous.dropna(subset=[column])
                                    else:
                                        impute_strategy = {
                                            'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                            'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                            'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                        }[strategy]
                                        imputer = SimpleImputer(strategy=impute_strategy)
                                        X_continuous[[column]] = imputer.fit_transform(X_continuous[[column]])

                                for column, strategy in categorical_missing_value_strategies.items():
                                    if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                        X_categorical = X_categorical.dropna(subset=[column])
                                    elif strategy == 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´':
                                        imputer = SimpleImputer(strategy='most_frequent')
                                        X_categorical[[column]] = imputer.fit_transform(X_categorical[[column]])

                                # ì¸ë±ìŠ¤ ë™ê¸°í™”
                                shared_indexes = X_continuous.index.intersection(X_categorical.index)
                                X_continuous = X_continuous.loc[shared_indexes]
                                X_categorical = X_categorical.loc[shared_indexes]

                                st.success("ê²°ì¸¡ê°’ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.", icon="âœ…")
                                st.session_state.causal_inference_ready = True

                    # ì¸ê³¼ê´€ê³„ ì¶”ë¡  ì„¹ì…˜ í‘œì‹œ
                    if st.session_state.get("causal_inference_ready", False):
                        st.divider()
                        st.header("â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ", divider="rainbow")

                        # ë°ì´í„° ê²°í•©
                        if not X_continuous.empty or not X_categorical.empty:
                            X = pd.concat([X_continuous, X_categorical], axis=1)

                            # ë°ì´í„° ì „ì²˜ë¦¬
                            preprocessor = ColumnTransformer(
                                transformers=[
                                    ('num', StandardScaler(), list(X_continuous.columns)),  # ì—°ì†í˜• ë³€ìˆ˜ í‘œì¤€í™”
                                    ('cat', OneHotEncoder(drop='first'), list(X_categorical.columns))  # ë²”ì£¼í˜• ë³€ìˆ˜ ì›-í•« ì¸ì½”ë”©
                                ]
                            )
                            X_transformed = preprocessor.fit_transform(X)

                            # Transformed column names (to align with X_transformed)
                            transformed_columns = (
                                list(X_continuous.columns) +  # Keep continuous column names
                                list(preprocessor.named_transformers_['cat'].get_feature_names_out(X_categorical.columns))  # Extract new column names for categorical variables
                            )

                            # Streamlit ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ì¶œë ¥
                            causal_graph_container = st.container()

                            # PC ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
                            cg = pc(X_transformed, alpha=0.05)

                            # Check if graph size matches transformed column names
                            if len(transformed_columns) != len(cg.G.graph):
                                raise ValueError(
                                    f"Mismatch between graph nodes ({len(cg.G.graph)}) and transformed columns ({len(transformed_columns)})."
                                )

                            # ë°©í–¥ì„± ìˆëŠ” ì¸ê³¼ê´€ê³„ë§Œ ì¶”ì¶œ
                            def extract_directed_edges(causal_graph, column_names):
                                edges = []
                                for i in range(len(causal_graph)):
                                    for j in range(len(causal_graph)):
                                        if causal_graph[i, j] == 1 and causal_graph[j, i] != 1:  # Only i â†’ j
                                            edges.append((column_names[i], column_names[j]))
                                        elif causal_graph[i, j] == -1 and causal_graph[j, i] != -1:  # Only j â†’ i
                                            edges.append((column_names[j], column_names[i]))
                                return edges

                            # Extract directed edges using transformed column names
                            edges = extract_directed_edges(cg.G.graph, transformed_columns)

                            # Create the causal graph
                            causal_graph = nx.DiGraph()
                            causal_graph.add_edges_from(edges)

                            # ê·¸ë˜í”„ ì‹œê°í™” í•¨ìˆ˜
                            def visualize_graph(graph, seed=None, padding_ratio=0.1, node_separation=1.5):
                                pos = nx.spring_layout(graph, seed=seed, k=node_separation, iterations=100)

                                edge_x = []
                                edge_y = []
                                annotations = []

                                for edge in graph.edges():
                                    x0, y0 = pos[edge[0]]
                                    x1, y1 = pos[edge[1]]
                                    dx, dy = x1 - x0, y1 - y0
                                    dist = (dx**2 + dy**2)**0.5

                                    # íŒ¨ë”© ì ìš©
                                    x0_padded = x0 + dx * padding_ratio / dist
                                    y0_padded = y0 + dy * padding_ratio / dist
                                    x1_padded = x1 - dx * padding_ratio / dist
                                    y1_padded = y1 - dy * padding_ratio / dist

                                    edge_x.extend([x0_padded, x1_padded, None])
                                    edge_y.extend([y0_padded, y1_padded, None])

                                    annotations.append(
                                        dict(
                                            ax=x0_padded, ay=y0_padded,
                                            x=x1_padded, y=y1_padded,
                                            xref="x", yref="y",
                                            axref="x", ayref="y",
                                            showarrow=True,
                                            arrowhead=3,
                                            arrowsize=1.5,
                                            arrowwidth=1.5,
                                            arrowcolor="gray"
                                        )
                                    )

                                node_x = []
                                node_y = []
                                node_text = []
                                for node in graph.nodes():
                                    x, y = pos[node]
                                    node_x.append(x)
                                    node_y.append(y)
                                    node_text.append(node)

                                node_trace = go.Scatter(
                                    x=node_x,
                                    y=node_y,
                                    mode='markers+text',
                                    text=node_text,
                                    textfont=dict(family='Times New Roman', size=12, color='black'),
                                    marker=dict(
                                        size=60,
                                        color='lightblue',
                                        line=dict(width=2, color='darkblue')
                                    ),
                                    hoverinfo='text'
                                )

                                edge_trace = go.Scatter(
                                    x=edge_x,
                                    y=edge_y,
                                    line=dict(width=1.5, color='gray'),
                                    hoverinfo='none',
                                    mode='lines'
                                )

                                fig = go.Figure(data=[edge_trace, node_trace])
                                fig.update_layout(
                                    height=800,
                                    showlegend=False,
                                    title_text="Causal Graph",
                                    title_font=dict(family="Times New Roman", size=20, color="black"),
                                    margin=dict(l=50, r=50, t=50, b=50),
                                    xaxis=dict(showgrid=False, zeroline=False),
                                    yaxis=dict(showgrid=False, zeroline=False),
                                    annotations=annotations
                                )

                                return fig

                            # Graph rendering
                            regenerate_layout_clicked = st.button("ğŸš€ Figure ìƒì„±", key="regenerate_causal_layout_button")

                            if regenerate_layout_clicked or not st.session_state.causal_graph_rendered:
                                if regenerate_layout_clicked:
                                    st.session_state.random_seed = np.random.randint(0, 9999)

                                fig = visualize_graph(causal_graph, seed=st.session_state.random_seed)  # Pass `causal_graph` explicitly
                                st.plotly_chart(fig, use_container_width=True, key=f"plotly_chart_causal_{st.session_state.random_seed}")
                                st.session_state.causal_graph_rendered = True

                        if st.session_state.get("causal_inference_ready", False):
                            st.divider()
                            st.header("â™»ï¸ ì¸ê³¼ê´€ê³„ ì¶”ë¡  with Simple Rule", divider="rainbow")

                        # Graph visualization container
                        simple_rule_graph_container = st.container()

                        # Initialize random seed
                        if "random_seed" not in st.session_state:
                            st.session_state.random_seed = 111

                        # Function to extract directed edges with exclusions
                        def extract_directed_edges_with_exclusions(causal_graph, column_names, exclusions):
                            edges = []
                            num_nodes = len(causal_graph)

                            # Ensure graph and column_names align
                            if num_nodes != len(column_names):
                                raise ValueError(
                                    f"Mismatch between graph nodes ({num_nodes}) and column names ({len(column_names)})."
                                )

                            for i in range(num_nodes):
                                for j in range(num_nodes):
                                    if causal_graph[i, j] == 1 and causal_graph[j, i] != 1:  # Only i â†’ j
                                        edge = (column_names[i], column_names[j])
                                        if edge not in exclusions:
                                            edges.append(edge)
                                    elif causal_graph[i, j] == -1 and causal_graph[j, i] != -1:  # Only j â†’ i
                                        edge = (column_names[j], column_names[i])
                                        if edge not in exclusions:
                                            edges.append(edge)
                            return edges

                        # Run PC algorithm
                        cg = pc(X_transformed, alpha=0.05)

                        # Track transformed column names
                        transformed_columns = (
                            list(X_continuous.columns) +  # Continuous variables
                            list(preprocessor.named_transformers_['cat'].get_feature_names_out(X_categorical.columns))  # Categorical variables
                        )

                        # Validate graph size against column names
                        if len(transformed_columns) != len(cg.G.graph):
                            raise ValueError(
                                f"Mismatch between the number of graph nodes ({len(cg.G.graph)}) and transformed columns ({len(transformed_columns)})."
                            )

                        # Simple Rule-based graph rendering
                        with simple_rule_graph_container:
                            st.markdown("#### ğŸ”” Simple Rule ì„¤ì •")
                            st.info("Simple Ruleì„ ì„¤ì •í•˜ì—¬ íŠ¹ì • ê´€ê³„ë¥¼ ì œì™¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: Age â†’ Sex ë˜ëŠ” Sex â†’ Age)")

                            # Simple Rule setup
                            available_columns = transformed_columns
                            exclude_edges = st.multiselect(
                                "âœ”ï¸ ì¸ê³¼ê´€ê³„ì—ì„œ ì œì™¸í•  ê´€ê³„ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                options=[f"{col1} â†’ {col2}" for col1 in available_columns for col2 in available_columns if col1 != col2],
                                default=[]
                            )
                            excluded_edges = [(edge.split(" â†’ ")[0], edge.split(" â†’ ")[1]) for edge in exclude_edges]

                            # Extract filtered edges based on exclusions
                            filtered_edges = extract_directed_edges_with_exclusions(cg.G.graph, available_columns, excluded_edges)
                            filtered_causal_graph = nx.DiGraph()
                            filtered_causal_graph.add_edges_from(filtered_edges)

                            # Visualization function
                            def visualize_graph(graph, seed=None, padding_ratio=0.1, node_separation=1.5):
                                pos = nx.spring_layout(graph, seed=seed, k=node_separation, iterations=100)

                                edge_x = []
                                edge_y = []
                                annotations = []

                                for edge in graph.edges():
                                    x0, y0 = pos[edge[0]]
                                    x1, y1 = pos[edge[1]]
                                    dx, dy = x1 - x0, y1 - y0
                                    dist = (dx**2 + dy**2)**0.5

                                    # Apply padding
                                    x0_padded = x0 + dx * padding_ratio / dist
                                    y0_padded = y0 + dy * padding_ratio / dist
                                    x1_padded = x1 - dx * padding_ratio / dist
                                    y1_padded = y1 - dy * padding_ratio / dist

                                    edge_x.extend([x0_padded, x1_padded, None])
                                    edge_y.extend([y0_padded, y1_padded, None])

                                    annotations.append(
                                        dict(
                                            ax=x0_padded, ay=y0_padded,
                                            x=x1_padded, y=y1_padded,
                                            xref="x", yref="y",
                                            axref="x", ayref="y",
                                            showarrow=True,
                                            arrowhead=3,
                                            arrowsize=1.5,
                                            arrowwidth=1.5,
                                            arrowcolor="gray"
                                        )
                                    )

                                node_x = []
                                node_y = []
                                node_text = []
                                for node in graph.nodes():
                                    x, y = pos[node]
                                    node_x.append(x)
                                    node_y.append(y)
                                    node_text.append(node)

                                node_trace = go.Scatter(
                                    x=node_x,
                                    y=node_y,
                                    mode='markers+text',
                                    text=node_text,
                                    textfont=dict(family='Times New Roman', size=12, color='black'),
                                    marker=dict(
                                        size=60,
                                        color='lightblue',
                                        line=dict(width=2, color='darkblue')
                                    ),
                                    hoverinfo='text'
                                )

                                edge_trace = go.Scatter(
                                    x=edge_x,
                                    y=edge_y,
                                    line=dict(width=1.5, color='gray'),
                                    hoverinfo='none',
                                    mode='lines'
                                )

                                fig = go.Figure(data=[edge_trace, node_trace])
                                fig.update_layout(
                                    height=800,
                                    showlegend=False,
                                    title_text="Causal Graph (Filtered by Simple Rules)",
                                    title_font=dict(family="Times New Roman", size=20, color="black"),
                                    margin=dict(l=50, r=50, t=50, b=50),
                                    xaxis=dict(showgrid=False, zeroline=False),
                                    yaxis=dict(showgrid=False, zeroline=False),
                                    annotations=annotations
                                )

                                return fig
    
                            # Render the filtered causal graph
                            regenerate_layout_clicked = st.button("ğŸš€ Simple Rule Figure ìƒì„±", key="regenerate_simple_rule_layout_button")

                            if regenerate_layout_clicked:
                                if len(excluded_edges) > 0:  # Check if any edges are excluded
                                    st.session_state.random_seed = np.random.randint(0, 9999)

                                    fig_simple_rule = visualize_graph(filtered_causal_graph, seed=st.session_state.random_seed)
                                    st.plotly_chart(fig_simple_rule, key=f"plotly_chart_simple_rule_{st.session_state.random_seed}")

                                    st.session_state["simple_rule_graph_rendered"] = True
                                else:
                                    st.error("âŒ ê´€ê³„ë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.", icon="âš ï¸")

            # except ValueError as e:
            #     st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:")
        st.warning("ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë²”ì£¼í˜• íƒ€ì…ì˜ ì¢…ì†ë³€ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.", icon="ğŸš¨")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Variable selection section
                    st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì€ ì¢…ì†ë³€ìˆ˜(y)ê°€ ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš° ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
                        <p>- ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ëŠ” unique ê°’ì´ 5ê°œ ë¯¸ë§Œì¸ ë³€ìˆ˜ë“¤ë¡œë§Œ ì¸ì‹ë©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )
                    st.write(" ")

                    # Initialize session state for variables and processing states
                    if 'y_column' not in st.session_state:
                        st.session_state.y_column = None
                    if 'X_columns' not in st.session_state:
                        st.session_state.X_columns = []
                    if 'proceed_to_preprocessing' not in st.session_state:
                        st.session_state.proceed_to_preprocessing = False

                    y_column = st.selectbox(
                        "âœ”ï¸ ì¢…ì†ë³€ìˆ˜(y)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                        options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 2],
                        index=0
                    )

                    def get_categorical_columns(df):
                        categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                        low_cardinality_numerical = [col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5]
                        return categorical_columns + low_cardinality_numerical

                    # ì¢…ì†ë³€ìˆ˜(y)ê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ ì„¤ëª…ë³€ìˆ˜ ì„ íƒ ì°½ í‘œì‹œ
                    if y_column != "-- ì„ íƒ --":
                        st.session_state.y_column = y_column

                        # Separate selections for continuous and categorical variables
                        continuous_columns = st.multiselect(
                            "âœ”ï¸ ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            df.select_dtypes(include=['float64', 'int64']).columns,
                            key="continuous_columns_selection"
                        )

                        categorical_columns = st.multiselect(
                            "âœ”ï¸ ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            get_categorical_columns(df),
                            key="categorical_columns_selection"
                        )

                        st.session_state.X_columns = continuous_columns + categorical_columns

                        # Add a button to confirm the selections
                        if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                            if y_column and (continuous_columns or categorical_columns):  # Ensure that y and at least one X is selected
                                st.session_state.y_column = y_column
                                st.session_state.continuous_columns = continuous_columns
                                st.session_state.categorical_columns = categorical_columns
                                st.session_state.proceed_to_preprocessing = True
                            else:
                                st.warning("ì¢…ì†ë³€ìˆ˜ì™€ ì„¤ëª…ë³€ìˆ˜ë¥¼ í•œ ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.", icon="âš ï¸")

                            # Drop rows with missing values in the dependent variable (y)
                            df = df.dropna(subset=[st.session_state.y_column])

                            # Separate continuous and categorical columns
                            X_continuous = df[st.session_state.continuous_columns]
                            X_categorical = df[st.session_state.categorical_columns]
                            y = df[st.session_state.y_column]

                        # ì „ì²˜ë¦¬ ë‹¨ê³„ (ì„ íƒ ì™„ë£Œ í›„ ì§„í–‰)
                        if st.session_state.get("proceed_to_preprocessing", False):
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•… ë° ì²˜ë¦¬</h4>", unsafe_allow_html=True)

                            # Check missing values in y
                            y_missing_count = df[st.session_state.y_column].isna().sum()
                            if y_missing_count > 0:
                                st.warning(f"ì„ íƒëœ ì¢…ì†ë³€ìˆ˜ '{st.session_state.y_column}'ì— ê²°ì¸¡ê°’ì´ {y_missing_count}ê°œ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ í–‰ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.", icon="âš ï¸")
                                df = df.dropna(subset=[st.session_state.y_column])

                            # ë°ì´í„° ë¶„ë¦¬
                            X_continuous = df[st.session_state.continuous_columns]
                            X_categorical = df[st.session_state.categorical_columns]
                            y = df[st.session_state.y_column]

                            # Check for missing values in independent variables
                            continuous_missing = X_continuous.isnull().any().any()
                            categorical_missing = X_categorical.isnull().any().any()

                            # ê²°ì¸¡ì´ ì—†ìœ¼ë©´ ë¶„ì„ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ë„ì›€
                            if not continuous_missing and not categorical_missing:
                                st.success("ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", icon="âœ…")
                                st.session_state.logit_ready = True  # ë°ì´í„°ê°€ ì¤€ë¹„ëœ ìƒíƒœë¡œ ì„¤ì •
                            else:
                                st.session_state.logit_ready = False  # ê²°ì¸¡ì´ ìˆìœ¼ë©´ logit_readyë¥¼ Falseë¡œ ì„¤ì •

                            # ê²°ì¸¡ ì²˜ë¦¬ ë¡œì§
                            continuous_missing_value_strategies = {}
                            categorical_missing_value_strategies = {}

                            # ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                            for column in st.session_state.continuous_columns:
                                missing_count = df[column].isna().sum()
                                if missing_count > 0:
                                    st.error(f"ì„ íƒí•˜ì‹  ì—°ì†í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                    strategy = st.selectbox(
                                        f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"continuous_{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        continuous_missing_value_strategies[column] = strategy

                            # ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                            for column in st.session_state.categorical_columns:
                                missing_count = df[column].isna().sum()
                                if missing_count > 0:
                                    st.error(f"ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                    strategy = st.selectbox(
                                        f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"categorical_{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        categorical_missing_value_strategies[column] = strategy

                            # "ë¶„ì„ ì‹œì‘" ë²„íŠ¼ì„ í•­ìƒ í‘œì‹œ
                            if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
                                if continuous_missing_value_strategies or categorical_missing_value_strategies:
                                    # ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                                    for column, strategy in continuous_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            X_continuous = X_continuous.dropna(subset=[column])
                                        else:
                                            impute_strategy = {
                                                'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                                'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                                'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                            }[strategy]
                                            imputer = SimpleImputer(strategy=impute_strategy)
                                            X_continuous[[column]] = imputer.fit_transform(X_continuous[[column]])

                                    # ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                                    for column, strategy in categorical_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            # Drop rows with missing values in the column
                                            X_categorical = X_categorical.dropna(subset=[column])
                                        elif strategy == 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´':
                                            # Ensure the column is of categorical type (optional, depending on your data)
                                            if X_categorical[column].dtype not in ['category', 'object']:
                                                X_categorical[column] = X_categorical[column].astype('category')
                                            
                                            # Impute the most frequent value
                                            imputer = SimpleImputer(strategy='most_frequent')
                                            X_categorical[[column]] = imputer.fit_transform(X_categorical[[column]])

                                    # ì¸ë±ìŠ¤ë¥¼ ë™ê¸°í™”
                                    shared_indexes = X_continuous.index.intersection(X_categorical.index)
                                    X_continuous = X_continuous.loc[shared_indexes]
                                    X_categorical = X_categorical.loc[shared_indexes]
                                    y = y.loc[shared_indexes]

                                    # session_stateì— ê°±ì‹ ëœ ë°ì´í„° ì €ì¥
                                    st.session_state.X_continuous = X_continuous
                                    st.session_state.X_categorical = X_categorical
                                    st.session_state.y = y
                                    st.session_state.logit_ready = True  # ë°ì´í„° ì¤€ë¹„ ì™„ë£Œë¡œ ì„¤ì •

                                    # ë””ë²„ê¹…ìš© ì¶œë ¥
                                    st.success("ê²°ì¸¡ê°’ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.", icon="âœ…")
                                else:
                                    # ê²°ì¸¡ê°’ì´ ì—†ì„ ë•Œ ì²˜ë¦¬ ì™„ë£Œ ë¬¸êµ¬ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
                                    st.session_state.logit_ready = True  # ë°ì´í„° ì¤€ë¹„ ì™„ë£Œë¡œ ì„¤ì •
                                    # st.success("ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", icon="âœ…")

                                # ë¶„ì„ ì‹œì‘ ë²„íŠ¼ì´ ëˆŒë¦° ê²½ìš°
                                if st.session_state.get("logit_ready", False):
                                    st.divider()
                                    st.header('ğŸ’» Logistic Regression ê²°ê³¼', divider='rainbow')

                                    # ê°±ì‹ ëœ ë°ì´í„°ë¥¼ session_stateì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                                    X_continuous = st.session_state.X_continuous
                                    X_categorical = st.session_state.X_categorical
                                    y = st.session_state.y

                                    # One-Hot Encoding for categorical variables
                                    X_categorical = pd.get_dummies(X_categorical, drop_first=True)

                                    # Boolean ì²˜ë¦¬
                                    for column in X_categorical.columns:
                                        if X_categorical[column].dtype == 'bool':
                                            X_categorical[column] = X_categorical[column].map({True: 1, False: 0})

                                    # Combine continuous and categorical variables
                                    X = pd.concat([X_continuous, X_categorical], axis=1)

                                    # Ensure all columns in X are numeric
                                    X = X.apply(pd.to_numeric, errors='coerce')

                                    # ê²°ì¸¡ ë° ë¬´í•œ ê°’ í™•ì¸
                                    if X.isnull().values.any():
                                        st.error("ì „ì²˜ë¦¬ í›„ì—ë„ ì„¤ëª…ë³€ìˆ˜ì— ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        st.dataframe(X)  # ë””ë²„ê¹…ìš© ë°ì´í„° ì¶œë ¥
                                    elif np.isinf(X).values.any():
                                        st.error("ì „ì²˜ë¦¬ í›„ ì„¤ëª…ë³€ìˆ˜ì— ë¬´í•œ ê°’ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ë°ì´í„° ì •ê·œí™”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        st.dataframe(X)  # ë””ë²„ê¹…ìš© ë°ì´í„° ì¶œë ¥
                                    else:
                                        try:
                                            # Split the data
                                            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                                            # Add constant (intercept) to the features
                                            X_train_const = sm.add_constant(X_train)
                                            X_test_const = sm.add_constant(X_test)

                                            # Logistic regression model using statsmodels
                                            model = sm.Logit(y_train, X_train_const)
                                            result = model.fit()

                                            # Predictions
                                            y_pred_prob = result.predict(X_test_const)
                                            y_pred_class = (y_pred_prob >= 0.5).astype(int)

                                            # ê²°ê³¼ ì¶œë ¥
                                            st.markdown("<h4 style='font-size:16px;'>Model OR & P-value:</h4>", unsafe_allow_html=True)
                                            summary_table = result.summary2().tables[1]
                                            summary_df = summary_table[['Coef.', 'P>|z|', '[0.025', '0.975]']]

                                            # Calculate Odds Ratio (OR) as the exponential of the coefficient
                                            summary_df['OR'] = np.exp(summary_df['Coef.'])
                                            summary_df['95% CI Lower'] = np.exp(summary_df['[0.025'])
                                            summary_df['95% CI Upper'] = np.exp(summary_df['0.975]'])

                                            # Rename columns for clarity
                                            summary_df = summary_df.rename(columns={'P>|z|': 'P-value'})

                                            # Replace P-values equal to 0 with "<0.001"
                                            summary_df['P-value'] = summary_df['P-value'].apply(lambda x: '<0.001' if x == 0 else round(x, 4))

                                            # Rearrange columns to include OR, Coefficient, P-value, and Confidence Interval
                                            summary_df = summary_df[['OR', '95% CI Lower', '95% CI Upper', 'P-value']]
                                            st.dataframe(summary_df, use_container_width=True)

                                            # Classification Report
                                            st.markdown("<h5 style='font-size:16px;'><strong>Classification Report:</strong></h5>", unsafe_allow_html=True)
                                            report = classification_report(y_test, y_pred_class, output_dict=True)
                                            st.dataframe(pd.DataFrame(report).transpose(), use_container_width=True)

                                            st.write(" ")
                                            st.write(" ")
                                            st.header("ğŸ’» Logistic Regression Figures", divider='rainbow')
                                            # AUC Curve
                                            fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
                                            roc_auc = auc(fpr, tpr)

                                            # Create a Plotly figure for ROC Curve
                                            fig_roc = go.Figure()

                                            # Add ROC curve line
                                            fig_roc.add_trace(go.Scatter(
                                                x=fpr, y=tpr,
                                                mode='lines',
                                                name=f'ROC curve (area = {roc_auc:.2f})',
                                                line=dict(color='darkorange', width=2)
                                            ))

                                            # Add diagonal line
                                            fig_roc.add_trace(go.Scatter(
                                                x=[0, 1], y=[0, 1],
                                                mode='lines',
                                                line=dict(color='navy', width=2, dash='dash'),
                                                showlegend=False
                                            ))

                                            # Update layout for Plotly figure
                                            fig_roc.update_layout(
                                                title="ROC Curve",
                                                xaxis_title="False Positive Rate",
                                                yaxis_title="True Positive Rate",
                                                legend=dict(x=0.4, y=0),
                                                width=600, height=600  # Adjust dimensions as per your requirement
                                            )

                                            # Display the Plotly figure in Streamlit
                                            st.plotly_chart(fig_roc)

                                            # Create confusion matrix
                                            cm = confusion_matrix(y_test, y_pred_class)

                                            # Create a Plotly heatmap for confusion matrix
                                            fig_cm = ff.create_annotated_heatmap(
                                                z=cm,
                                                x=['Predicted Negative', 'Predicted Positive'],
                                                y=['Actual Negative', 'Actual Positive'],
                                                colorscale='Blues',
                                                showscale=False,
                                                annotation_text=[[str(value) for value in row] for row in cm]  # Add annotations with values
                                            )

                                            # Update annotations to change font size
                                            for annotation in fig_cm.layout.annotations:
                                                annotation.font.size = 16  # Adjust font size
                                                annotation.font.color = "black"  # Change font color for better contrast

                                            # Update layout for the confusion matrix
                                            fig_cm.update_layout(
                                                title="Confusion Matrix",
                                                width=600, height=600  # Adjust dimensions as per your requirement
                                            )

                                            # Display the Plotly heatmap in Streamlit
                                            st.plotly_chart(fig_cm)

                                            # Filter out "const" variable from the summary_df
                                            summary_df = summary_df[~summary_df.index.str.contains('const')]

                                            # Drop rows with NaN in CI or OR columns
                                            summary_df = summary_df.dropna(subset=['95% CI Lower', '95% CI Upper', 'OR'])

                                            # Calculate X-axis range (ensure CI fits and log scale works)
                                            x_min = 0  # Set minimum to avoid log(0)
                                            x_max = summary_df['95% CI Upper'].max()+1

                                            # Apply log transformation safely
                                            log_x_min = np.log10(x_min)
                                            log_x_max = np.log10(x_max)

                                            # Initialize the figure
                                            fig_forest = go.Figure()

                                            # Add horizontal lines for confidence intervals
                                            for i, row in summary_df.iterrows():
                                                # Add CI line
                                                fig_forest.add_trace(go.Scatter(
                                                    x=[row['95% CI Lower'], row['95% CI Upper']],
                                                    y=[i, i],
                                                    mode='lines',
                                                    line=dict(color='gray', width=2),
                                                    showlegend=False
                                                ))

                                                # Add OR point
                                                fig_forest.add_trace(go.Scatter(
                                                    x=[row['OR']],
                                                    y=[i],
                                                    mode='markers',
                                                    marker=dict(color='blue', size=7),
                                                    showlegend=False
                                                ))

                                                # Add CI end markers ("|") with thicker appearance
                                                fig_forest.add_trace(go.Scatter(
                                                    x=[row['95% CI Lower'], row['95% CI Upper']],
                                                    y=[i, i],
                                                    mode='text',
                                                    text=["|", "|"],
                                                    textfont=dict(size=18, color="gray", family="Arial Black"),  # Bold and larger font
                                                    textposition="middle center",
                                                    showlegend=False
                                                ))

                                            # Add vertical line for OR=1
                                            fig_forest.add_shape(
                                                type="line",
                                                x0=1, x1=1,
                                                y0=-0.5, y1=len(summary_df) - 0.5,
                                                line=dict(color="red", width=2, dash="dash")
                                            )

                                            # Update layout for the forest plot
                                            fig_forest.update_layout(
                                                title="Forest Plot of Odds Ratios",
                                                xaxis=dict(
                                                    title="Odds Ratio",
                                                    type="log",  # Log scale for better visualization
                                                    range=[np.log10(x_min), np.log10(x_max)],
                                                    zeroline=False
                                                ),
                                                yaxis=dict(
                                                    title="Variables",
                                                    tickvals=list(range(len(summary_df))),
                                                    ticktext=summary_df.index,  # Use index names (variables) as y-axis labels
                                                    autorange="reversed"  # Reverse Y-axis to match conventional forest plot style
                                                ),
                                                width=800,
                                                height=600,
                                                template="plotly_white"
                                            )

                                            # Display the Plotly figure in Streamlit
                                            st.plotly_chart(fig_forest)

                                        except Exception as e:
                                            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                                            st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ’» ìƒì¡´ë¶„ì„":
    # Streamlit setup
        st.markdown(
            """
            <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
                <h2 style="color: #000000;">ğŸ’» ìƒì¡´ë¶„ì„</h2>
                <p style="font-size:18px; color: #000000;">
                &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
                </p>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ğŸ“ ìƒì¡´ë¶„ì„ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:")
        st.warning("ìƒì¡´ë¶„ì„ì€ ì‚¬ê±´ ë°œìƒê¹Œì§€ì˜ ì‹œê°„(duration)ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ì™€ ì‚¬ê±´ë°œìƒ ì—¬ë¶€(event)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.", icon="ğŸš¨")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    st.stop()

                # íŒŒì¼ ì´ë¦„ í•´ì‹± ë° ì„ì‹œ ì €ì¥
                with tempfile.TemporaryDirectory() as temp_dir:
                    # íŒŒì¼ ì´ë¦„ì„ í•´ì‹œë¡œ ìµëª…í™”
                    file_hash = hashlib.sha256(uploaded_file.name.encode()).hexdigest()
                    temp_file_path = os.path.join(temp_dir, file_hash)

                    # ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ë””ë ‰í„°ë¦¬ì— ì €ì¥
                    with open(temp_file_path, "wb") as temp_file:
                        temp_file.write(uploaded_file.getbuffer())

                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(temp_file_path)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(temp_file_path)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜
                        if len(sheet_names) > 1:
                            sheet = st.selectbox("âœ”ï¸ ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:", 
                                                ["-- ì„ íƒ --"] + sheet_names)
                            if sheet == "-- ì„ íƒ --":
                                st.stop()
                            else:
                                df = pd.read_excel(temp_file_path, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            df = pd.read_excel(temp_file_path, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("âœ”ï¸ ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ’» ìƒì¡´ë¶„ì„")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Section for variable selection
                    duration_column = None  # Initialize duration_column as None
                    
                    # Session state ì´ˆê¸°í™”
                    if "analysis_ready" not in st.session_state:
                        st.session_state.analysis_ready = False

                    # Step 1: ë³€ìˆ˜ ì„ íƒ
                    st.markdown("<h4 style='color:grey;'>â˜‘ï¸ ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)

                    # ìƒì¡´ ê¸°ê°„ ì—´ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                    duration_column = st.selectbox(
                        "âœ”ï¸ ì‚¬ê±´ì´ ë°œìƒí•˜ê¸°ê¹Œì§€ì˜ ì‹œê°„(duration)ì„ ë‚˜íƒ€ë‚´ëŠ” ì—°ì†í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                        options=["-- ì„ íƒ --"] + list(df.columns),
                        index=0,
                        key="duration_column"
                    )
                    event_column = st.selectbox(
                        "âœ”ï¸ ì‚¬ê±´ì´ ë°œìƒí–ˆëŠ”ì§€ ì—¬ë¶€(event)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì´ì§„ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
                        options=["-- ì„ íƒ --"] + list(df.columns),
                        index=0,
                        key="event_column"
                    )

                    if duration_column != "-- ì„ íƒ --" and event_column != "-- ì„ íƒ --":
                        # ê²°ì¸¡ íŒŒì•…
                        missing_duration_count = df[duration_column].isna().sum()
                        missing_event_count = df[event_column].isna().sum()
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                        if missing_duration_count > 0 or missing_event_count > 0:
                            st.markdown(
                                f"<p style='font-size:16px; color:red;'><strong>{missing_duration_count}ê°œì˜ ê²°ì¸¡ì´ '{duration_column}' ì—´ì—, "
                                f"{missing_event_count}ê°œì˜ ê²°ì¸¡ì´ '{event_column}' ì—´ì— ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.</strong></p>",
                                unsafe_allow_html=True
                            )
                            if st.checkbox("âœ”ï¸ ê²°ì¸¡ëœ ê´€ì¸¡ì„ ê²€ì—´ë¡œ ê¸°ë¡í•˜ì‹œë ¤ë©´ ì„ íƒí•´ì£¼ì„¸ìš”: (ë¯¸ì„ íƒ ì‹œ ê²°ì¸¡ í–‰ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.)"):
                                # ì˜ˆì œ: ê²€ì—´ ê¸°ê°„ ì…ë ¥
                                censoring_date = st.number_input("ê²€ì—´ ê¸°ê°„(ì •ìˆ˜ ì…ë ¥)ì„ ì„¤ì •í•´ì£¼ì„¸ìš”:", min_value=0, max_value=10000, step=1)
                                if censoring_date:
                                    df[duration_column] = df[duration_column].fillna(censoring_date)
                                    df[event_column] = df[event_column].fillna(0)  # Mark as censored
                        else:
                            st.success("ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", icon="âœ…")

                        # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
                        st.write(" ")
                        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", key="start_analysis"):
                            st.session_state.analysis_ready = True

                    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                    if st.session_state.analysis_ready:
                        st.divider()
                        st.header("ğŸ’» ìƒì¡´ë¶„ì„ ê²°ê³¼", divider='rainbow')

                        # ê¸°ê°„ ì—´ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                        df_to_display = df[[event_column, duration_column]]
                        durations = df[duration_column].dropna()

                        events = df[event_column].dropna()

                        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                        st.markdown("<h6>Event Dataframe</h6>", unsafe_allow_html=True)
                        st.dataframe(df_to_display, use_container_width=True)

                        # Kaplan-Meier ë¶„ì„
                        st.markdown("<h6>Event Table</h6>", unsafe_allow_html=True)
                        from lifelines import KaplanMeierFitter
                        kmf = KaplanMeierFitter()
                        kmf.fit(durations, event_observed=events)
                        event_table = kmf.event_table
                        st.dataframe(event_table, use_container_width=True)

                        st.write(" ")
                        st.header("ğŸ’» Kaplan-Meier Curve", divider='rainbow')

                        # Kaplan-Meier ìƒì¡´ ê³¡ì„ 
                        plt.figure(figsize=(10, 6))
                        kmf.plot_survival_function()

                        # Plot Kaplan-Meier curve using Plotly
                        km_curve = go.Figure()
                        km_curve.add_trace(go.Scatter(
                            x=kmf.timeline,
                            y=kmf.survival_function_['KM_estimate'],
                            mode='lines',
                            name='Kaplan-Meier Curve',
                            line=dict(color='blue')
                        ))
                        km_curve.update_layout(
                            title="Kaplan-Meier Curve",
                            xaxis_title="Duration (days)",
                            yaxis_title="Survival Probability",
                            width=800,
                            height=600
                        )
                        st.plotly_chart(km_curve)

                        # Divider for categorical analysis
                        st.divider()
                        st.markdown("<h6>Kaplan-Meier Curve with Variables</h6>", unsafe_allow_html=True)

                        # Categorical variable selection for Kaplan-Meier curve
                        excluded_columns = ["baseline_date", duration_column, event_column]

                        km_cat_column = st.selectbox(
                            "âœ”ï¸ KM Curveë¥¼ ê·¸ë£¹ë³„ë¡œ í™•ì¸í•  ê·¸ë£¹ì—´ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:"",
                            options=["-- ì„ íƒ --"] + [col for col in df.columns if col not in excluded_columns and df[col].nunique() < 10],
                            index=0,
                            key="km_cat_column"
                        )

                        # Display the selected DataFrame and grouped KM curves if a variable is selected
                        if st.session_state.km_cat_column != "-- ì„ íƒ --":
                            st.markdown("<h6>Event Dataframe</h6>", unsafe_allow_html=True)

                            try:
                                # ìƒì¡´ ê¸°ê°„ ì—´ ì‚¬ìš© ì‹œ
                                st.dataframe(
                                    df[[event_column, duration_column, st.session_state.km_cat_column]], use_container_width=True
                                )
                            except KeyError as e:
                                st.error(f"ì„ íƒëœ ì—´ ì¤‘ í•˜ë‚˜ê°€ ë°ì´í„°í”„ë ˆì„ì— ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")

                            # Plot Kaplan-Meier curves grouped by the categorical variable
                            km_curve = go.Figure()

                            for group in df[st.session_state.km_cat_column].dropna().unique():
                                # Filter the DataFrame for the current group
                                group_df = df[df[st.session_state.km_cat_column] == group]

                                # Extract durations and events
                                group_durations = group_df[duration_column].dropna()
                                group_events = group_df[event_column].dropna()

                                # Ensure non-empty groups
                                if not group_durations.empty and not group_events.empty:
                                    kmf.fit(group_durations, event_observed=group_events, label=str(group))

                                    # Add trace
                                    km_curve.add_trace(go.Scatter(
                                        x=kmf.timeline,
                                        y=kmf.survival_function_[kmf.survival_function_.columns[0]],
                                        mode='lines',
                                        name=f'{st.session_state.km_cat_column}: {group}'
                                    ))

                            # Update layout for Plotly figure
                            km_curve.update_layout(
                                title="Kaplan-Meier Curve by Category",
                                xaxis_title="Duration (days)",
                                yaxis_title="Survival Probability",
                                width=800,
                                height=600
                            )
                            st.plotly_chart(km_curve)

                            for group in df[st.session_state.km_cat_column].dropna().unique():  # Ensure no NaN groups
                                # Display the event table for the current group
                                st.markdown(f"<h6>Event Table for {st.session_state.km_cat_column}: {group}</h6>", unsafe_allow_html=True)
                                event_table = kmf.event_table
                                st.dataframe(event_table, use_container_width=True)

                        # Style for custom callout boxes
                        st.divider()
                        st.markdown(
                            """
                            <style>
                            .custom-callout {
                                background-color: #f9f9f9;
                                padding: 10px;
                                border-radius: 10px;
                                border: 1px solid #d3d3d3;
                                box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                            }
                            .custom-callout p {
                                margin: 0;
                                color: #000000;
                                font-size: 14px;
                                line-height: 1.4;
                                text-align: left;
                            }
                            </style>
                            """,
                            unsafe_allow_html=True
                        )

                        # st.session_state ì´ˆê¸°í™”
                        if "continuous_columns" not in st.session_state:
                            st.session_state.continuous_columns = []
                        if "categorical_columns" not in st.session_state:
                            st.session_state.categorical_columns = []
                        if "proceed_to_preprocessing" not in st.session_state:
                            st.session_state.proceed_to_preprocessing = False
                        if "survival_ready" not in st.session_state:
                            st.session_state.survival_ready = False

                        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
                        def get_categorical_columns(df):
                            categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                            low_cardinality_numerical = [
                                col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5
                            ]
                            return categorical_columns + low_cardinality_numerical

                        # UI for variable selection
                        st.header("ğŸ’» Cox Proportional Hazards Modeling", divider='rainbow')
                        st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)

                        # ì—°ì†í˜• ë³€ìˆ˜ ì„ íƒ (ì œì™¸ëœ ì—´ ì œì™¸)
                        continuous_columns = st.multiselect(
                            "âœ”ï¸ ì—°ì†í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            [
                                col for col in df.select_dtypes(include=['float64', 'int64']).columns 
                                if col not in excluded_columns and df[col].nunique() >= 5
                            ],
                            key="continuous_columns_selection"
                        )

                        # ë²”ì£¼í˜• ë³€ìˆ˜ ì„ íƒ (ì œì™¸ëœ ì—´ ì œì™¸)
                        categorical_columns = st.multiselect(
                            "âœ”ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:",
                            [col for col in get_categorical_columns(df) if col not in excluded_columns],
                            key="categorical_columns_selection"
                        )

                        # ì„ íƒ ì™„ë£Œ ë²„íŠ¼
                        if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                            if len(continuous_columns) + len(categorical_columns) > 1:
                                st.session_state.continuous_columns = continuous_columns
                                st.session_state.categorical_columns = categorical_columns
                                st.session_state.proceed_to_preprocessing = True
                                st.success("ë³€ìˆ˜ ì„ íƒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”.", icon="âœ…")
                            else:
                                st.warning("ë³€ìˆ˜ë¥¼ ë‘ ê°œ ì´ìƒ ì„ íƒí•˜ì…”ì•¼ í•©ë‹ˆë‹¤.", icon="âš ï¸")

                        # 2. ì „ì²˜ë¦¬ ë‹¨ê³„
                        if st.session_state.get("proceed_to_preprocessing", False):
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                            # ë°ì´í„° ë¶„ë¦¬
                            X_continuous = df[st.session_state.continuous_columns]
                            X_categorical = df[st.session_state.categorical_columns]

                            # ê²°ì¸¡ê°’ ìœ ë¬´ í™•ì¸
                            continuous_missing = X_continuous.isnull().any().any()
                            categorical_missing = X_categorical.isnull().any().any()

                            if not continuous_missing and not categorical_missing:
                                st.success("ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", icon="âœ…")
                                st.session_state.survival_ready = True  # ë°”ë¡œ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ
                            else:
                                # ê²°ì¸¡ ì²˜ë¦¬: ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                                continuous_missing_value_strategies = {}
                                categorical_missing_value_strategies = {}

                                # Step 2: ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬ ì„ íƒ
                                for column in st.session_state.continuous_columns:
                                    missing_count = df[column].isna().sum()
                                    if missing_count > 0:
                                        st.error(f"ì„ íƒí•˜ì‹  ì—°ì†í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                        strategy = st.selectbox(
                                            f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                            ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                            key=f"continuous_{column}_strategy"
                                        )
                                        if strategy != '-- ì„ íƒ --':
                                            continuous_missing_value_strategies[column] = strategy

                                # Step 3: ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬ ì„ íƒ
                                for column in st.session_state.categorical_columns:
                                    missing_count = df[column].isna().sum()
                                    if missing_count > 0:
                                        st.error(f"ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ë³€ìˆ˜ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.", icon="â›”")
                                        strategy = st.selectbox(
                                            f"âœ”ï¸ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
                                            ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                            key=f"categorical_{column}_strategy"
                                        )
                                        if strategy != '-- ì„ íƒ --':
                                            categorical_missing_value_strategies[column] = strategy

                                # Step 4: ê²°ì¸¡ ì²˜ë¦¬ ë¡œì§ - ëª¨ë¸ í•™ìŠµ ì‹œì‘ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì‹¤í–‰
                                if continuous_missing_value_strategies or categorical_missing_value_strategies:
                                    # ì—°ì†í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                                    for column, strategy in continuous_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            X_continuous = X_continuous.dropna(subset=[column])
                                        else:
                                            impute_strategy = {
                                                'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                                'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                                'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                            }[strategy]
                                            imputer = SimpleImputer(strategy=impute_strategy)
                                            X_continuous[[column]] = imputer.fit_transform(X_continuous[[column]])

                                    # ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ ì²˜ë¦¬
                                    for column, strategy in categorical_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            X_categorical = X_categorical.dropna(subset=[column])
                                        elif strategy == 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´':
                                            imputer = SimpleImputer(strategy='most_frequent')
                                            X_categorical[[column]] = imputer.fit_transform(X_categorical[[column]])

                                    # Step 5: ì¸ë±ìŠ¤ ë™ê¸°í™”
                                    shared_indexes = X_continuous.index.intersection(X_categorical.index)
                                    X_continuous = X_continuous.loc[shared_indexes]
                                    X_categorical = X_categorical.loc[shared_indexes]

                                st.session_state.survival_ready = True  # ë°ì´í„° ì¤€ë¹„ ì™„ë£Œë¡œ ì„¤ì •

                            # Step 6: ëª¨ë¸ í•™ìŠµ ì‹œì‘ ë²„íŠ¼
                            if st.session_state.get("survival_ready", False) and st.button('ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘', key='train_model_button'):
                                st.divider()

                                # ê²°ì¸¡ ì²˜ë¦¬ ë° ëª¨ë¸ í•™ìŠµ
                                try:
                                    # Handle categorical variables (e.g., converting categories to dummy variables)
                                    X_categorical = pd.get_dummies(X_categorical, drop_first=True)

                                    # Check and handle boolean columns if they exist
                                    for column in X_categorical.columns:
                                        if X_categorical[column].dtype == 'bool':  # Only map if the column is of boolean type
                                            X_categorical[column] = X_categorical[column].map({True: 1, False: 0})

                                    # Ensure all columns in X_categorical are integers
                                    X_categorical = X_categorical.astype(int, errors='ignore')

                                    # Combine continuous and categorical columns
                                    X = pd.concat([X_continuous, X_categorical], axis=1)

                                    # Ensure that combined X does not have object or mixed types
                                    X = X.apply(pd.to_numeric, errors='coerce')

                                    # Combine X with duration and event columns
                                    df_for_cox = pd.concat([df[[duration_column, event_column]], X], axis=1).dropna()

                                    train_data, test_data = train_test_split(
                                        df_for_cox, 
                                        test_size=0.2, 
                                        random_state=42, 
                                        stratify=df_for_cox[event_column]
                                    )

                                    # Fit the Cox Proportional Hazards Model on training data
                                    cph = CoxPHFitter()
                                    cph.fit(train_data, duration_col=duration_column, event_col=event_column)

                                    # Display Cox model summary
                                    summary_table = cph.summary
                                    summary_df = summary_table[['coef', 'p', 'coef lower 95%', 'coef upper 95%']]
                                    summary_df['HR'] = np.exp(summary_df['coef'])
                                    summary_df['95% CI Lower'] = np.exp(summary_df['coef lower 95%'])
                                    summary_df['95% CI Upper'] = np.exp(summary_df['coef upper 95%'])

                                    # Display results
                                    st.header("ğŸ’» Cox Proportional Hazards Model ê²°ê³¼", divider="rainbow")

                                    # Evaluate model on test data
                                    c_index = cph.score(test_data)
                                    st.write(f"**Concordance Index (Test Data): {c_index:.3f}**")

                                    # Rename columns for clarity
                                    summary_df = summary_df.rename(columns={'p': 'P-value'})
                                    st.dataframe(summary_df[['HR', '95% CI Lower', '95% CI Upper', 'P-value']], use_container_width=True)

                                    # Predict survival probabilities for test data
                                    survival_probabilities = cph.predict_survival_function(test_data)

                                    # Convert survival probabilities to event predictions (threshold: 0.5)
                                    predicted_probs = 1 - survival_probabilities.iloc[-1, :]  # Probability of the event occurring at the last time point
                                    predicted_probs.index = test_data.index  # Align indices
                                    y_pred_class = (predicted_probs >= 0.5).astype(int)  # Classify based on threshold

                                    # Ensure y_test is aligned
                                    y_test = test_data[event_column]  # Extract true event labels from test data

                                    # Classification Report
                                    st.markdown("<h5 style='font-size:16px;'><strong>Classification Report:</strong></h5>", unsafe_allow_html=True)
                                    report = classification_report(y_test, y_pred_class, output_dict=True)
                                    st.dataframe(pd.DataFrame(report).transpose(), use_container_width=True)

                                    st.write(" ")
                                    st.write(" ")
                                    st.header("ğŸ’» Kaplan-Meier Curve", divider='rainbow')

                                    # ROC Curve
                                    fpr, tpr, _ = roc_curve(y_test, predicted_probs)
                                    roc_auc = auc(fpr, tpr)

                                    # Create a Plotly figure for ROC Curve
                                    fig_roc = go.Figure()

                                    # Add ROC curve line
                                    fig_roc.add_trace(go.Scatter(
                                        x=fpr, y=tpr,
                                        mode='lines',
                                        name=f'ROC curve (area = {roc_auc:.2f})',
                                        line=dict(color='darkorange', width=2)
                                    ))

                                    # Add diagonal line
                                    fig_roc.add_trace(go.Scatter(
                                        x=[0, 1], y=[0, 1],
                                        mode='lines',
                                        line=dict(color='navy', width=2, dash='dash'),
                                        showlegend=False
                                    ))

                                    # Update layout for Plotly figure
                                    fig_roc.update_layout(
                                        title="ROC Curve",
                                        xaxis_title="False Positive Rate",
                                        yaxis_title="True Positive Rate",
                                        legend=dict(x=0.4, y=0),
                                        width=600, height=600  # Adjust dimensions as per your requirement
                                    )

                                    # Display the Plotly figure in Streamlit
                                    st.plotly_chart(fig_roc)

                                    # Confusion Matrix
                                    cm = confusion_matrix(y_test, y_pred_class)

                                    # Create a Plotly heatmap for confusion matrix
                                    fig_cm = ff.create_annotated_heatmap(
                                        z=cm,
                                        x=['Predicted Negative', 'Predicted Positive'],
                                        y=['Actual Negative', 'Actual Positive'],
                                        colorscale='Blues',
                                        showscale=False,
                                        annotation_text=[[str(value) for value in row] for row in cm]  # Add annotations with values
                                    )

                                    # Update annotations to change font size
                                    for annotation in fig_cm.layout.annotations:
                                        annotation.font.size = 16  # Adjust font size
                                        annotation.font.color = "black"  # Change font color for better contrast

                                    # Update layout for the confusion matrix
                                    fig_cm.update_layout(
                                        title="Confusion Matrix",
                                        width=600, height=600  # Adjust dimensions as per your requirement
                                    )

                                    # Display the Plotly heatmap in Streamlit
                                    st.plotly_chart(fig_cm)

                                    # Filter out "const" variable from the summary_df
                                    summary_df = summary_df[~summary_df.index.str.contains('const')]

                                    # Drop rows with NaN in CI or OR columns
                                    summary_df = summary_df.dropna(subset=['95% CI Lower', '95% CI Upper', 'HR'])

                                    # Calculate X-axis range (ensure CI fits and log scale works)
                                    x_min = 0  # Set minimum to avoid log(0)
                                    x_max = summary_df['95% CI Upper'].max()+1

                                    # Apply log transformation safely
                                    log_x_min = np.log10(x_min)
                                    log_x_max = np.log10(x_max)

                                    # Initialize the figure
                                    fig_forest = go.Figure()

                                    # Add horizontal lines for confidence intervals
                                    for i, row in summary_df.iterrows():
                                        # Add CI line
                                        fig_forest.add_trace(go.Scatter(
                                            x=[row['95% CI Lower'], row['95% CI Upper']],
                                            y=[i, i],
                                            mode='lines',
                                            line=dict(color='gray', width=2),
                                            showlegend=False
                                        ))

                                        # Add HR point
                                        fig_forest.add_trace(go.Scatter(
                                            x=[row['HR']],
                                            y=[i],
                                            mode='markers',
                                            marker=dict(color='blue', size=7),
                                            showlegend=False
                                        ))

                                        # Add CI end markers ("|") with thicker appearance
                                        fig_forest.add_trace(go.Scatter(
                                            x=[row['95% CI Lower'], row['95% CI Upper']],
                                            y=[i, i],
                                            mode='text',
                                            text=["|", "|"],
                                            textfont=dict(size=18, color="gray", family="Arial Black"),  # Bold and larger font
                                            textposition="middle center",
                                            showlegend=False
                                        ))

                                    # Add vertical line for HR=1
                                    fig_forest.add_shape(
                                        type="line",
                                        x0=1, x1=1,
                                        y0=-0.5, y1=len(summary_df) - 0.5,
                                        line=dict(color="red", width=2, dash="dash")
                                    )

                                    # Update layout for the forest plot
                                    fig_forest.update_layout(
                                        title="Forest Plot of Hazard Ratios",
                                        xaxis=dict(
                                            title="Hazard Ratio",
                                            type="log",  # Log scale for better visualization
                                            range=[np.log10(x_min), np.log10(x_max)],
                                            zeroline=False
                                        ),
                                        yaxis=dict(
                                            title="Variables",
                                            tickvals=list(range(len(summary_df))),
                                            ticktext=summary_df.index,  # Use index names (variables) as y-axis labels
                                            autorange="reversed"  # Reverse Y-axis to match conventional forest plot style
                                        ),
                                        width=800,
                                        height=600,
                                        template="plotly_white"
                                    )

                                    # Display the Plotly figure in Streamlit
                                    st.plotly_chart(fig_forest)


                                except Exception as e:
                                    st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                                    st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except ValueError as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìœ¼ë¯€ë¡œ ë³´ê³ ê°€ í•„ìš”í•©ë‹ˆë‹¤, ë¬¸ì˜í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n: {str(e)}")
                st.error("ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´: ", traceback.format_exc())  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ì¶œë ¥
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


    elif page == "â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”":
        # SendGrid API í‚¤ ë° ì´ë©”ì¼ ì„¤ì •
        SENDGRID_API_KEY = "***REMOVED***6p4TQk8LSFeXLE_nq8W5pg.y3sSlucLQuAGg6JtuRJoshmhjJR49VyZKUE_PHNiHyk"
        MY_EMAIL = "hui135@snu.ac.kr"  # ìì‹ ì˜ ì´ë©”ì¼ ì£¼ì†Œ

        # ì´ë©”ì¼ ì „ì†¡ í•¨ìˆ˜
        def send_email_via_sendgrid(subject, content):
            try:
                # ì´ë©”ì¼ êµ¬ì„±
                email = Mail(
                    from_email="hui135@snu.ac.kr",  # ë°œì‹ ì ì´ë©”ì¼
                    to_emails=MY_EMAIL,                  # ìˆ˜ì‹ ì ì´ë©”ì¼
                    subject=subject,
                    html_content=f"<strong>{content}</strong>"
                )

                # SendGrid í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë©”ì¼ ì „ì†¡
                sg = SendGridAPIClient(SENDGRID_API_KEY)
                response = sg.send(email)
                return response  # ì‘ë‹µ ë°˜í™˜
            except Exception as e:
                st.error(f"Error: {e}")
                return None

        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”</h2>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Get user input
        st.markdown("<h4 style='color:grey;'>ì–´ë–¤ ì–´ë ¤ì›€ì´ ìˆìœ¼ì…¨ë‚˜ìš”?</h4>", unsafe_allow_html=True)
        user_input = st.text_area("ì…ë ¥í•˜ì‹  ë©”ì„¸ì§€ëŠ” ê¹€í¬ì—° ì—°êµ¬ì›ì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤.", key="user_input")

        # ì œì¶œ ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
        if st.button("ì œì¶œ", key="submit_button_1"):
            if user_input.strip() == "":  # ë¹ˆ ì…ë ¥ í™•ì¸
                st.warning("ì œì¶œ ì „ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
            else:
                # ì´ë©”ì¼ ì „ì†¡ ì‹œë„
                response = send_email_via_sendgrid("User Feedback", user_input)

                if response is None:
                    st.error("ì „ì†¡ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")  # ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ ì‹œ
                else:
                    # ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
                    if response.status_code == 202:  # 202ëŠ” SendGrid ì„±ê³µ ìƒíƒœ ì½”ë“œ
                        st.success("ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error(f"Send failed: {response.text}")
                        st.write(f"Status code: {response.status_code}")

else:
    display_header()
    st.info('GC DataRoom ì‹œìŠ¤í…œ ì´ìš©ì„ ìœ„í•´ì„  ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.', icon="ğŸ””")
