import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
import plotly.express as px
import smtplib
from email.mime.text import MIMEText
import scipy
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import requests
import plotly.figure_factory as ff
import plotly.graph_objects as go
import time
from scipy.stats import chi2_contingency, ttest_ind, levene, kruskal, shapiro, f_oneway
from lifelines import KaplanMeierFitter, CoxPHFitter
from lifelines.statistics import logrank_test
import hmac
import hashlib
import base64
import datetime
import boto3
from botocore.client import Config
# from pgmpy.estimators import HillClimbSearch, BicScore
# import networkx as nx
from causallearn.search.ConstraintBased.PC import pc
from causallearn.utils.GraphUtils import GraphUtils
import matplotlib.pyplot as plt
import networkx as nx
import openpyxl
# from causallearn.utils.GraphUtils import graph_to_adjacency_matrix

# wide format
st.set_page_config(layout="wide")

############################
######### Homepage #########
############################

# Image URL
image_url = 'http://www.snuh.org/upload/about/hi/15e707df55274846b596e0d9095d2b0e.png'
title_html = "<h2 class='title'>ğŸ¥ í—¬ìŠ¤ì¼€ì–´ì—°êµ¬ì†Œ ğŸ¥ ì—°êµ¬ì ì§€ì›</h2>"
contact_info_html = """
<div style='text-align: right; font-size: 20px; color: grey;'>
ì˜¤ë¥˜ ë¬¸ì˜: í—¬ìŠ¤ì¼€ì–´ì—°êµ¬ì†Œ ë°ì´í„° ì—°êµ¬ì› ê¹€í¬ì—° (hui135@snu.ac.kr)
</div>
"""

# Password for accessing the site
PASSWORD = "snuhgchc"  # Change this to your desired password


def login():
    if "logged_in" not in st.session_state:
        st.session_state.logged_in = False  # Initialize login state

    if not st.session_state.logged_in:  # Show login form only if not logged in
        st.sidebar.title("ë¡œê·¸ì¸")
        password = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
        # Check if the password matches
        if password == PASSWORD:
            st.sidebar.success("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤")
            st.session_state.logged_in = True  # Set login state to True
            st.session_state.loading_complete = False  # Reset loading state
            return True
        elif password:  # Show an error message only if some input is provided
            st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return False
    return True

# Main app logic
if login():  # If logged in, show the rest of the app
    if "loading_complete" not in st.session_state or not st.session_state.loading_complete:
        # Display loading image and spinner for the 3-second delay
        loading_image = st.image(image_url)  # Replace with your loading image path
        with st.spinner("Loading..."):
            time.sleep(3)  # Simulate loading time
        # After loading is complete, remove loading components
        loading_image.empty()
        st.session_state.loading_complete = True  # Mark loading as complete

    # After the loading is complete, show the sidebar menu and hide login form
    st.sidebar.empty()  # Clear the sidebar completely

    # Sidebar with functionality options after login
    st.sidebar.title("ê¸°ëŠ¥ ì„ íƒ")
    page = st.sidebar.selectbox(
        "ì‚¬ìš©í•˜ì‹¤ ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
        ["-- ì„ íƒ --", "â„¹ï¸ ì‚¬ìš©ì„¤ëª…ì„œ", "ğŸ“ í”¼ë´‡ ë³€í™˜", "ğŸ“ˆ ì‹œê°í™”", "ğŸ“Š íŠ¹ì„±í‘œ ì‚°ì¶œ", "ğŸ”ƒ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ", "ğŸ“ íŒë…ë¬¸ ì½”ë”©", "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„", "ğŸ’» ìƒì¡´ë¶„ì„", "ğŸ–ï¸ H-PEACE ë°ì´í„° íŒŒì•…", "â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"],
        index=0  # Default to "-- ì„ íƒ --"
    )

    # Display content based on the page selected
    if page == "-- ì„ íƒ --":
        st.markdown(
            """
            <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
                <h2 style="color: #000000;">ğŸ’¡ í™˜ì˜í•©ë‹ˆë‹¤!</h2>
                <p style="font-size:18px; color: #000000;">
                &nbsp;&nbsp;&nbsp;&nbsp;ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì›í•˜ì‹œëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.
                </p>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.divider()
        # Create a checkbox to toggle visibility
        toggle = st.checkbox("Update ì‚¬í•­ ìì„¸íˆë³´ê¸° - 24.12.11 Updated")
        if toggle:
            st.write("í”¼ë´‡ ê¸°ëŠ¥ Age 1 - Age 2- Age 3 ë“± í™•ì¸í•  ê²ƒ")
            st.write("íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: There are multiple radio elements with the same auto-generated ID")
            st.write("ì‹œê°í™” ê¸°ëŠ¥ TypeError: pie() got an unexpected keyword argument 'x'")
            st.write("- (ì˜ˆì‹œ) 2024.12.01 ğŸ“ í”¼ë´‡ ë³€í™˜ : ì˜¤ë¥˜ ìˆ˜ì •")
            st.write("- (ì˜ˆì‹œ) 2024.12.11 ğŸ“ˆ ì‹œê°í™” : ê¸°ëŠ¥ ì¶”ê°€")

    elif page == "â„¹ï¸ ì‚¬ìš©ì„¤ëª…ì„œ":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">â„¹ï¸  ì‚¬ìš©ì„¤ëª…ì„œ</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ê¸°ëŠ¥ ì‚¬ìš©ì„¤ëª…ë²•ì„ ì˜ìƒì„ í†µí•´ ì‚´í´ë³´ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        st.markdown("<h4 style='color:grey;'>ì–´ë–¤ ê¸°ëŠ¥ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?</h4>", unsafe_allow_html=True)
        selected = st.selectbox("ì‚¬ìš©ì„¤ëª…ì„œë¥¼ ë³´ì‹¤ ê¸°ëŠ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", options=["-- ì„ íƒ --", "ğŸ“ í”¼ë´‡ ë³€í™˜", "ğŸ“ˆ ì‹œê°í™”", "ğŸ“Š íŠ¹ì„±í‘œ ì‚°ì¶œ", "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„", "ğŸ’» ìƒì¡´ë¶„ì„", "ğŸ–ï¸ H-PEACE ë°ì´í„° íŒŒì•…", "ğŸ“ íŒë…ë¬¸ ì½”ë”©"])
        if selected == "-- ì„ íƒ --":
            st.write()
        elif selected == "ğŸ“ íŒë…ë¬¸ ì½”ë”©":
            st.video("https://youtu.be/uE45G40TnTE")

    elif page == "ğŸ–ï¸ H-PEACE ë°ì´í„° íŒŒì•…":
        # ë„¤ì´ë²„ í´ë¼ìš°ë“œ API ì¸ì¦ ì •ë³´
        access_key = "ncp_iam_BPAMKR52lve6ioI12iS1"  # ë°œê¸‰ë°›ì€ Access Key ID
        secret_key = "ncp_iam_BPKMKRWniGGEaLImGCq5UB9EkgEQEa7XWV"  # ë°œê¸‰ë°›ì€ Secret Key


        # ë„¤ì´ë²„ í´ë¼ìš°ë“œ Object Storageì˜ S3 í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
        endpoint_url = "https://kr.object.ncloudstorage.com"

        # boto3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        s3 = boto3.client(
            's3',
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key,
            endpoint_url=endpoint_url,
            config=Config(signature_version='s3v4')  # S3 í˜¸í™˜ ì¸ì¦ ë°©ì‹ ì‚¬ìš©
        )

        # ë²„í‚·ì˜ ê°ì²´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        bucket_name = "snuhgc"
        object_name = "hpeace_sample.xlsx"

        try:
            # S3ì—ì„œ ê°ì²´(íŒŒì¼)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            response = s3.get_object(Bucket=bucket_name, Key=object_name)

            # íŒŒì¼ ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
            excel_data = BytesIO(response['Body'].read())

            # Pandasë¥¼ ì‚¬ìš©í•´ Excel íŒŒì¼ì„ DataFrameìœ¼ë¡œ ì½ê¸°
            df = pd.read_excel(excel_data, engine='openpyxl')

            # Streamlitì— DataFrame ì¶œë ¥
            st.markdown(
                """
                <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
                    <h2 style="color: #000000;">ğŸ–ï¸ H-PEACE ë°ì´í„° íŒŒì•…</h2>
                    <p style="font-size:18px; color: #000000;">
                    &nbsp;&nbsp;&nbsp;&nbsp;H-PEACE ë°ì´í„°ë¥¼ ì‚´í´ë³´ì„¸ìš”.
                    </p>
                </div>
                """,
                unsafe_allow_html=True
                )
            st.divider()
            st.write(" ")

            # Select all df related to the selected patient
            patient_id = st.selectbox('ìë£Œë¥¼ ë³´ì‹¤ í™˜ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + list(df['GCID'].unique()))
            patient_df = st.session_state.df[st.session_state.df['GCID'] == patient_id]

            cat = ['ê³ í˜ˆì••_ì—¬ë¶€',
            'ê³ í˜ˆì••_íˆ¬ì•½ì—¬ë¶€',
            'ë‹¹ë‡¨_ì—¬ë¶€',
            'ë‹¹ë‡¨_íˆ¬ì•½ì—¬ë¶€',
            'ê³ ì§€í˜ˆì¦_ì—¬ë¶€',
            'ê³ ì§€í˜ˆì¦_íˆ¬ì•½ì—¬ë¶€',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_ì—¬ë¶€',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_íˆ¬ì•½ì—¬ë¶€',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_ì¤‘ì¬ìˆ˜ìˆ ì—¬ë¶€_ìŠ¤í…íŠ¸',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_ìˆ˜ìˆ ì—¬ë¶€',
            'ë‡Œì¡¸ì¤‘(ì¤‘í’)_ì—¬ë¶€',
            'ë‡Œì¡¸ì¤‘(ì¤‘í’)_íˆ¬ì•½ì—¬ë¶€',
            'ë§Œì„±ì‹ ì¥ì—¼/ë§Œì„±ì‹ ë¶€ì „_ì—¬ë¶€',
            'ë§Œì„±ì‹ ì¥ì—¼/ë§Œì„±ì‹ ë¶€ì „_íˆ¬ì•½ì—¬ë¶€',
            'ë§Œì„±ì‹ ì¥ì—¼/ë§Œì„±ì‹ ë¶€ì „_ì‹ ê¸°ëŠ¥ì €í•˜ì—¬ë¶€',
            'ë§Œì„±ì‹ ì¥ì—¼/ë§Œì„±ì‹ ë¶€ì „_íˆ¬ì„ì—¬ë¶€',
            'ê°„ê²½ë³€_ì—¬ë¶€',
            'ê°„ê²½ë³€_íˆ¬ì•½ì—¬ë¶€',
            'ë§Œì„±Bí˜•_ì—¬ë¶€',
            'ë§Œì„±Bí˜•_íˆ¬ì•½ì—¬ë¶€',
            'ë§Œì„±Cí˜•_ì—¬ë¶€',
            'ë§Œì„±Cí˜•_íˆ¬ì•½ì—¬ë¶€',
            'íê²°í•µ_ì—¬ë¶€',
            'íê²°í•µ_íˆ¬ì•½ì—¬ë¶€',
            'íê²°í•µ_ì™„ì¹˜ì—¬ë¶€_ì¹˜ë£Œì¢…ê²°',
            'íê²°í•µ_ë°˜í”ì—¬ë¶€',
            'ì²œì‹_ì—¬ë¶€',
            'ì²œì‹_íˆ¬ì•½ì—¬ë¶€',
            'ë¹„ì—¼_ì—¬ë¶€',
            'ë¹„ì—¼_íˆ¬ì•½ì—¬ë¶€',
            'ê³ í˜ˆì••_í†µí•©',
            'ë‹¹ë‡¨_í†µí•©',
            'ê³ ì§€í˜ˆì¦_í†µí•©',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_í†µí•©',
            'ë‡Œì¡¸ì¤‘(ì¤‘í’)_í†µí•©',
            'ë§Œì„±ì‹ ì¥ì—¼/ë§Œì„±ì‹ ë¶€ì „_í†µí•©',
            'ê°„ê²½ë³€_í†µí•©',
            'íê²°í•µ_í†µí•©',
            'ì²œì‹_í†µí•©',
            'íì•”_ì—¬ë¶€',
            'ìœ„ì•”_ì—¬ë¶€',
            'ëŒ€ì¥ì•”/ì§ì¥ì•”_ì—¬ë¶€',
            'ê°„ì•”_ì—¬ë¶€',
            'ìœ ë°©ì•”_ì—¬ë¶€',
            'ìê¶ê²½ë¶€ì•”_ì—¬ë¶€',
            'ê°‘ìƒì„ ì•”_ì—¬ë¶€',
            'ì „ë¦½ì„ ì•”_ì—¬ë¶€',
            'ê¸°íƒ€ì•”_ì—¬ë¶€',
            'ê³ í˜ˆì••_ê°€ì¡±ë ¥',
            'ë‹¹ë‡¨_ê°€ì¡±ë ¥',
            'ë§Œì„±ê°„ì—¼/ê°„ê²½ë³€_ê°€ì¡±ë ¥',
            'ë‡Œì¡¸ì¤‘(ì¤‘í’)_ê°€ì¡±ë ¥',
            'í˜‘ì‹¬ì¦/ì‹¬ê·¼ê²½ìƒ‰ì¦_ê°€ì¡±ë ¥',
            'íì•”_ê°€ì¡±ë ¥',
            'ìœ„ì•”_ê°€ì¡±ë ¥',
            'ëŒ€ì¥ì•”/ì§ì¥ì•”_ê°€ì¡±ë ¥',
            'ê°„ì•”_ê°€ì¡±ë ¥',
            'í•­í˜ˆì†ŒíŒì œì œ_ë³µì•½ì—¬ë¶€',
            'í•­ì‘ê³ ì œ_ë³µì•½ì—¬ë¶€',
            'ë¶€ì •ë§¥ì•½_ë³µì•½ì—¬ë¶€',
            'ì¸ìŠë¦°ì£¼ì‚¬/íŒí”„_ë³µì•½ì—¬ë¶€',
            'ì§„ì •ì œ/ìˆ˜ë©´ì œ_ë³µì•½ì—¬ë¶€',
            'í•­ìš°ìš¸ì œ/ì •ì‹ ê³¼ì•½ë¬¼_ë³µì•½ì—¬ë¶€',
            'ê°‘ìƒì„ ì•½_ë³µì•½ì—¬ë¶€',
            'ê°‘ìƒì„ ê¸°ëŠ¥í•­ì§„ì¦ì•½_ë³µì•½ì—¬ë¶€',
            'ê³¨ë‹¤ê³µì¦ì•½_ë³µì•½ì—¬ë¶€',
            'ê¸°íƒ€ì•½_ë³µì•½ì—¬ë¶€',
            'ìŠ¤í…Œë¡œì´ë“œì œ_ë³µì•½ì—¬ë¶€',
            'ì†Œì—¼ì§„í†µì œ_ë³µì•½ì—¬ë¶€',
            'í•œì•½_ë³µì•½ì—¬ë¶€',
            'ì¹¼ìŠ˜ì œ_ë³µì•½ì—¬ë¶€',
            'ì¼ë°˜ë‹´ë°°_í¡ì—°ì—¬ë¶€',
            'ì¼ë°˜ë‹´ë°°_ê³¼ê±°í¡ì—°ëŸ‰',
            'ì¼ë°˜ë‹´ë°°_í˜„ì¬í¡ì—°ëŸ‰',
            'ì•¡ìƒí˜•ì „ìë‹´ë°°_í¡ì—°ì—¬ë¶€',
            'ê¶ë ¨í˜•ì „ìë‹´ë°°_í¡ì—°ì—¬ë¶€',
            'ê³ ê°•ë„_ì‹ ì²´í™œë™ì—¬ë¶€',
            'ì¤‘ê°•ë„_ì‹ ì²´í™œë™ì—¬ë¶€',
            'ì €ê°•ë„_ì‹ ì²´í™œë™ì—¬ë¶€',
            'ê³ ê°•ë„_ìš´ë™ì—¬ë¶€',
            'ì¤‘ê°•ë„_ìš´ë™ì—¬ë¶€']

            num = [
                'ì¼ë°˜ë‹´ë°°_ê³¼ê±°í¡ì—°ê¸°ê°„',
                'ì¼ë°˜ë‹´ë°°_í˜„ì¬í¡ì—°ê¸°ê°„',
                'ì•¡ìƒí˜•ì „ìë‹´ë°°_í˜„ì¬í¡ì—°ë¹ˆë„',
                'ê¶ë ¨í˜•ì „ìë‹´ë°°_í˜„ì¬í¡ì—°ëŸ‰',
                'ìŒì£¼ë¹ˆë„',
                'ìŒì£¼ëŸ‰',
                'ê³ ê°•ë„_ì‹ ì²´í™œë™ë¹ˆë„',
                'ê³ ê°•ë„_ì‹ ì²´í™œë™ì‹œê°„',
                'ì¤‘ê°•ë„_ì‹ ì²´í™œë™ë¹ˆë„',
                'ì¤‘ê°•ë„_ì‹ ì²´í™œë™ì‹œê°„',
                'ì €ê°•ë„_ì‹ ì²´í™œë™ë¹ˆë„',
                'ì €ê°•ë„_ì‹ ì²´í™œë™ì‹œê°„',
                'ê³ ê°•ë„_ìš´ë™ë¹ˆë„',
                'ê³ ê°•ë„_ìš´ë™ì‹œê°„',
                'ì¤‘ê°•ë„_ìš´ë™ë¹ˆë„',
                'ì¤‘ê°•ë„_ìš´ë™ì‹œê°„',
                'ìµœì¢…í•™ë ¥',
                'ê²°í˜¼ìƒíƒœ',
                'ê°€ê³„ìˆ˜ì…']

            # Function to get a combined view of past and current df
            def combined_status(patient_df, cat):
                cat_columns = [col for col in patient_df.columns if cat in col]
                combined_results = {}

                for disease in cat_columns:
                    if disease in patient_df.columns:
                        unique_vals = patient_df[disease].unique()
                        # Initialize an empty string to store check marks, crosses, or question marks in a stacked format
                        combined_results[disease] = ""

                        # Iterate through unique values
                        for val in unique_vals:
                            if pd.isna(val):  # Check if the value is NaN
                                combined_results[disease] += "â” "
                            elif val == 1:
                                combined_results[disease] += "âœ”ï¸ "
                            else:
                                combined_results[disease] += "âŒ "

                return combined_results

            # Display combined information
            def display_combined_info(combined_results):
                cols = st.columns(3)  # Create 3 columns to distribute the information
                for i, (disease, status) in enumerate(combined_results.items()):
                    cols[i % 3].markdown(f"**{disease}**: {status}")

            # Function to plot lab changes over multiple visits
            def plot_changes(patient_df, num):
                # Extract num columns (assuming num columns follow a specific naming pattern)
                num_columns = [col for col in patient_df.columns if num in col]
                num_df = []

                # Collect num df across visits
                for col in num_columns:
                    # Iterate through all rows (assuming each row represents a visit)
                    for i in range(len(patient_df)):
                        if pd.notna(patient_df[col].iloc[i]):
                            num_df.append((i + 1, patient_df[col].iloc[i]))  # (visit number, num value)

                # Plotting num changes
                if num_df:
                    visits, num_values = zip(*num_df)

                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=visits,
                        y=num_values,
                        mode='lines+markers',
                        name=num,
                        marker=dict(symbol='circle', size=10),
                    ))

                    fig.update_xaxes(title_text="Visits", dtick=1)
                    fig.update_yaxes(title_text=f"{num} Levels")

                    fig.update_layout(height=600, width=900, title_text=f"{num}", showlegend=False)

                    return fig
                else:
                    return None

            no_data_messages = []

            for col in cat:
                comorbidity_results = combined_status(patient_df, col)
                display_combined_info(comorbidity_results)

            for col in num:
                fig = plot_changes(patient_df, col)
                if fig:
                    st.plotly_chart(fig)

            # # Loop through columns and display the results for categorical and numerical data separately
            # for col in patient_df.columns if col == :
            #     if patient_df[col].nunique() == 2:  # Checking for categorical columns with two unique values
            #         if patient_df[col].isnull().all():  # Check if all values in the column are NaN
            #             no_data_messages.append(f"No meaningful data for {col} in this patient (all values are NaN).")
            #         else:
            #             comorbidity_results = combined_status(patient_df, col)
            #             display_combined_info(comorbidity_results)

            # for col in patient_df.columns:
            #     if patient_df[col].nunique() >= 3:  # Checking for numerical columns with three or more unique values
            #         fig = plot_changes(patient_df, col)
            #         if fig:
            #             st.plotly_chart(fig)
            #         else:
            #             no_data_messages.append(f"No {col} data available for this patient.")

            # Display all "No data available" messages if any
            if no_data_messages:
                for message in no_data_messages:
                    st.write(message)

        except Exception as e:
            st.write("íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:", e)

    elif page == "ğŸ“ í”¼ë´‡ ë³€í™˜":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ í”¼ë´‡ ë³€í™˜</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;í™˜ìì˜ ì—¬ëŸ¬ ë‚´ì› ê²°ê³¼ê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ì—´ ê¸°ë°˜ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("í™˜ìì˜ ì—¬ëŸ¬ ë‚´ì› ë°ì´í„°ê°€ í–‰ìœ¼ë¡œ ì¶•ì ë˜ì–´ìˆëŠ” ë°ì´í„° íŒŒì¼ì„ ì˜¬ë ¤ì£¼ì„¸ìš”.", type=["csv", "xlsx"])


        if uploaded_file is not None:
            # íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if st.session_state.uploaded_file != uploaded_file:
                    st.session_state.uploaded_file = uploaded_file
                    st.session_state.phrases_by_code = {}
                    st.session_state.text_input = ""
                    st.session_state.code_input = ""
                    st.session_state.coded_df = None  # Initialize session state for coded DataFrame

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file, engine='openpyxl')
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ í”¼ë´‡ ë³€í™˜")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì •ë³´ì…ë ¥</h4>", unsafe_allow_html=True)

                # ìœ ì €ì—ê²Œ í”¼ë²—í•  ê¸°ì¤€ ì—´ ì„ íƒ (selectboxì— '-- ì„ íƒ --' ì¶”ê°€)
                id_column = st.selectbox("í™˜ìë¥¼ êµ¬ë¶„í•  ID í˜¹ì€ RID ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", ["-- ì„ íƒ --"] + list(df.columns))
                if id_column == "-- ì„ íƒ --":
                    st.write(" ")
                    st.stop()

                date_column = st.selectbox("ë°©ë¬¸ì„ êµ¬ë¶„í•  Date ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", ["-- ì„ íƒ --"] + list(df.columns))
                if date_column == "-- ì„ íƒ --":
                    st.write(" ")
                    st.stop()

                # ë‚ ì§œ ë³€í™˜ ë° ì •ë ¬
                try:
                    # ë‚ ì§œ ë³€í™˜ ë° ìœ íš¨ì„± ê²€ì‚¬
                    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')  # Ensure valid date conversion

                    # ë³€í™˜ëœ ë‚ ì§œ ì—´ì˜ ìœ íš¨í•œ ë‚ ì§œ ê°œìˆ˜ í™•ì¸
                    if df[date_column].isnull().all():
                        st.error("ë‚ ì§œ ì—´ì— ê²°ì¸¡ê°’ì´ ì¡´ì¬í•˜ì—¬ ë³€í™˜ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()  # ë” ì´ìƒì˜ ì½”ë“œ ì‹¤í–‰ì„ ì¤‘ë‹¨
                    else:
                        # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ í–‰ ì‚­ì œ
                        df = df.dropna(subset=[date_column])  # Drop rows with invalid dates
                        df = df.sort_values(by=[id_column, date_column]).reset_index(drop=True)
                except Exception as e:
                    st.error("ë‚ ì§œ ì—´ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
                df = df.dropna(subset=[date_column])  # Drop rows with invalid dates
                df = df.sort_values(by=[id_column, date_column]).reset_index(drop=True)

                # ì—´ ë²ˆí˜¸ ë¶™ì´ê¸°
                df['row_number'] = df.groupby(id_column).cumcount() + 1
                df_pivot = df.pivot(index=id_column, columns='row_number')
                df_pivot.columns = [f"{col}_{num}" for col, num in df_pivot.columns]

                df_pivot.reset_index(inplace=True)

                # ê²°ê³¼ í‘œì‹œ
                st.divider()
                st.header("ğŸ“ í”¼ë´‡ ë³€í™˜ ê²°ê³¼", divider='rainbow')

                total_len = len(df)  # Total number of rows
                unique_len = df[id_column].nunique()  # Number of unique IDs (patients)

                # Counting the number of patients who visited once, twice, and three times
                visit_counts = df[id_column].value_counts()
                once_len = (visit_counts == 1).sum()
                twice_len = (visit_counts == 2).sum()
                third_len = (visit_counts == 3).sum()
                max_len = visit_counts.max()
                avg_len = round(visit_counts.mean(), 2)

                # Displaying the results using Streamlit markdown
                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- ì „ì²´ ë°ì´í„°ì—ëŠ” ì´ '{total_len:,}'ê°œì˜ í–‰ì´ ìˆìœ¼ë©°, ì´ ì¤‘ '{unique_len:,}'ëª…ì˜ í™˜ì ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- í•œ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{once_len:,}'ëª…, ë‘ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{twice_len:,}'ëª…, ì„¸ ë²ˆ ë‚´ì›í•œ í™˜ìëŠ” '{third_len:,}'ëª…ì…ë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                st.markdown(
                    f"<p style='font-size:16px; color:#0D47A1;'><strong>- í™˜ìì˜ ìµœëŒ€ ë‚´ì› íšŸìˆ˜ëŠ” '{max_len}'ì´ë©°, í‰ê·  ë‚´ì› íšŸìˆ˜ëŠ” '{avg_len}'íšŒì…ë‹ˆë‹¤.</strong></p>",
                    unsafe_allow_html=True
                )

                # Simulate a long-running process
                def long_running_process():
                    # Replace this loop with your actual computation or loading process
                    for i in range(100):
                        time.sleep(0.1)  # Example processing time for each step

                with st.spinner("Loading... 30ì´ˆ ê°€ëŸ‰ì˜ ë¡œë”©ì´ ì†Œìš”ë©ë‹ˆë‹¤."):
                    long_running_process()  # Run your process here instead of time.sleep()

                st.success("ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.df_pivot = df_pivot
                st.divider()
                st.markdown("<h4 style='color:grey;'>í”¼ë´‡ ë°ì´í„°</h4>", unsafe_allow_html=True)
                st.dataframe(df_pivot)

                # Initialize session state for df_pivot and button states if they are not already present
                if "df_pivot" not in st.session_state:
                    st.session_state.df_pivot = df_pivot  # Load df_pivot data if not already loaded
                if "filter_button_pressed" not in st.session_state:
                    st.session_state.filter_button_pressed = False
                if "download_button_pressed" not in st.session_state:
                    st.session_state.download_button_pressed = False
                if "download_filtered_button_pressed" not in st.session_state:
                    st.session_state.download_filtered_button_pressed = False

                # Display additional functionalities only if df_pivot is present in the session state
                if st.session_state.df_pivot is not None:
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ì¶”ê°€ ì‘ì—… ìˆ˜í–‰</h4>", unsafe_allow_html=True)

                    # Filter button in a row
                    if st.button("ì¬ì§„ í•„í„°ë§"):
                        # Update session state to indicate that the filter button was pressed
                        st.session_state.filter_button_pressed = True

                    # Filter functionality with dynamic column dropping if filter_button is pressed
                    if st.session_state.filter_button_pressed:
                        num = st.selectbox("ìµœëŒ€ ë‚´ì› íšŸìˆ˜ë¥¼ níšŒë¡œ ì§€ì •í•©ë‹ˆë‹¤.", ["-- ì„ íƒ --"] + list(range(1, max_len)))

                        if num != "-- ì„ íƒ --":
                            # Determine columns to keep based on the selected max visit count
                            columns_to_keep = [col for col in st.session_state.df_pivot.columns
                                            if not any(col.endswith(f"_{i}") for i in range(num + 1, max_len + 1))]

                            # Filter the DataFrame based on selected columns
                            df_pivot_filtered = st.session_state.df_pivot[columns_to_keep]
                            st.session_state.df_pivot_filtered = df_pivot_filtered

                            # Display the filtered DataFrame
                            st.dataframe(df_pivot_filtered, use_container_width=True)

                            export_format_filtered = st.radio("ë‹¤ìš´ë¡œë“œí•˜ì‹¤ ìë£Œ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”.", options=["CSV", "Excel"], key="export_format_filtered")

                            # Handle filtered data download
                            if export_format_filtered:
                                if export_format_filtered == "CSV":
                                    csv = st.session_state.df_pivot_filtered.to_csv(index=False).encode('utf-8')
                                    st.download_button(
                                        label="CSV ë‹¤ìš´ë¡œë“œ (í•„í„° ìë£Œ)",
                                        data=csv,
                                        file_name="pivot_data_filtered.csv",
                                        mime='text/csv'
                                    )
                                elif export_format_filtered == "Excel":
                                    buffer = BytesIO()
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        st.session_state.df_pivot_filtered.to_excel(writer, index=False)
                                    buffer.seek(0)
                                    st.download_button(
                                        label="Excel ë‹¤ìš´ë¡œë“œ (í•„í„° ìë£Œ)",
                                        data=buffer,
                                        file_name="pivot_data_filtered.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)

                    # Display the file format selection radio button for original data download
                    export_format_original = st.radio("ë‹¤ìš´ë¡œë“œí•˜ì‹¤ ìë£Œ íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”.", options=["CSV", "Excel"], key="export_format_original")

                    # Handle original data download
                    if export_format_original:
                        if export_format_original == "CSV":
                            csv = st.session_state.df_pivot.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv,
                                file_name="pivot_data.csv",
                                mime='text/csv'
                            )
                        elif export_format_original == "Excel":
                            buffer = BytesIO()
                            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                st.session_state.df_pivot.to_excel(writer, index=False)
                            buffer.seek(0)
                            st.download_button(
                                label="Excel ë‹¤ìš´ë¡œë“œ (ì›ë³¸ ìë£Œ)",
                                data=buffer,
                                file_name="pivot_data.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )

            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    elif page == "ğŸ“ íŒë…ë¬¸ ì½”ë”©":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ íŒë…ë¬¸ ì½”ë”©</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;íŒë…ë¬¸ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ì›í•˜ì‹œëŠ” ì½”ë”©ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ì„ í¬í•¨í•œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

        if uploaded_file is not None:
            # íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if st.session_state.uploaded_file != uploaded_file:
                    st.session_state.uploaded_file = uploaded_file
                    st.session_state.phrases_by_code = {}
                    st.session_state.text_input = ""
                    st.session_state.code_input = ""
                    st.session_state.coded_df = None  # Initialize session state for coded DataFrame

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ íŒë…ë¬¸ ì½”ë”©")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    # íŒë…ë¬¸ ì—´ ì„ íƒì°½
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ ì„ íƒ</h4>", unsafe_allow_html=True)
                    column_selected = st.selectbox("ì½”ë”©í•  íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ì„ ì„ íƒí•˜ì„¸ìš”.", options=df.columns)

                    # 'coding' ì—´ ì¶”ê°€
                    if 'coding' not in df.columns:
                        df['coding'] = np.nan  # ê¸°ë³¸ì ìœ¼ë¡œ nanìœ¼ë¡œ ì±„ì›€

                    # ì„ íƒëœ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…
                    st.session_state.df = df  # Ensure df is stored initially


                # Session state initialization for phrases (reset on new file upload)
                if 'phrases_by_code' not in st.session_state:
                    st.session_state.phrases_by_code = {}  # Session state to hold phrases and codes

                st.divider()
                st.header("ğŸ“ íŒë…ë¬¸ ì½”ë”©", divider='rainbow')
                st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;
                        font-size: 14px;
                        line-height: 1.4;
                        text-align: left;
                    }
                    </style>
                    <div class="custom-callout">
                        <p>í•˜ë‹¨ì— ì½”ë“œì™€ í•¨ê»˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ ì‹œ, í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ íŒë…ë¬¸ í–‰ì€ í•¨ê»˜ ì…ë ¥ëœ ì½”ë“œë¡œ ì½”ë”©ì´ ì´ë¤„ì§‘ë‹ˆë‹¤.</p>
                        <p> </p>
                        <p>ğŸ”” ì£¼ì˜!) ë¨¼ì € ì…ë ¥í•œ ì½”ë“œ ë‚´ìš©ë³´ë‹¤ ë’¤ì— ì…ë ¥í•œ ì½”ë“œ ë‚´ìš©ì— ë†’ì€ ìš°ì„ ìˆœìœ„ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤.</p>
                        <p>    - Case 1) ì½”ë“œ 1ê³¼ "disease1" ì…ë ¥ í›„, ì½”ë“œ 2ì™€ ë‹¤ì‹œ "disease1" ì…ë ¥: "disease1"ì´ í¬í•¨ëœ í–‰ì€ 2ë¡œ ì½”ë”©ë©ë‹ˆë‹¤.</p>
                        <p>    - Case 2) ì½”ë“œ 1ê³¼ "disease1" ì…ë ¥ í›„, ì½”ë“œ 2ì™€ "disease2" ì…ë ¥: "disease1, disease2" ëª¨ë‘ í¬í•¨ëœ í–‰ì€ 2ë¡œ ì½”ë”©ë©ë‹ˆë‹¤.</p>
                        </p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.write(" ")

                current_code = st.text_input("ì½”ë“œë¥¼ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”. (ex - 0, 1, 2)", key="code_input")

                if current_code:
                    current_code = int(current_code)  # Convert to integer code

                    # Check if current code already exists in session state
                    if current_code not in st.session_state.phrases_by_code:
                        st.session_state.phrases_by_code[current_code] = []  # Create a new list for this code if doesn't exist

                    # Define a callback function to handle text input
                    def add_text():
                        if st.session_state.text_input:
                            st.session_state.phrases_by_code[current_code].append(st.session_state.text_input)
                            st.session_state.text_input = ""  # Reset the input field

                    # Allow multiple text input with callback
                    st.text_input("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”.", key="text_input", on_change=add_text)

                # 4. ì…ë ¥ëœ ì½”ë”© ë° í…ìŠ¤íŠ¸ ëª©ë¡ í‘œì‹œ ë° ì‚­ì œ ê¸°ëŠ¥ ì¶”ê°€
                if st.session_state.phrases_by_code:
                    st.write(" ")
                    st.write(" ")
                    st.markdown("<h5>í˜„ì¬ ì…ë ¥ëœ ì½”ë“œ ë° í…ìŠ¤íŠ¸ ëª©ë¡ :</h5>", unsafe_allow_html=True)
                    for code, phrases in st.session_state.phrases_by_code.items():
                        st.markdown(f"<span style='color:red;'>ì½”ë“œ {code}ì— ëŒ€í•œ í…ìŠ¤íŠ¸:</span>", unsafe_allow_html=True)
                        # Create a dynamic list where phrases can be deleted
                        for phrase in phrases:
                            col1, col2 = st.columns([4, 1])
                            with col1:
                                st.markdown(f"<span style='color:red;'>- {phrase}</span>", unsafe_allow_html=True)
                            with col2:
                                if st.button(f"ì‚­ì œ", key=f"delete_{code}_{phrase}"):
                                    st.session_state.phrases_by_code[code].remove(phrase)  # Remove the phrase from the list
                                    # Force rerun by altering a session state value
                                    st.session_state["rerun_trigger"] = not st.session_state.get("rerun_trigger", False)

                # 5. ë¯¸ì²˜ë¦¬ í•­ëª©ì„ ìë™ìœ¼ë¡œ 0ìœ¼ë¡œ ì²˜ë¦¬ ë˜ëŠ” ë‹¤ë¥¸ ë°©ì‹ ì²˜ë¦¬
                st.divider()
                st.markdown("<h4 style='color:grey;'>ì½”ë”©ë˜ì§€ ì•Šì€ ê·¸ ì™¸ íŒë…ë¬¸ ì²˜ë¦¬ ë°©ë²•</h4>", unsafe_allow_html=True)

                # Use radio buttons to select between filling with 0 or missing
                fill_option = st.radio("ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”.", ("ì „ë¶€ 0ìœ¼ë¡œ", "ì „ë¶€ 99ë¡œ", "ì „ë¶€ ê³µë°±ìœ¼ë¡œ"))

                # 3. ì™„ë£Œ ë²„íŠ¼ - í…ìŠ¤íŠ¸ ì…ë ¥ í›„ í™œì„±í™”
                st.divider()
                st.markdown("<h4 style='color:grey;'>ì½”ë”© ì‘ì—… ì¢…ë£Œí•˜ê¸°</h4>", unsafe_allow_html=True)
                if current_code and st.session_state.phrases_by_code[current_code]:
                    if st.button("ì½”ë”© ì¢…ë£Œ"):
                        # Create a temporary lowercase column for matching
                        df = st.session_state.df.copy()  # Use session_state to preserve df between runs
                        df['lower_temp'] = df[column_selected].str.lower()

                        # Process the text for each code
                        for code, phrases in st.session_state.phrases_by_code.items():
                            for phrase in phrases:
                                # Match against the lowercase temporary column
                                df['coding'] = df['coding'].where(~df['lower_temp'].str.contains(phrase.lower(), na=False), code)

                        # Apply the appropriate fill method based on the radio selection
                        if fill_option == "ì „ë¶€ 0ìœ¼ë¡œ":
                            df['coding'].fillna(0, inplace=True)
                        elif fill_option == "ì „ë¶€ 99ë¡œ":
                            df['coding'].fillna(99, inplace=True)
                        elif fill_option == "ì „ë¶€ ê³µë°±":
                            df['coding'].fillna(np.nan, inplace=True)

                        # Drop the temporary column after coding
                        df.drop(columns=['lower_temp'], inplace=True)

                        # Store the coded DataFrame in session state
                        st.session_state.coded_df = df

                        with st.spinner("Loading..."):
                            time.sleep(5)  # Simulate loading time

                        # Display coding result
                        st.write("ì½”ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.dataframe(st.session_state.coded_df, use_container_width=True)

                    # 6. ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (Excel ë˜ëŠ” CSV)
                    if st.session_state.coded_df is not None:
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                        export_format = st.radio("íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”", options=["CSV", "Excel"])
                        if export_format == "CSV":
                            csv = st.session_state.coded_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv,
                                file_name="bc_table.csv",
                                mime='text/csv'
                            )
                        elif export_format == "Excel":
                            buffer = BytesIO()
                            try:
                                # Use ExcelWriter with openpyxl
                                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                    st.session_state.coded_df.to_excel(writer, index=False)

                                # Move the buffer's position back to the start
                                buffer.seek(0)

                                # Offer the download button for Excel
                                st.download_button(
                                    label="Excel ë‹¤ìš´ë¡œë“œ",
                                    data=buffer,
                                    file_name="bc_table.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            finally:
                                buffer.close()

            except ValueError as e:
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ“ˆ ì‹œê°í™”":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“ˆ ì‹œê°í™”</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ì‹œê°í™”í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write("")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("ì‹œê°í™”ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“ˆ ì‹œê°í™”")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Select visualization format
                    st.header("ğŸ“ˆ Univariable ë°ì´í„° ì‹œê°í™”", divider='rainbow')
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜: ì„±ë³„(ë‚¨/ì—¬), ì§ˆí™˜ë ¥(ìœ /ë¬´)ì™€ ê°™ì´ ê³ ìœ í•œ ê°’ì´ë‚˜ ë²”ì£¼ ìˆ˜ê°€ ì œí•œëœ ë³€ìˆ˜</p>
                        <p>- ì—°ì†í˜• ë³€ìˆ˜: í‚¤, ëª¸ë¬´ê²Œ, í˜ˆì•¡ê³¼ ê°™ì´ ìˆ«ìë¡œ ì¸¡ì •ë˜ë©°, ì¼ì • ë²”ìœ„ ì•ˆì—ì„œ ì–´ë– í•œ ê°’ë„ ì·¨í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                    st.text("")
                    st.text("")
                    plot_type = st.radio("ê·¸ë˜í”„ ì„ íƒ", ('ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart', 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot'))
                    st.text("")

                    # Creating visualizations using Plotlyif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                    # Convert to categorical data if necessary
                    # Create visualizations based on user's selection
                    if plot_type:  # ì‚¬ìš©ìê°€ ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•˜ë©´ ì‹¤í–‰
                        if plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                            # Convert to categorical data if necessary
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")

                            selected_column = st.selectbox("ì—´ ì„ íƒ", columns)
                            if selected_column != "-- ì„ íƒ --":
                                if df[selected_column].dtype != 'category':
                                    df[selected_column] = df[selected_column].astype('category')
                                # Data preparation
                                count_data = df[selected_column].value_counts().reset_index()
                                count_data.columns = [selected_column, 'Count']  # Specify appropriate column names
                                # Create Barplot
                                fig = px.bar(count_data,
                                            x=selected_column,
                                            y='Count',
                                            labels={selected_column: selected_column, 'Count': 'Count'},
                                            color_discrete_sequence=["#FFBDBD", "#BBDDEE"])  # Specify color
                                st.plotly_chart(fig)

                        elif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart':
                            # Convert to categorical data if necessary
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")

                            selected_column = st.selectbox("ì—´ ì„ íƒ", columns)
                            if selected_column != "-- ì„ íƒ --":
                                if df[selected_column].dtype != 'category':
                                    df[selected_column] = df[selected_column].astype('category')
                                # Data preparation
                                count_data = df[selected_column].value_counts().reset_index()
                                count_data.columns = [selected_column, 'Count']  # Specify appropriate column names
                                # Create Barplot
                                fig = px.pie(
                                    count_data,
                                    names=selected_column,  # Categories for the pie slices
                                    values='Count',         # Values (count) for the pie slices
                                    labels={selected_column: selected_column, 'Count': 'Count'},  # Optional: Custom labels
                                    color_discrete_sequence=["#FFBDBD", "#BBDDEE"]  # Specify color
                                )

                                # Display the plot
                                st.plotly_chart(fig)

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram':
                            # Check if the selected column is continuous
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")

                            selected_column = st.selectbox("ì—´ ì„ íƒ", columns)
                            if selected_column != "-- ì„ íƒ --":
                                if df[selected_column].dtype in ['int64', 'float64']:
                                    fig = ff.create_distplot([df[selected_column].dropna()], [selected_column], bin_size=0.1)
                                    fig.update_layout(showlegend=False)
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Histogramì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot':
                            # Check if the selected column is continuous
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")

                            selected_column = st.selectbox("ì—´ ì„ íƒ", columns)
                            if selected_column != "-- ì„ íƒ --":
                                if df[selected_column].dtype in ['int64', 'float64']:
                                    fig = px.box(df, x=selected_column, color_discrete_sequence=["#BBDDEE"])  # Specify color
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Boxplotì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        else:
                            st.write("ë¨¼ì € ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                    st.divider()

                        # Select visualization format
                    st.header("ğŸ“ˆ Multivariable ë°ì´í„° ì‹œê°í™”", divider='rainbow')
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜: ì„±ë³„(ë‚¨/ì—¬), ì§ˆí™˜ë ¥(ìœ /ë¬´)ì™€ ê°™ì´ ê³ ìœ í•œ ê°’ì´ë‚˜ ë²”ì£¼ ìˆ˜ê°€ ì œí•œëœ ë³€ìˆ˜</p>
                        <p>- ì—°ì†í˜• ë³€ìˆ˜: í‚¤, ëª¸ë¬´ê²Œ, í˜ˆì•¡ê³¼ ê°™ì´ ìˆ«ìë¡œ ì¸¡ì •ë˜ë©°, ì¼ì • ë²”ìœ„ ì•ˆì—ì„œ ì–´ë– í•œ ê°’ë„ ì·¨í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜</p>
                        <p>â­ ê·¸ë£¹ì—´ ë³€ìˆ˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                    st.text("")
                    st.text("")
                    plot_type = st.radio("ê·¸ë˜í”„ ì„ íƒ", ('ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot', 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart', 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram', 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot', 'ì—°ì†í˜• ë³€ìˆ˜: Correlation Heatmap'))
                    st.text("")

                    # Creating visualizations using Plotlyif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                    # Convert to categorical data if necessary
                    # Create visualizations based on user's selection
                    if plot_type:  # ì‚¬ìš©ìê°€ ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•˜ë©´ ì‹¤í–‰
                        if plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Barplot':
                            # Convert to categorical data if necessary
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")
                            selected_column_1 = st.selectbox("ì—´ ì„ íƒ", columns, key='categorical_variable')
                            selected_column_2 = st.selectbox("ê·¸ë£¹ì—´ ì„ íƒ", columns, key='group_variable')

                            if selected_column_1 != "-- ì„ íƒ --":
                                if df[selected_column_1].dtype != 'category':
                                    df[selected_column_1] = df[selected_column_1].astype('category')
                            if selected_column_2 != "-- ì„ íƒ --":
                                if df[selected_column_2].dtype != 'category':
                                    df[selected_column_2] = df[selected_column_2].astype('category')

                                # Create Barplot
                                    # Data preparation: Group by selected_column_2 and count selected_column_1
                                count_data = df.groupby([selected_column_2, selected_column_1]).size().reset_index(name='Count')
                                count_data = count_data.sort_values(by=selected_column_2)

                                # Create Barplot
                                fig = px.bar(
                                    count_data,
                                    x=selected_column_1,
                                    y='Count',
                                    color=selected_column_2,
                                    barmode='group',  # Change to 'group' for side-by-side bars
                                    labels={selected_column_1: selected_column_1, 'Count': 'Count'},
                                    color_discrete_sequence=px.colors.qualitative.Set2  # Use a qualitative color palette
                                )

                                # Hide the legend
                                fig.update_layout(showlegend=True)  # Hides the legend

                                # Display the plot
                                st.plotly_chart(fig)

                        elif plot_type == 'ë²”ì£¼í˜• ë³€ìˆ˜ : Pie chart':
                            # Convert to categorical data if necessary
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")
                            selected_column_1 = st.selectbox("ì—´ ì„ íƒ", columns, key='categorical_variable')
                            selected_column_2 = st.selectbox("ê·¸ë£¹ì—´ ì„ íƒ", columns, key='group_variable')

                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Data preparation: Group by selected_column_2 and count selected_column_1
                                count_data = df.groupby([selected_column_2, selected_column_1]).size().reset_index(name='Count')
                                count_data = count_data.sort_values(by=selected_column_2)

                                # Get unique values in selected_column_2 for separate pie charts
                                unique_groups = count_data[selected_column_2].unique()

                                # Create a pie chart for each unique group in selected_column_2
                                for group in unique_groups:
                                    group_data = count_data[count_data[selected_column_2] == group]

                                    # Create Pie Chart
                                    fig = px.pie(
                                        group_data,
                                        names=selected_column_1,  # Categories for the pie slices
                                        values='Count',            # Values for the pie chart
                                        title=f"{selected_column_2}ì—´ì˜ {group}ì— ëŒ€í•œ íŒŒì´ ì°¨íŠ¸",  # Title indicating the group
                                        color_discrete_sequence=px.colors.qualitative.Set2  # Use a qualitative color palette
                                    )

                                    # Display the plot
                                    st.plotly_chart(fig)

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Histogram':
                            # Check if the selected column is continuous
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")
                            selected_column_1 = st.selectbox("ì—´ ì„ íƒ", columns, key='continuous_variable')
                            selected_column_2 = st.selectbox("ê·¸ë£¹ì—´ ì„ íƒ", columns, key='group_variable')

                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Check if selected_column_1 is continuous
                                if df[selected_column_1].dtype in ['int64', 'float64']:
                                    # Check if selected_column_2 is categorical
                                    if df[selected_column_2].dtype != 'category':
                                        df[selected_column_2] = df[selected_column_2].astype('category')

                                    # Prepare data for distplot
                                    # Get sorted unique categories from selected_column_2
                                    sorted_categories = sorted(df[selected_column_2].cat.categories)

                                    data_to_plot = [
                                        df[df[selected_column_2] == category][selected_column_1].dropna().tolist()
                                        for category in sorted_categories
                                    ]

                                    # Create Distplot
                                    fig = ff.create_distplot(data_to_plot,
                                                            group_labels=sorted_categories,  # Use sorted categories for labels
                                                            bin_size=0.1)

                                    # Display the plot
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Histogramì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜ : Boxplot':
                            # Check if the selected column is continuous
                            columns = df.columns.tolist()
                            columns.insert(0, "-- ì„ íƒ --")
                            selected_column_1 = st.selectbox("ì—´ ì„ íƒ", columns, key='continuous_variable')
                            selected_column_2 = st.selectbox("ê·¸ë£¹ì—´ ì„ íƒ", columns, key='group_variable')

                            if selected_column_1 != "-- ì„ íƒ --" and selected_column_2 != "-- ì„ íƒ --":
                                # Check if selected_column_1 is continuous
                                if df[selected_column_1].dtype in ['int64', 'float64']:
                                    # Check if selected_column_2 is categorical
                                    if df[selected_column_2].dtype != 'category':
                                        df[selected_column_2] = df[selected_column_2].astype('category')

                                    sorted_categories = df[selected_column_2].cat.categories.tolist() if df[selected_column_2].dtype == 'category' else df[selected_column_2].unique().tolist()
                                    sorted_categories.sort()

                                    # Create Box Plot
                                    fig = px.box(
                                        df,
                                        x=selected_column_2,
                                        y=selected_column_1,
                                        color=selected_column_2,  # Color by selected_column_2
                                        color_discrete_sequence=px.colors.qualitative.Set2,  # Use a qualitative color palette
                                        title='Box Plot of {} by {}'.format(selected_column_1, selected_column_2),
                                        labels={selected_column_2: selected_column_2, selected_column_1: selected_column_1}  # Custom labels
                                    )

                                    # Sort the x-axis categories based on sorted_categories
                                    fig.update_layout(xaxis=dict(categoryorder='array', categoryarray=sorted_categories))

                                    # Display the plot
                                    st.plotly_chart(fig)
                                else:
                                    st.warning("Boxplotì€ ì—°ì†í˜• ë³€ìˆ˜ì— ì í•©í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

                        elif plot_type == 'ì—°ì†í˜• ë³€ìˆ˜: Correlation Heatmap':
                            # Select numerical columns for correlation
                            numeric_columns = [col for col in df.select_dtypes(include=['int64', 'float64']).columns if df[col].nunique() > 10]
                            if len(numeric_columns) > 1:
                                st.warning("íˆíŠ¸ë§µì€ ì—°ì†í˜• ë³€ìˆ˜ë§Œ ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. \n ê³ ìœ  ê°’ì´ 10ê°œ ì´í•˜ì¸ ë³€ìˆ˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ê°„ì£¼í•˜ì—¬ ìë™ ì œì™¸ë©ë‹ˆë‹¤.", icon="ğŸš¨")
                                corr = df[numeric_columns].corr()

                                # Plotly interactive correlation matrix
                                fig = px.imshow(round(corr, 3), text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
                                st.plotly_chart(fig)
                            else:
                                st.warning("íˆíŠ¸ë§µì„ êµ¬í˜„í•  ì—°ì†í˜• ë³€ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

                        else:
                            st.write("ë¨¼ì € ì‹œê°í™” ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

            except ValueError as e:
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ“Š íŠ¹ì„±í‘œ ì‚°ì¶œ":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ“Š íŠ¹ì„±í‘œ ì‚°ì¶œ</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("íŠ¹ì„±í‘œ ì‚°ì¶œì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.warning("ì—…ë¡œë“œ ì‹œ, ë‚ ì§œí˜• íƒ€ì…ì˜ ì—´ì€ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ì œì™¸ë©ë‹ˆë‹¤.", icon="ğŸš¨")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ“Š íŠ¹ì„±í‘œ ì‚°ì¶œ")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Select visualization format
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° Nìˆ˜ íŒŒì•…</h4>", unsafe_allow_html=True)
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” unique ê°’ì´ 3ê°œ ì´í•˜ì¸ ê²½ìš°ë¡œë§Œ íƒìƒ‰ë©ë‹ˆë‹¤.</p>
                        <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„  n(percentage) í˜•íƒœê°€, ì—°ì†í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„  mean[IQR] í˜•íƒœê°€ ë„ì¶œë©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )

                    def is_date_column(column):
                        """Function to determine if a column should be considered as a date column."""
                        return pd.api.types.is_datetime64_any_dtype(column) or pd.api.types.is_object_dtype(column) or column.name.lower().endswith("date")

                    def bs_count(sample):
                        # Categorical columns with 2 or 3 unique values, excluding potential date columns
                        cat_col = [col for col in sample.columns if sample[col].nunique() <= 3 and not is_date_column(sample[col])]

                        # Two unique values
                        cat_table2 = pd.DataFrame()
                        cat_col2 = [col for col in cat_col if sample[col].nunique() == 2]

                        for col in cat_col2:
                            counts = sample[col].value_counts().sort_index()
                            percentages = (sample[col].value_counts(normalize=True) * 100).round(1).sort_index()

                            for level in counts.index:
                                var_name = f"{col}_{level}"
                                count_value = counts[level]
                                percent_value = percentages[level]
                                merged_value = f"{count_value:,.0f} ({percent_value:.1f})"
                                cat_table2 = pd.concat([cat_table2, pd.DataFrame({'Variable': [var_name], 'Count': [merged_value]})], ignore_index=True)

                        # Three unique values
                        cat_table3 = pd.DataFrame()
                        cat_col3 = [col for col in cat_col if sample[col].nunique() == 3 and not is_date_column(sample[col])]

                        for col in cat_col3:
                            counts = sample[col].value_counts().sort_index()
                            percentages = (sample[col].value_counts(normalize=True) * 100).round(1).sort_index()

                            for level in counts.index:
                                var_name = f"{col}_{level}"
                                count_value = counts[level]
                                percent_value = percentages[level]
                                merged_value = f"{count_value:,.0f} ({percent_value:.1f})"
                                cat_table3 = pd.concat([cat_table3, pd.DataFrame({'Variable': [var_name], 'Count': [merged_value]})], ignore_index=True)

                        # Numerical values
                        num_table = pd.DataFrame(columns=['Variable', 'Count'])
                        num_col = [col for col in sample.columns if col not in cat_col and not is_date_column(sample[col])]

                        for col in num_col:
                            means = sample[col].mean()
                            iqr = sample[col].quantile(0.75) - sample[col].quantile(0.25)
                            num_table = pd.concat([num_table, pd.DataFrame({'Variable': [col], 'Count': ['{:,.1f} [{:,.1f}]'.format(means, iqr)]})], ignore_index=True)

                        # Combine all tables
                        final_tab = pd.concat([cat_table2, cat_table3, num_table], axis=0, ignore_index=True)

                        # Extract original column names without levels for merging
                        # for col in cat_col2 + cat_col3:
                            # final_tab.loc[final_tab['Variable'].str.startswith(col), 'Base_Col'] = final_tab['Variable'].str.rsplit('_',n=1).str[0]

                        # num_colì˜ ì»¬ëŸ¼ë“¤ì— ëŒ€í•´, Variable ê°’ ìì²´ë¥¼ Base_Colë¡œ ìœ ì§€
                        # for col in num_col:
                            # final_tab.loc[final_tab['Variable'] == col, 'Base_Col'] = col

                        return final_tab


                    def bs_res_count(sample, response_col):
                        # Ensure the response column is categorical with only two categories
                        if sample[response_col].dtype.name != 'category':
                            sample[response_col] = sample[response_col].astype('category')

                        if sample[response_col].nunique() != 2:
                            raise ValueError("ì„ íƒí•  ì¢…ì†ë³€ìˆ˜ê°€ 2ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì ¸ì•¼í•©ë‹ˆë‹¤.")

                        # Remove rows with missing response column values
                        sample = sample.dropna(subset=[response_col])

                        # Identify categorical columns based on the number of unique values and the data type
                        cat_col = [col for col in sample.columns if (sample[col].nunique() <= 3) and not is_date_column(sample[col])]
                        for col in cat_col:
                            sample[col] = sample[col].astype('category')

                        if response_col in cat_col:
                            cat_col.remove(response_col)

                        # Analysis for categorical columns
                        results_cat = []
                        for col in cat_col:
                            # Drop rows with missing values in the column
                            cat_sample = sample.dropna(subset=[col])

                            # Calculate counts and percentages grouped by the response column
                            counts = cat_sample.groupby([response_col, col]).size().unstack(fill_value=0)
                            percentages = counts.div(counts.sum(axis=1), axis=0) * 100

                            # Create a combined table with count and percentage
                            for level in counts.columns:
                                row_data = {
                                    'Variable': f"{col}_{level}",
                                    # 'Statistic': None,
                                    'P-value': None
                                }
                                for group in counts.index:
                                    count_value = counts.loc[group, level]
                                    percent_value = percentages.loc[group, level]
                                    row_data[f'{response_col}_{group}'] = f"{count_value:,} ({percent_value:.1f})"
                                results_cat.append(row_data)

                            # Chi-square test for association between the column and response variable
                            crosstab = pd.crosstab(cat_sample[col], cat_sample[response_col], margins=False)
                            if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:  # Ensure at least 2x2 table
                                chi2_stat, chi2_p = chi2_contingency(observed=crosstab, correction=False)[:2]
                                for row in results_cat:
                                    if row['Variable'].startswith(col):
                                        # row['Statistic'] = round(chi2_stat, 3)
                                        row['P-value'] = '<0.001' if chi2_p < 0.001 else round(chi2_p, 3)

                        # Analysis for numerical columns
                        results_num = []
                        num_col = [col for col in sample.columns if col not in cat_col + [response_col] and not is_date_column(sample[col])]
                        for col in num_col:
                            # Drop rows with missing values in the numerical column
                            num_sample = sample.dropna(subset=[col])

                            # Test for normality across both groups using Shapiro-Wilk test
                            normality_results = []
                            for category in num_sample[response_col].cat.categories:
                                group_data = num_sample[num_sample[response_col] == category][col].dropna()
                                if len(group_data) >= 3:
                                    normality_results.append(shapiro(group_data)[1])
                                else:
                                    normality_results.append(0)  # Consider non-normal if the group has less than 3 observations

                            is_normal = all(p > 0.05 for p in normality_results)

                            # Calculate mean and IQR grouped by the response column
                            group_stats = num_sample.groupby(response_col).agg(
                                mean=(col, 'mean'),
                                q1=(col, lambda x: x.quantile(0.25)),
                                q3=(col, lambda x: x.quantile(0.75))
                            )
                            group_stats['iqr'] = group_stats['q3'] - group_stats['q1']

                            row_data = {
                                'Variable': col,
                                # 'Statistic': None,
                                'P-value': None
                            }
                            for group in group_stats.index:
                                mean_value = group_stats.loc[group, 'mean']
                                iqr_value = group_stats.loc[group, 'iqr']
                                row_data[f'{response_col}_{group}'] = f"{mean_value:.1f} [{iqr_value:.1f}]"
                            results_num.append(row_data)

                            # Perform the appropriate test based on normality
                            groups = [num_sample[num_sample[response_col] == category][col].dropna() for category in num_sample[response_col].cat.categories]
                            if len(groups) == 2:  # Ensure there are exactly two groups for t-test
                                if is_normal:
                                    # Check for equal variances using Levene's test
                                    _, p_levene = levene(*groups)
                                    equal_var = p_levene > 0.05

                                    # Perform t-test if data is normally distributed
                                    t_stat, t_p = ttest_ind(*groups, equal_var=equal_var)
                                    # row_data['Statistic'] = round(t_stat, 3)
                                    row_data['P-value'] = '<0.001' if t_p < 0.001 else round(t_p, 3)
                                else:
                                    # Perform Mann-Whitney U test if data is not normally distributed
                                    u_stat, u_p = kruskal(*groups)  # Using Kruskal-Wallis with 2 groups as Mann-Whitney U alternative
                                    # row_data['Statistic'] = round(u_stat, 3)
                                    row_data['P-value'] = '<0.001' if u_p < 0.001 else round(u_p, 3)

                        # Combine results and create a DataFrame
                        final_results = pd.DataFrame(results_cat + results_num)

                        # Reorder columns to match the desired format
                        response_cols = [col for col in final_results.columns if col.startswith(response_col)]
                        final_results = final_results[['Variable'] + response_cols + ['P-value']]

                        return final_results

                    def bs_res_count3(sample, response_col):
                        # Ensure the response column is categorical with three categories
                        if sample[response_col].dtype.name != 'category':
                            sample[response_col] = sample[response_col].astype('category')

                        if sample[response_col].nunique() != 3:
                            raise ValueError("ì„ íƒí•  ì¢…ì†ë³€ìˆ˜ê°€ 3ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì ¸ì•¼í•©ë‹ˆë‹¤.")

                        # Remove rows with missing response column values
                        sample = sample.dropna(subset=[response_col])

                        # Identify categorical columns based on the number of unique values and the data type
                        cat_col = [col for col in sample.columns if (sample[col].nunique() <= 3) and not is_date_column(sample[col])]
                        for col in cat_col:
                            sample[col] = sample[col].astype('category')

                        if response_col in cat_col:
                            cat_col.remove(response_col)

                        # Analysis for categorical columns
                        results_cat = []
                        for col in cat_col:
                            # Drop rows with missing values in the column
                            cat_sample = sample.dropna(subset=[col])

                            # Calculate counts and percentages grouped by the response column
                            counts = cat_sample.groupby([response_col, col]).size().unstack(fill_value=0)
                            percentages = counts.div(counts.sum(axis=1), axis=0) * 100

                            # Create a combined table with count and percentage
                            for level in counts.columns:
                                row_data = {
                                    'Variable': f"{col}_{level}",
                                    'P-value': None
                                }
                                for group in counts.index:
                                    count_value = counts.loc[group, level]
                                    percent_value = percentages.loc[group, level]
                                    row_data[f'{response_col}_{group}'] = f"{count_value:,} ({percent_value:.1f})"
                                results_cat.append(row_data)

                            # Chi-square test for association between the column and response variable
                            crosstab = pd.crosstab(cat_sample[col], cat_sample[response_col], margins=False)
                            if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:  # Ensure at least 2x3 table
                                chi2_stat, chi2_p = chi2_contingency(observed=crosstab, correction=False)[:2]
                                for row in results_cat:
                                    if row['Variable'].startswith(col):
                                        row['P-value'] = '<0.001' if chi2_p < 0.001 else round(chi2_p, 3)

                        # Analysis for numerical columns
                        results_num = []
                        num_col = [col for col in sample.columns if col not in cat_col + [response_col] and not is_date_column(sample[col])]
                        for col in num_col:
                            # Drop rows with missing values in the numerical column
                            num_sample = sample.dropna(subset=[col])

                            # Test for normality across all groups using Shapiro-Wilk test
                            normality_results = []
                            for category in num_sample[response_col].cat.categories:
                                group_data = num_sample[num_sample[response_col] == category][col].dropna()
                                if len(group_data) >= 3:
                                    normality_results.append(shapiro(group_data)[1])
                                else:
                                    normality_results.append(0)  # Consider non-normal if the group has less than 3 observations

                            is_normal = all(p > 0.05 for p in normality_results)

                            # Calculate mean and IQR grouped by the response column
                            group_stats = num_sample.groupby(response_col).agg(
                                mean=(col, 'mean'),
                                q1=(col, lambda x: x.quantile(0.25)),
                                q3=(col, lambda x: x.quantile(0.75))
                            )
                            group_stats['iqr'] = group_stats['q3'] - group_stats['q1']

                            row_data = {
                                'Variable': col,
                                'P-value': None
                            }
                            for group in group_stats.index:
                                mean_value = group_stats.loc[group, 'mean']
                                iqr_value = group_stats.loc[group, 'iqr']
                                row_data[f'{response_col}_{group}'] = f"{mean_value:.1f} [{iqr_value:.1f}]"
                            results_num.append(row_data)

                            # Perform the appropriate test based on normality
                            groups = [num_sample[num_sample[response_col] == category][col].dropna() for category in num_sample[response_col].cat.categories]
                            if len(groups) == 3:  # Ensure there are exactly three groups for ANOVA or Kruskal-Wallis
                                if is_normal:
                                    # Check for equal variances using Levene's test
                                    _, p_levene = levene(*groups)
                                    equal_var = p_levene > 0.05

                                    # Perform ANOVA if data is normally distributed
                                    f_stat, anova_p = f_oneway(*groups)
                                    row_data['P-value'] = '<0.001' if anova_p < 0.001 else round(anova_p, 3)
                                else:
                                    # Perform Kruskal-Wallis test if data is not normally distributed
                                    kw_stat, kw_p = kruskal(*groups)
                                    row_data['P-value'] = '<0.001' if kw_p < 0.001 else round(kw_p, 3)

                        # Combine results and create a DataFrame
                        final_results = pd.DataFrame(results_cat + results_num)

                        # Reorder columns to match the desired format
                        response_cols = [col for col in final_results.columns if col.startswith(response_col)]
                        final_results = final_results[['Variable'] + response_cols + ['P-value']]

                        return final_results


                    # Function to merge bs_count and bs_char
                    def merge_results(count_result, char_result):
                        # Merge based on the last occurrence of '_'
                        merged_result = pd.merge(count_result, char_result, how='left', on='Variable')
                        # Drop the auxiliary 'Base_Col' used for merging
                        return merged_result

                    st.write(" ")
                    count = bs_count(df)
                    st.dataframe(count[['Variable', 'Count']], use_container_width=True)

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>íŠ¹ì„±í‘œ ìƒì„±</h4>", unsafe_allow_html=True)
                    st.header("ğŸ“Š íŠ¹ì„±í‘œ ìƒì„±", divider="rainbow")

                    # Let the user select whether the dependent variable has 2 or 3 categories
                    category_choice = st.radio(
                        "ì¢…ì†ë³€ìˆ˜ê°€ ëª‡ ê°œì˜ ë²”ì£¼ë¥¼ ê°€ì§€ëŠ”ì§€ ì„ íƒí•´ì£¼ì„¸ìš”.",
                        options=["2 ë²”ì£¼", "3 ë²”ì£¼"]
                    )
                    st.write()

                    if category_choice == "2 ë²”ì£¼":
                        st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;  /* Adjust padding */
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;  /* Font color */
                            font-size: 14px;  /* Font size */
                            line-height: 1.4; /* Line height */
                            text-align: left; /* Align text to the left */
                        }
                        </style>
                        <div class="custom-callout">
                            <p>- ì¢…ì†ë³€ìˆ˜ê°€ ê²°ì¸¡ì¸ í–‰ì€ ì œì™¸ í›„ countë©ë‹ˆë‹¤.</p>
                            <p>- ë“±ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Student t-ê²€ì •ì´ ì‚¬ìš©ë˜ë©°, ì´ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Welch's t-ê²€ì •ì´ ì ìš©ë©ë‹ˆë‹¤.</p>
                            <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— Chi-square ê²€ì •ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

                        </div>
                        """,
                        unsafe_allow_html=True
                        )
                        st.write(" ")
                        st.write(" ")

                        response_col = st.selectbox(
                            "í†µê³„ì  ìœ ì˜ì„±ì„ ë³¼ ì¢…ì†ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                            options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 2],
                            index=0
                        )

                        if response_col != "-- ì„ íƒ --":
                            char = bs_res_count(df, response_col)
                            st.dataframe(char, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ìµœì¢… íŠ¹ì„±í‘œ</h4>", unsafe_allow_html=True)
                            merged = merge_results(count, char)
                            st.dataframe(merged, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                            export_format = st.radio("íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”", options=["CSV", "Excel"])
                            if export_format == "CSV":
                                csv = merged.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name="bc_table.csv",
                                    mime='text/csv'
                                )
                            elif export_format == "Excel":
                                buffer = BytesIO()
                                try:
                                    # Use ExcelWriter with openpyxl
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        merged.to_excel(writer, index=False)

                                    # Move the buffer's position back to the start
                                    buffer.seek(0)

                                    # Offer the download button for Excel
                                    st.download_button(
                                        label="Excel ë‹¤ìš´ë¡œë“œ",
                                        data=buffer,
                                        file_name="bc_table.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                finally:
                                    buffer.close()
                        else:
                            st.write("")

                    elif category_choice == "3 ë²”ì£¼":
                        st.markdown(
                        """
                        <style>
                        .custom-callout {
                            background-color: #f9f9f9;
                            padding: 10px;  /* Adjust padding */
                            border-radius: 10px;
                            border: 1px solid #d3d3d3;
                            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                        }
                        .custom-callout p {
                            margin: 0;
                            color: #000000;  /* Font color */
                            font-size: 14px;  /* Font size */
                            line-height: 1.4; /* Line height */
                            text-align: left; /* Align text to the left */
                        }
                        </style>
                        <div class="custom-callout">
                            <p>- ì¢…ì†ë³€ìˆ˜ê°€ ê²°ì¸¡ì¸ í–‰ì€ ì œì™¸ í›„ countë©ë‹ˆë‹¤.</p>
                            <p>- ë“±ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— ANOVA ê²€ì •ì´ ì‚¬ìš©ë˜ë©°, ì´ë¶„ì‚°ì„±ì„ ê°–ëŠ” ì—°ì†í˜• ë³€ìˆ˜ì— Kruskal-Wallis ê²€ì •ì´ ì ìš©ë©ë‹ˆë‹¤.</p>
                            <p>- ë²”ì£¼í˜• ë³€ìˆ˜ì— Chi-square ê²€ì •ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.</p>

                        </div>
                        """,
                        unsafe_allow_html=True
                        )
                        st.write(" ")
                        st.write(" ")

                        response_col = st.selectbox(
                            "í†µê³„ì  ìœ ì˜ì„±ì„ ë³¼ ì¢…ì†ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                            options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 3],
                            index=0
                        )

                        if response_col != "-- ì„ íƒ --":
                            char = bs_res_count3(df, response_col)
                            st.dataframe(char, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ìµœì¢… íŠ¹ì„±í‘œ</h4>", unsafe_allow_html=True)
                            merged = merge_results(count, char)
                            st.dataframe(merged, use_container_width=True)

                            st.divider()
                            st.markdown("<h4 style='color:grey;'>íŠ¹ì„±í‘œ ë‹¤ìš´ë¡œë“œ</h4>", unsafe_allow_html=True)
                            export_format = st.radio("íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”", options=["CSV", "Excel"])
                            if export_format == "CSV":
                                csv = merged.to_csv(index=False).encode('utf-8')
                                st.download_button(
                                    label="CSV ë‹¤ìš´ë¡œë“œ",
                                    data=csv,
                                    file_name="bc_table.csv",
                                    mime='text/csv'
                                )
                            elif export_format == "Excel":
                                buffer = BytesIO()
                                try:
                                    # Use ExcelWriter with openpyxl
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        merged.to_excel(writer, index=False)

                                    # Move the buffer's position back to the start
                                    buffer.seek(0)

                                    # Offer the download button for Excel
                                    st.download_button(
                                        label="Excel ë‹¤ìš´ë¡œë“œ",
                                        data=buffer,
                                        file_name="bc_table.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                finally:
                                    buffer.close()
                        else:
                            st.write("")
            except ValueError as e:
                st.error(e)
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ”ƒ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ”ƒ ì¸ê³¼ê´€ê³„ ì¶”ë¡ </h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;íŒë…ë¬¸ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ì›í•˜ì‹œëŠ” ì½”ë”©ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # Track the uploaded file in session state to reset the UI when a new file is uploaded
        if 'uploaded_file' not in st.session_state:
            st.session_state.uploaded_file = None

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("íŒë…ë¬¸ í…ìŠ¤íŠ¸ ì—´ì„ í¬í•¨í•œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

        if uploaded_file is not None:
            # íŒŒì¼ì´ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if st.session_state.uploaded_file != uploaded_file:
                    st.session_state.uploaded_file = uploaded_file
                    st.session_state.phrases_by_code = {}
                    st.session_state.text_input = ""
                    st.session_state.code_input = ""
                    st.session_state.coded_df = None  # Initialize session state for coded DataFrame

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ”ƒ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    # íŒë…ë¬¸ ì—´ ì„ íƒì°½
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ê´€ê³„ë¥¼ ë³¼ ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                    column_selected = st.selectbox("ì¸ê³¼ê´€ê³„ë¥¼ ë³¼ ë³€ìˆ˜ ì—´ì„ ì„ íƒí•˜ì„¸ìš”.", options=df.columns)

                    # ì„ íƒëœ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…
                    st.session_state.df = df  # Ensure df is stored initially

                    def get_categorical_columns(df):
                        categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                        low_cardinality_numerical = [col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5]
                        return categorical_columns + low_cardinality_numerical

                    # Separate selections for continuous and categorical variables
                    continuous_columns = st.multiselect(
                        "- ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                        df.select_dtypes(include=['float64', 'int64']).columns,
                        key="continuous_columns_selection"
                    )

                    categorical_columns = st.multiselect(
                        "- ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                        get_categorical_columns(df),
                        key="categorical_columns_selection"
                    )

                    st.session_state.X_columns = continuous_columns + categorical_columns
                    if 'proceed_to_preprocessing' not in st.session_state:
                        st.session_state.proceed_to_preprocessing = False

                    # Add a button to confirm the selections
                    if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                        if (continuous_columns or categorical_columns):  # Ensure that y and at least one X is selected
                            st.session_state.continuous_columns = continuous_columns
                            st.session_state.categorical_columns = categorical_columns
                            st.session_state.proceed_to_preprocessing = True
                        else:
                            st.warning("ë³€ìˆ˜ë¥¼ í•œ ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.", icon="âš ï¸")

                    # Check if preprocessing should proceed
                    if st.session_state.proceed_to_preprocessing:
                        st.divider()
                        st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                        # Check missing values for continuous and categorical variables separately
                        for X_column in st.session_state.continuous_columns:
                            X_missing_count = df[X_column].isna().sum()
                            st.markdown(
                                f"<p style='font-size:16px; color:firebrick;'><strong>ì„ íƒëœ ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜ '{X_column}'ì— ê²°ì¸¡ì´ {X_missing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.</strong></p>",
                                unsafe_allow_html=True
                            )

                        for X_column in st.session_state.categorical_columns:
                            X_missing_count = df[X_column].isna().sum()
                            st.markdown(
                                f"<p style='font-size:16px; color:firebrick;'><strong>ì„ íƒëœ ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ '{X_column}'ì— ê²°ì¸¡ì´ {X_missing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.</strong></p>",
                                unsafe_allow_html=True
                            )

                        # Function to handle missing values
                        def handle_missing_values(df, columns, strategies):
                            for column, strategy in strategies.items():
                                if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                    df = df.dropna(subset=[column])
                                elif strategy in ['í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´']:
                                    impute_strategy = {
                                        'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                        'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                        'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                    }[strategy]
                                    imputer = SimpleImputer(strategy=impute_strategy)
                                    df[[column]] = imputer.fit_transform(df[[column]])
                            return df

                        # Synchronize indexes between continuous and categorical data
                        def synchronize_indexes(X_continuous, X_categorical):
                            shared_indexes = X_continuous.index.intersection(X_categorical.index)
                            return X_continuous.loc[shared_indexes], X_categorical.loc[shared_indexes]

                        # Separate continuous and categorical columns
                        X_continuous = df[st.session_state.continuous_columns]
                        X_categorical = df[st.session_state.categorical_columns]

                        # Check for missing values
                        continuous_missing = X_continuous.isnull().any().any()
                        categorical_missing = X_categorical.isnull().any().any()

                        if not continuous_missing and not categorical_missing:
                            st.markdown(
                                f"<p style='font-size:16px;'><strong>ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</strong></p>",
                                unsafe_allow_html=True
                            )

                        else:
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì „ì²˜ë¦¬</h4>", unsafe_allow_html=True)

                            # Missing value strategies for continuous columns
                            continuous_missing_value_strategies = {}
                            for column in st.session_state.continuous_columns:
                                if df[column].isnull().any():
                                    n = df[column].isna().sum()
                                    strategy = st.selectbox(
                                        f"- âš ï¸ ì„ íƒí•˜ì‹  ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì— {n}ê°œì˜ ê²°ì¸¡ì´ ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        continuous_missing_value_strategies[column] = strategy

                            # Missing value strategies for categorical columns
                            categorical_missing_value_strategies = {}
                            for column in st.session_state.categorical_columns:
                                if df[column].isnull().any():
                                    n = df[column].isna().sum()
                                    strategy = st.selectbox(
                                        f"- âš ï¸ ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì— {n}ê°œì˜ ê²°ì¸¡ì´ ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                        ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                        key=f"{column}_strategy"
                                    )
                                    if strategy != '-- ì„ íƒ --':
                                        categorical_missing_value_strategies[column] = strategy

                            # Apply missing value strategies
                            if continuous_missing_value_strategies:
                                X_continuous = handle_missing_values(X_continuous, st.session_state.continuous_columns, continuous_missing_value_strategies)

                            if categorical_missing_value_strategies:
                                X_categorical = handle_missing_values(X_categorical, st.session_state.categorical_columns, categorical_missing_value_strategies)

                            # Synchronize indexes between X_continuous and X_categorical
                            X_continuous, X_categorical = synchronize_indexes(X_continuous, X_categorical)

                        st.divider()
                        st.header("ğŸ”ƒ ì¸ê³¼ê´€ê³„ ì¶”ë¡ ", divider="rainbow")

                        # Example: Combine continuous and categorical data
                        X = pd.concat([X_continuous, X_categorical], axis=1)

                        # Step 1: Run the PC algorithm to learn causal structure
                        cg = pc(X.to_numpy(), alpha=0.05)

                        # Step 2: Extract causal edges
                        def extract_edges(causal_graph, column_names):
                            edges = []
                            for i in range(len(causal_graph)):
                                for j in range(len(causal_graph)):
                                    if causal_graph[i, j] == 1:  # Direction i â†’ j
                                        edges.append((column_names[i], column_names[j]))
                                    elif causal_graph[i, j] == -1:  # Direction j â†’ i
                                        edges.append((column_names[j], column_names[i]))
                            return edges

                        edges = extract_edges(cg.G.graph, X.columns)

                        # Step 3: Create a NetworkX graph
                        causal_graph = nx.DiGraph()
                        causal_graph.add_edges_from(edges)

                        # Step 4: Visualize the graph with proper padding
                        def visualize_graph(graph, seed=None, padding_ratio=0.05):
                            # Generate positions for nodes
                            pos = nx.spring_layout(graph, seed=seed)

                            # Extract node positions and edges
                            edge_x = []
                            edge_y = []
                            annotations = []

                            for edge in graph.edges():
                                x0, y0 = pos[edge[0]]  # Start node position
                                x1, y1 = pos[edge[1]]  # End node position

                                # Calculate vector components and length
                                dx, dy = x1 - x0, y1 - y0
                                dist = (dx**2 + dy**2)**0.5

                                # Apply padding to both start and end points
                                x0_padded = x0 + dx * padding_ratio / dist
                                y0_padded = y0 + dy * padding_ratio / dist
                                x1_padded = x1 - dx * padding_ratio / dist
                                y1_padded = y1 - dy * padding_ratio / dist

                                # Add edges for visual reference
                                edge_x.append(x0_padded)
                                edge_x.append(x1_padded)
                                edge_x.append(None)
                                edge_y.append(y0_padded)
                                edge_y.append(y1_padded)
                                edge_y.append(None)

                                # Add arrow annotations for direction
                                annotations.append(
                                    dict(
                                        ax=x0_padded, ay=y0_padded,  # Adjusted start point
                                        x=x1_padded, y=y1_padded,  # Adjusted end point
                                        xref="x", yref="y",
                                        axref="x", ayref="y",
                                        showarrow=True,
                                        arrowhead=3,  # Arrow style
                                        arrowsize=1.5,  # Arrow size
                                        arrowwidth=1.5,  # Arrow line width
                                        arrowcolor="gray"
                                    )
                                )

                            # Create edge traces
                            edge_trace = go.Scatter(
                                x=edge_x,
                                y=edge_y,
                                line=dict(width=1.5, color='gray'),
                                hoverinfo='none',
                                mode='lines'
                            )

                            # Create node traces
                            node_x = []
                            node_y = []
                            node_text = []
                            for node in graph.nodes():
                                x, y = pos[node]
                                node_x.append(x)
                                node_y.append(y)
                                node_text.append(node)

                            node_trace = go.Scatter(
                                x=node_x,
                                y=node_y,
                                mode='markers+text',
                                text=node_text,
                                textfont=dict(family='Times New Roman', size=12, color='darkblue'),
                                marker=dict(
                                    size=30,
                                    color='lightblue',
                                    line=dict(width=2, color='darkblue')
                                ),
                                hoverinfo='text'
                            )

                            # Combine traces
                            fig = go.Figure(data=[edge_trace, node_trace])

                            # Add arrow annotations for edges
                            fig.update_layout(
                                showlegend=False,
                                title_text="Causal Graph with Padded Nodes and Arrows",
                                title_font=dict(family="Times New Roman", size=20, color="darkblue"),
                                margin=dict(l=40, r=40, t=40, b=40),
                                xaxis=dict(showgrid=False, zeroline=False),
                                yaxis=dict(showgrid=False, zeroline=False),
                                annotations=annotations  # Add arrows
                            )

                            # Display the graph in Streamlit
                            st.plotly_chart(fig)

                        # Visualize the graph
                        if "random_seed" not in st.session_state:
                            st.session_state.random_seed = 99  # Default seed

                        visualize_graph(causal_graph, seed=st.session_state.random_seed)

                        # Add a regenerate button to update the layout
                        if st.button("Regenerate Layout"):
                            st.session_state.random_seed = None  # Clear the seed for a new random layout
                            visualize_graph(causal_graph, seed=st.session_state.random_seed)

                        # hc = HillClimbSearch(X)
                        # model = hc.estimate(scoring_method=BicScore(X))  # Bayesian Information Criterion (BIC)

                        # # Display learned edges
                        # st.write("Learned Causal Edges:", model.edges())

                        # # Step 5: Create the causal graph
                        # causal_graph = nx.DiGraph(model.edges)

                        # # Step 6: Visualize the graph using matplotlib
                        # plt.figure(figsize=(10, 8))
                        # plt.rc('font', family='Times New Roman')  # Set font globally
                        # pos = nx.spring_layout(causal_graph, seed=42)  # Generate positions for nodes
                        # nx.draw(
                        #     causal_graph, pos, with_labels=True,
                        #     node_size=3000,  # Node size
                        #     node_color="lightblue",  # Node color
                        #     font_size=12,  # Node label font size
                        #     font_color="darkblue",  # Node label color
                        #     edge_color="gray",  # Edge color
                        #     arrowsize=20,  # Arrow size
                        #     width=2  # Edge thickness
                        # )

                        # # Add edge labels
                        # edge_labels = {(edge[0], edge[1]): f"{edge[0]}â†’{edge[1]}" for edge in causal_graph.edges}
                        # nx.draw_networkx_edge_labels(causal_graph, pos, edge_labels=edge_labels, font_size=10)

                        # # Add a title
                        # plt.title("Causal Graph Discovered from X", fontsize=18, color="darkblue", pad=20)

                        # # Step 7: Display the graph in Streamlit
                        # st.pyplot(plt)


            except ValueError as e:
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„":
        st.markdown(
        """
        <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
            <h2 style="color: #000000;">ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„</h2>
            <p style="font-size:18px; color: #000000;">
            &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
            </p>
        </div>
        """,
        unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        st.warning("ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë²”ì£¼í˜• íƒ€ì…ì˜ ì¢…ì†ë³€ìˆ˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.", icon="ğŸš¨")
        uploaded_file = st.file_uploader("ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        xls = pd.ExcelFile(uploaded_file)
                        sheet_names = xls.sheet_names

                        # ì‹œíŠ¸ ì„ íƒ ì˜µì…˜ì— "-- ì„ íƒ --" ì¶”ê°€
                        if len(sheet_names) > 1:
                            sheet = st.selectbox('ì—…ë¡œë“œí•˜ì‹  íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ìš©í•˜ì‹¤ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.', ["-- ì„ íƒ --"] + sheet_names)

                            # "-- ì„ íƒ --"ì¸ ê²½ìš° ë™ì‘ ì¤‘ë‹¨
                            if sheet == "-- ì„ íƒ --":
                                st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨
                            else:
                                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                        elif len(sheet_names) == 1:
                            # ì‹œíŠ¸ê°€ 1ê°œë§Œ ìˆëŠ” ê²½ìš°
                            df = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
                        else:
                            st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            st.stop()

                if 'df' in locals():

                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Variable selection section
                    st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                    st.markdown(
                    """
                    <style>
                    .custom-callout {
                        background-color: #f9f9f9;
                        padding: 10px;  /* Adjust padding */
                        border-radius: 10px;
                        border: 1px solid #d3d3d3;
                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                    }
                    .custom-callout p {
                        margin: 0;
                        color: #000000;  /* Font color */
                        font-size: 14px;  /* Font size */
                        line-height: 1.4; /* Line height */
                        text-align: left; /* Align text to the left */
                    }
                    </style>
                    <div class="custom-callout">
                        <p>- ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì€ ì¢…ì†ë³€ìˆ˜(y)ê°€ ë²”ì£¼í˜• ë³€ìˆ˜ì¼ ê²½ìš° ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
                        <p>- ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ëŠ” unique ê°’ì´ 5ê°œ ë¯¸ë§Œì¸ ë³€ìˆ˜ë“¤ë¡œë§Œ ì¸ì‹ë©ë‹ˆë‹¤.</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                    )
                    st.write(" ")

                    # Initialize session state for variables and processing states
                    if 'y_column' not in st.session_state:
                        st.session_state.y_column = None
                    if 'X_columns' not in st.session_state:
                        st.session_state.X_columns = []
                    if 'proceed_to_preprocessing' not in st.session_state:
                        st.session_state.proceed_to_preprocessing = False

                    y_column = st.selectbox(
                        "ì¢…ì†ë³€ìˆ˜(y)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                        options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() == 2],
                        index=0
                    )

                    def get_categorical_columns(df):
                        categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                        low_cardinality_numerical = [col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5]
                        return categorical_columns + low_cardinality_numerical

                    # ì¢…ì†ë³€ìˆ˜(y)ê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ ì„¤ëª…ë³€ìˆ˜ ì„ íƒ ì°½ í‘œì‹œ
                    if y_column != "-- ì„ íƒ --":
                        st.session_state.y_column = y_column

                        # Separate selections for continuous and categorical variables
                        continuous_columns = st.multiselect(
                            "- ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                            df.select_dtypes(include=['float64', 'int64']).columns,
                            key="continuous_columns_selection"
                        )

                        categorical_columns = st.multiselect(
                            "- ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                            get_categorical_columns(df),
                            key="categorical_columns_selection"
                        )

                        st.session_state.X_columns = continuous_columns + categorical_columns

                        # Add a button to confirm the selections
                        if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                            if y_column and (continuous_columns or categorical_columns):  # Ensure that y and at least one X is selected
                                st.session_state.y_column = y_column
                                st.session_state.continuous_columns = continuous_columns
                                st.session_state.categorical_columns = categorical_columns
                                st.session_state.proceed_to_preprocessing = True
                            else:
                                st.warning("ì¢…ì†ë³€ìˆ˜ì™€ ì„¤ëª…ë³€ìˆ˜ë¥¼ í•œ ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.", icon="âš ï¸")

                        # Check if preprocessing should proceed
                        if st.session_state.proceed_to_preprocessing:
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)
                            st.markdown(
                            """
                            <style>
                            .custom-callout {
                                background-color: #f9f9f9;
                                padding: 10px;  /* Adjust padding */
                                border-radius: 10px;
                                border: 1px solid #d3d3d3;
                                box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                            }
                            .custom-callout p {
                                margin: 0;
                                color: #000000;  /* Font color */
                                font-size: 14px;  /* Font size */
                                line-height: 1.4; /* Line height */
                                text-align: left; /* Align text to the left */
                            }
                            </style>
                            <div class="custom-callout">
                                <p>- ì„ íƒí•˜ì‹  ì¢…ì†ë³€ìˆ˜(y)ì— ê²°ì¸¡ê°’ì´ ì¡´ì¬í•œë‹¤ë©´, í•´ë‹¹ í–‰ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.</p>
                            </div>
                            """,
                            unsafe_allow_html=True
                            )
                            st.write(" ")

                            # Display missing value check for the dependent variable
                            y_missing_count = df[st.session_state.y_column].isna().sum()
                            st.markdown(
                                f"<p style='font-size:16px; color:red;'><strong>ì„ íƒëœ ì¢…ì†ë³€ìˆ˜ '{st.session_state.y_column}'ì— ê²°ì¸¡ì´ {y_missing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.</strong></p>",
                                unsafe_allow_html=True
                            )

                            # Check missing values for continuous and categorical variables separately
                            for X_column in st.session_state.continuous_columns:
                                X_missing_count = df[X_column].isna().sum()
                                st.markdown(
                                    f"<p style='font-size:16px; color:firebrick;'><strong>ì„ íƒëœ ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜ '{X_column}'ì— ê²°ì¸¡ì´ {X_missing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.</strong></p>",
                                    unsafe_allow_html=True
                                )

                            for X_column in st.session_state.categorical_columns:
                                X_missing_count = df[X_column].isna().sum()
                                st.markdown(
                                    f"<p style='font-size:16px; color:firebrick;'><strong>ì„ íƒëœ ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ '{X_column}'ì— ê²°ì¸¡ì´ {X_missing_count}ê°œ ì¡´ì¬í•©ë‹ˆë‹¤.</strong></p>",
                                    unsafe_allow_html=True
                                )

                            # Drop rows with missing values in the dependent variable (y)
                            df = df.dropna(subset=[st.session_state.y_column])

                            # Separate continuous and categorical columns
                            X_continuous = df[st.session_state.continuous_columns]
                            X_categorical = df[st.session_state.categorical_columns]
                            y = df[st.session_state.y_column]

                            if not X_continuous.isnull().any().any() and not X_categorical.isnull().any().any():
                                st.markdown(
                                    f"<p style='font-size:16px;'><strong>ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</strong></p>",
                                    unsafe_allow_html=True
                                )

                            else:

                                st.divider()
                                st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì „ì²˜ë¦¬</h4>", unsafe_allow_html=True)

                                # Handling missing value strategies for continuous columns
                                continuous_missing_value_strategies = {}
                                for column in st.session_state.continuous_columns:
                                    if df[column].isnull().any():
                                        n = df[column].isna().sum()
                                        strategy = st.selectbox(
                                            f"- âš ï¸ ì„ íƒí•˜ì‹  ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì— {n}ê°œì˜ ê²°ì¸¡ì´ ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                            ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                            key=f"{column}_strategy"
                                        )
                                        if strategy != '-- ì„ íƒ --':
                                            continuous_missing_value_strategies[column] = strategy

                                # Handling missing value strategies for categorical columns
                                categorical_missing_value_strategies = {}
                                for column in st.session_state.categorical_columns:
                                    if df[column].isnull().any():
                                        n = df[column].isna().sum()
                                        strategy = st.selectbox(
                                            f"- âš ï¸ ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì— {n}ê°œì˜ ê²°ì¸¡ì´ ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                            ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                            key=f"{column}_strategy"
                                        )
                                        if strategy != '-- ì„ íƒ --':
                                            categorical_missing_value_strategies[column] = strategy

                                # Apply missing value strategies for continuous columns
                                for column, strategy in continuous_missing_value_strategies.items():
                                    if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                        X_continuous = X_continuous.dropna(subset=[column])
                                    elif strategy in ['í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´']:
                                        impute_strategy = {
                                            'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                            'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                            'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                        }[strategy]
                                        imputer = SimpleImputer(strategy=impute_strategy)
                                        X_continuous[[column]] = imputer.fit_transform(X_continuous[[column]])

                                # Ensure continuous columns are numeric
                                for column in X_continuous.columns:
                                    X_continuous[column] = pd.to_numeric(X_continuous[column], errors='coerce')
                                    X_continuous[column] = X_continuous[column].astype(float)

                                # Apply missing value strategies for categorical columns
                                for column, strategy in categorical_missing_value_strategies.items():
                                    if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                        X_categorical = X_categorical.dropna(subset=[column])
                                    elif strategy == 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´':
                                        imputer = SimpleImputer(strategy='most_frequent')
                                        X_categorical[[column]] = imputer.fit_transform(X_categorical[[column]])

                                # Synchronize index changes between X_continuous, X_categorical, and y
                                shared_indexes = X_continuous.index.intersection(X_categorical.index)
                                X_continuous = X_continuous.loc[shared_indexes]
                                X_categorical = X_categorical.loc[shared_indexes]
                                y = y.loc[shared_indexes]

                            # Check for missing or infinite values in combined data
                            if st.button('ëª¨ë¸ í•™ìŠµ ì‹œì‘', key='train_model_button'):
                                # Handle categorical variables with pd.get_dummies
                                st.divider()
                                st.header('ğŸ’» ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ ê²°ê³¼', divider='rainbow')
                                X_categorical = pd.get_dummies(X_categorical, drop_first=True)

                                # Check and handle boolean columns if they exist
                                for column in X_categorical.columns:
                                    if X_categorical[column].dtype == 'bool':  # Only map if the column is of boolean type
                                        X_categorical[column] = X_categorical[column].map({True: 1, False: 0})

                                # Ensure all columns in X_categorical are integers
                                X_categorical = X_categorical.astype(int, errors='ignore')

                                # Combine continuous and categorical columns
                                X = pd.concat([X_continuous, X_categorical], axis=1)

                                # Ensure that combined X does not have object or mixed types
                                X = X.apply(pd.to_numeric, errors='coerce')

                                if X.isnull().values.any():
                                    st.error("ì „ì²˜ë¦¬ í›„ì—ë„ ì„¤ëª…ë³€ìˆ˜ì— ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                elif np.isinf(X).values.any():
                                    st.error("ì „ì²˜ë¦¬ í›„ ì„¤ëª…ë³€ìˆ˜ì— ë¬´í•œ ê°’ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ë°ì´í„° ì •ê·œí™”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                else:
                                    try:
                                        # Split the data
                                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                                        # Add constant (intercept) to the features
                                        X_train_const = sm.add_constant(X_train)
                                        X_test_const = sm.add_constant(X_test)

                                        # Final checks for NaN or infinite values before fitting the model
                                        if X_train_const.isnull().values.any() or np.isinf(X_train_const).values.any():
                                            st.error("ëª¨ë¸ í•™ìŠµ ë°ì´í„°ì— NaN ë˜ëŠ” ë¬´í•œ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        elif X_test_const.isnull().values.any() or np.isinf(X_test_const).values.any():
                                            st.error("ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— NaN ë˜ëŠ” ë¬´í•œ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        else:
                                            # Logistic regression model using statsmodels
                                            model = sm.Logit(y_train, X_train_const)
                                            result = model.fit()

                                            # Predictions
                                            y_pred_prob = result.predict(X_test_const)
                                            y_pred_class = (y_pred_prob >= 0.5).astype(int)

                                        # Display model summary
                                        # st.markdown("<h3 style='font-size:14px;'>Model Results:</h3>", unsafe_allow_html=True)
                                        # Assuming result is a statsmodels results object
                                        summary_html = result.summary().as_html()

                                        # Display the summary as HTML
                                        # summary_df = result.summary().tables[1]
                                        # st.dataframe(summary_df)

                                        st.markdown(summary_html, unsafe_allow_html=True)
                                        st.write(" ")
                                        st.write("---")

                                        st.markdown("<h4 style='font-size:14px;'>Model OR & P-value:</h4>", unsafe_allow_html=True)
                                        summary_table = result.summary2().tables[1]  # Get the detailed table
                                        summary_df = summary_table[['Coef.', 'P>|z|', '[0.025', '0.975]']]  # Extract Coefficient, p-value, and Confidence Intervals

                                        # Calculate Odds Ratio (OR) as the exponential of the coefficient
                                        summary_df['OR'] = np.exp(summary_df['Coef.'])
                                        summary_df['95% CI Lower'] = np.exp(summary_df['[0.025'])
                                        summary_df['95% CI Upper'] = np.exp(summary_df['0.975]'])

                                        # Rename columns for clarity
                                        summary_df = summary_df.rename(columns={'P>|z|': 'P-value'})

                                        # Replace P-values equal to 0 with "<0.001"
                                        summary_df['P-value'] = summary_df['P-value'].apply(lambda x: '<0.001' if x == 0 else round(x, 4))

                                        # Rearrange columns to include OR, Coefficient, P-value, and Confidence Interval
                                        summary_df = summary_df[['OR', '95% CI Lower', '95% CI Upper', 'P-value']]
                                        st.dataframe(summary_df, use_container_width=True)

                                        # AUC Curve
                                        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
                                        roc_auc = auc(fpr, tpr)

                                        # Create a Plotly figure for ROC Curve
                                        fig_roc = go.Figure()

                                        # Add ROC curve line
                                        fig_roc.add_trace(go.Scatter(
                                            x=fpr, y=tpr,
                                            mode='lines',
                                            name=f'ROC curve (area = {roc_auc:.2f})',
                                            line=dict(color='darkorange', width=2)
                                        ))

                                        # Add diagonal line
                                        fig_roc.add_trace(go.Scatter(
                                            x=[0, 1], y=[0, 1],
                                            mode='lines',
                                            line=dict(color='navy', width=2, dash='dash'),
                                            showlegend=False
                                        ))

                                        # Update layout for Plotly figure
                                        fig_roc.update_layout(
                                            title="ROC Curve",
                                            xaxis_title="False Positive Rate",
                                            yaxis_title="True Positive Rate",
                                            legend=dict(x=0.4, y=0),
                                            width=600, height=600  # Adjust dimensions as per your requirement
                                        )

                                        # Display the Plotly figure in Streamlit
                                        st.plotly_chart(fig_roc)

                                        # Create confusion matrix
                                        cm = confusion_matrix(y_test, y_pred_class)

                                        # Create a Plotly heatmap for confusion matrix
                                        fig_cm = ff.create_annotated_heatmap(
                                            z=cm,
                                            x=['Predicted Negative', 'Predicted Positive'],
                                            y=['Actual Negative', 'Actual Positive'],
                                            colorscale='Blues',
                                            showscale=False,
                                            annotation_text=[[str(value) for value in row] for row in cm]  # Add annotations with values
                                        )

                                        # Update annotations to change font size
                                        for annotation in fig_cm.layout.annotations:
                                            annotation.font.size = 16  # Adjust font size
                                            annotation.font.color = "black"  # Change font color for better contrast

                                        # Update layout for the confusion matrix
                                        fig_cm.update_layout(
                                            title="Confusion Matrix",
                                            width=600, height=600  # Adjust dimensions as per your requirement
                                        )

                                        # Display the Plotly heatmap in Streamlit
                                        st.plotly_chart(fig_cm)

                                        # Classification Report
                                        st.markdown("<h5 style='font-size:14px;'>Classification Report:</h5>", unsafe_allow_html=True)
                                        report = classification_report(y_test, y_pred_class, output_dict=True)
                                        st.dataframe(pd.DataFrame(report).transpose(), use_container_width=True)

                                    except Exception as e:
                                        st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

            except ValueError as e:
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif page == "ğŸ’» ìƒì¡´ë¶„ì„":
    # Streamlit setup
        st.markdown(
            """
            <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
                <h2 style="color: #000000;">ğŸ’» ìƒì¡´ë¶„ì„</h2>
                <p style="font-size:18px; color: #000000;">
                &nbsp;&nbsp;&nbsp;&nbsp;ì›í•˜ì‹œëŠ” ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì‹  í›„ ììœ ë¡­ê²Œ ë¶„ì„í•˜ì„¸ìš”.
                </p>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.divider()
        st.write(" ")

        # 1. íŒŒì¼ ì—…ë¡œë“œ
        st.markdown("<h4 style='color:grey;'>ë°ì´í„° ì—…ë¡œë“œ</h4>", unsafe_allow_html=True)
        st.warning("ìƒì¡´ë¶„ì„ì€ ìƒì¡´ ì‹œê°„ê³¼ ìƒíƒœ(ìƒì¡´/ì‚¬ë§ ë“±)ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.", icon="ğŸš¨")
        uploaded_file = st.file_uploader("ìƒì¡´ë¶„ì„ì— ì´ìš©í•˜ì‹¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

        if uploaded_file is not None:
            try:
                # íŒŒì¼ í¬ê¸°ê°€ í° ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜¤ë¥˜ ì²˜ë¦¬
                if uploaded_file.size > 200 * 1024 * 1024:  # 200MB ì œí•œ
                    raise ValueError("íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. í–‰ì˜ ê°œìˆ˜ í˜¹ì€ ì—´ì˜ ê°œìˆ˜ë¥¼ ì¤„ì¸ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

                if uploaded_file:  # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°ì—ë§Œ ì‹¤í–‰
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° ì½ê¸°
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".xlsx"):
                        df = pd.read_excel(uploaded_file)

                if 'df' in locals():
                    st.divider()
                    st.markdown("<h4 style='color:grey;'>ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°</h4>", unsafe_allow_html=True)

                    # Add a radio button for the user to select the option
                    selected_option = st.radio("ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë°ì´í„°", "ê²°ì¸¡ìˆ˜", "ìš”ì•½í†µê³„"], key="ğŸ’» ìƒì¡´ë¶„ì„")

                    # Show the corresponding output based on the user's selection
                    if selected_option == "ë°ì´í„°":
                        # Display the data
                        st.dataframe(df, use_container_width=True)

                    elif selected_option == "ê²°ì¸¡ìˆ˜":
                        # Calculate counts, missing counts, and percentages
                        counts = df.notna().sum()
                        missing_counts = df.isna().sum()
                        missing_percentages = (df.isna().mean()) * 100

                        # Format counts and missing counts with 1000 separators and percentages
                        counts_formatted = counts.apply(lambda x: f"{x:,}")
                        missing_counts_formatted = missing_counts.apply(lambda x: f"{x:,}")
                        missing_percentages_formatted = missing_percentages.round(2).astype(str) + '%'

                        # Create a DataFrame with the formatted information
                        missing_info = pd.DataFrame({
                            'Columns': df.columns,
                            'Count': counts_formatted,
                            'Missing Count': missing_counts_formatted,
                            'Missing Percentage': missing_percentages_formatted
                        }).reset_index(drop=True)

                        # Display the missing information
                        st.dataframe(missing_info, use_container_width=True)

                    elif selected_option == "ìš”ì•½í†µê³„":
                        # Display summary statistics
                        st.dataframe(df.describe(), use_container_width=True)

                    st.divider()

                    # Section for variable selection
                    st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                    use_duration_column = st.checkbox("ìƒì¡´ 'ê¸°ê°„' ì—´ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆê¹Œ?")
                    st.write(" ")
                    st.write(" ")
                    duration_column = None  # Initialize duration_column as None

                    if use_duration_column:
                        # If the duration column exists
                        st.markdown("<h5>ìƒì¡´ ê¸°ê°„ê³¼ ìƒì¡´ ìƒíƒœ ì„ íƒ</h5>", unsafe_allow_html=True)
                        duration_column = st.selectbox("ìƒì¡´ ê¸°ê°„ì„ ë‚˜íƒ€ë‚´ëŠ” ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", options=["-- ì„ íƒ --"] + list(df.columns), index=0)
                        event_column = st.selectbox("ìƒì¡´ ìƒíƒœ(1=ì´ë²¤íŠ¸ ë°œìƒ, 0=ê²€ì—´)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", options=["-- ì„ íƒ --"] + list(df.columns), index=0)

                        if duration_column != '-- ì„ íƒ --' and event_column != '-- ì„ íƒ --':
                            try:
                                df[duration_column] = pd.to_numeric(df[duration_column], errors='coerce')
                            except Exception as e:
                                st.error(f"'{duration_column}' ì—´ì„ numerical í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

                            if not df[event_column].isin([0, 1]).all():
                                st.error("ìƒì¡´ ìƒíƒœ ì—´(event_column)ì— 0ê³¼ 1 ì´ì™¸ì˜ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

                            missing_duration_count = df[duration_column].isna().sum()
                            missing_event_count = df[event_column].isna().sum()
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                            if missing_duration_count > 0 or missing_event_count > 0:
                                st.markdown(
                                    f"<p style='font-size:16px; color:red;'><strong>{missing_duration_count}ê°œì˜ ê²°ì¸¡ì´ '{duration_column}' ì—´ì—, {missing_event_count}ê°œì˜ ê²°ì¸¡ì´ '{event_column}' ì—´ì— ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.</strong></p>",
                                    unsafe_allow_html=True
                                )
                                if st.checkbox("ê²°ì¸¡ëœ ê´€ì¸¡ì„ ê²€ì—´ë¡œ ê¸°ë¡í•˜ì‹œë ¤ë©´ ì„ íƒí•˜ì„¸ìš”. ë¯¸ì„ íƒ ì‹œ ê²°ì¸¡ í–‰ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤."):
                                    censoring_num = st.number_input("ê²€ì—´ê¹Œì§€ì˜ ê¸°ê°„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”:")
                                    if censoring_num:
                                        df[duration_column] = df[duration_column].fillna(censoring_num)
                                        df[event_column] = df[event_column].fillna(0)  # Mark as censored
                            else:
                                st.markdown("<p style='font-size:16px; color:black;'><strong>ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</strong></p>", unsafe_allow_html=True)

                    else:
                        # If the duration column does not exist
                        st.markdown("<h5>ìƒì¡´(ê²€ì—´)ì¼ì ìƒì¡´ ìƒíƒœ ì„ íƒ</h5>", unsafe_allow_html=True)
                        time_column = st.selectbox("ìƒì¡´(ê²€ì—´)ì¼ìë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", options=["-- ì„ íƒ --"] + list(df.columns), index=0)
                        event_column = st.selectbox("ìƒì¡´ ìƒíƒœ(1=ì´ë²¤íŠ¸ ë°œìƒ, 0=ê²€ì—´)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì—´ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", options=["-- ì„ íƒ --"] + list(df.columns), index=0)

                        if time_column != '-- ì„ íƒ --' and event_column != '-- ì„ íƒ --':
                            try:
                                df[time_column] = pd.to_datetime(df[time_column], format='%Y%m%d', errors='coerce')
                            except Exception as e:
                                st.error(f"'{time_column}' ì—´ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

                            if not df[event_column].isin([0, 1]).all():
                                st.error("ìƒì¡´ ìƒíƒœ ì—´(event_column)ì— 0ê³¼ 1 ì´ì™¸ì˜ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

                            missing_time_count = df[time_column].isna().sum()
                            missing_event_count = df[event_column].isna().sum()
                            st.divider()
                            st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                            if missing_time_count > 0 or missing_event_count > 0:
                                st.markdown(
                                    f"<p style='font-size:16px; color:red;'><strong>{missing_time_count}ê°œì˜ ê²°ì¸¡ì´ '{time_column}' ì—´ì—, {missing_event_count}ê°œì˜ ê²°ì¸¡ì´ '{event_column}' ì—´ì— ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.</strong></p>",
                                    unsafe_allow_html=True
                                )
                                if st.checkbox("ê²°ì¸¡ëœ ê´€ì¸¡ì„ ê²€ì—´ë¡œ ê¸°ë¡í•˜ì‹œë ¤ë©´ ì„ íƒí•˜ì„¸ìš”. ë¯¸ì„ íƒ ì‹œ ê²°ì¸¡ í–‰ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤."):
                                    censoring_date = st.date_input("ê²€ì—´ì¼ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (YYYY-MM-DD):")
                                    if censoring_date:
                                        censoring_date_numeric = pd.to_datetime(censoring_date, format='%Y%m%d')
                                        df[time_column] = df[time_column].fillna(censoring_date_numeric)
                                        df[event_column] = df[event_column].fillna(0)  # Mark as censored
                            else:
                                st.markdown("<p style='font-size:16px; color:black;'><strong>ê²°ì¸¡ ì²˜ë¦¬ ì‘ì—… ì—†ì´ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</strong></p>", unsafe_allow_html=True)

                            # Calculate durations based on the last date
                            last_date = df[time_column].max()
                            duration_column = 'duration'
                            df[duration_column] = (last_date - df[time_column]).dt.days

                            # Ensure variables are properly initialized in the session state
                            if 'analysis_started' not in st.session_state:
                                st.session_state.analysis_started = False
                            if 'km_cat_column' not in st.session_state:
                                st.session_state.km_cat_column = "-- ì„ íƒ --"

                            # UI for starting the analysis
                            if st.button("ë¶„ì„ ì‹œì‘"):
                                st.session_state.analysis_started = True  # Set the flag to indicate that analysis has started

                            # Check if the analysis has been started
                            if st.session_state.analysis_started:
                                st.divider()
                                st.header("ğŸ’» ìƒì¡´ë¶„ì„ ê²°ê³¼", divider='rainbow')
                                st.markdown("<h4 style='color:grey;'>Kaplan-Meier Curve</h4>", unsafe_allow_html=True)

                                # Display the event DataFrame
                                st.markdown("<h6>Event Dataframe</h6>", unsafe_allow_html=True)
                                if 'time_column' in locals() and time_column in df.columns:
                                    # Display the DataFrame with time_column
                                    st.dataframe(df[[event_column, time_column, duration_column]], use_container_width=True)
                                else:
                                    # Display the DataFrame without time_column
                                    st.dataframe(df[[event_column, duration_column]], use_container_width=True)

                                # Kaplan-Meier analysis
                                durations = df[duration_column].dropna()  # Drop missing values if any
                                events = df[event_column].dropna()  # Drop missing values if any
                                kmf = KaplanMeierFitter()
                                kmf.fit(durations, event_observed=events)

                                # Plot Kaplan-Meier curve using Plotly
                                km_curve = go.Figure()
                                km_curve.add_trace(go.Scatter(
                                    x=kmf.timeline,
                                    y=kmf.survival_function_['KM_estimate'],
                                    mode='lines',
                                    name='Kaplan-Meier Curve',
                                    line=dict(color='blue')
                                ))
                                km_curve.update_layout(
                                    title="Kaplan-Meier Curve",
                                    xaxis_title="Duration (days)",
                                    yaxis_title="Survival Probability",
                                    width=800,
                                    height=600
                                )
                                st.plotly_chart(km_curve)

                                # Display the event table
                                st.markdown("<h6>Event Table</h6>", unsafe_allow_html=True)
                                event_table = kmf.event_table
                                st.dataframe(event_table, use_container_width=True)

                                # Divider for categorical analysis
                                st.divider()
                                st.markdown("<h4 style='color:grey;'>Kaplan-Meier Curve with Variables</h4>", unsafe_allow_html=True)

                                # Categorical variable selection
                                km_cat_column = st.selectbox(
                                    "KM Curveë¥¼ ë³¼ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                                    options=["-- ì„ íƒ --"] + [col for col in df.columns if df[col].nunique() < 10],
                                    index=0,
                                    key="km_cat_column"  # Use key to bind to session state
                                )

                                # Display the selected DataFrame and grouped KM curves if a variable is selected
                                if st.session_state.km_cat_column != "-- ì„ íƒ --":
                                    st.markdown("<h6>Event Dataframe</h6>", unsafe_allow_html=True)
                                    try:
                                        if 'time_column' in locals() and time_column in df.columns:
                                            st.dataframe(df[[event_column, time_column, duration_column, st.session_state.km_cat_column]], use_container_width=True)
                                        else:
                                            st.dataframe(df[[event_column, duration_column, st.session_state.km_cat_column]], use_container_width=True)
                                    except KeyError as e:
                                        st.error(f"One of the columns is not found in the DataFrame: {e}")

                                    # Plot Kaplan-Meier curves grouped by the categorical variable
                                    km_curve = go.Figure()
                                    for group in df[st.session_state.km_cat_column].dropna().unique():  # Ensure no NaN groups
                                        # Filter the DataFrame for the current group
                                        group_df = df[df[st.session_state.km_cat_column] == group]

                                        # Extract durations and events, and drop any missing values
                                        group_durations = group_df[duration_column].dropna()
                                        group_events = group_df[event_column].dropna()

                                        # Check that the durations and events are not empty before fitting the model
                                        if not group_durations.empty and not group_events.empty:
                                            # Fit the Kaplan-Meier model for the current group
                                            kmf.fit(group_durations, event_observed=group_events, label=str(group))

                                            # Use the correct label to access the survival function
                                            km_curve.add_trace(go.Scatter(
                                                x=kmf.timeline,
                                                y=kmf.survival_function_[str(group)],  # Use the label as the key
                                                mode='lines',
                                                name=f'{st.session_state.km_cat_column}: {group}'
                                            ))

                                    # Update layout for the grouped Plotly figure
                                    km_curve.update_layout(
                                        title="Kaplan-Meier Curve by Category",
                                        xaxis_title="Duration (days)",
                                        yaxis_title="Survival Probability",
                                        width=800,
                                        height=600
                                    )
                                    st.plotly_chart(km_curve)

                                    for group in df[st.session_state.km_cat_column].dropna().unique():  # Ensure no NaN groups
                                        # Display the event table for the current group
                                        st.markdown(f"<h6>Event Table for Group: {group}</h6>", unsafe_allow_html=True)
                                        event_table = kmf.event_table
                                        st.dataframe(event_table, use_container_width=True)

                                # Style for custom callout boxes
                                st.divider()
                                st.markdown(
                                    """
                                    <style>
                                    .custom-callout {
                                        background-color: #f9f9f9;
                                        padding: 10px;
                                        border-radius: 10px;
                                        border: 1px solid #d3d3d3;
                                        box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
                                    }
                                    .custom-callout p {
                                        margin: 0;
                                        color: #000000;
                                        font-size: 14px;
                                        line-height: 1.4;
                                        text-align: left;
                                    }
                                    </style>
                                    """,
                                    unsafe_allow_html=True
                                )

                                # Function to get categorical columns, including low-cardinality numerical columns
                                def get_categorical_columns(df):
                                    categorical_columns = list(df.select_dtypes(include=['object', 'category']).columns)
                                    low_cardinality_numerical = [col for col in df.select_dtypes(exclude=['object', 'category']).columns if df[col].nunique() < 5]
                                    return categorical_columns + low_cardinality_numerical

                                # UI for variable selection
                                st.markdown("<h4 style='color:grey;'>ë³€ìˆ˜ ì„ íƒ</h4>", unsafe_allow_html=True)
                                st.markdown(
                                    """
                                    <div class="custom-callout">
                                        <p>- ìƒì¡´ ë¶„ì„ì—ì„œëŠ” ìƒì¡´ ê¸°ê°„(duration)ê³¼ ì´ë²¤íŠ¸(event)ë¥¼ ì´ìš©í•´ ë¶„ì„í•©ë‹ˆë‹¤.</p>
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                                st.write(" ")

                                # Select continuous and categorical explanatory variables
                                continuous_columns = st.multiselect(
                                    "- ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                                    df.select_dtypes(include=['float64', 'int64']).columns,
                                    key="continuous_columns_selection"
                                )


                                categorical_columns = st.multiselect(
                                    "- ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜(X)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                                    get_categorical_columns(df),
                                    key="categorical_columns_selection"
                                )

                                # Add a "ì„ íƒ ì™„ë£Œ" button to confirm selections
                                if st.button('ì„ íƒ ì™„ë£Œ', key='complete_button'):
                                    if continuous_columns or categorical_columns:
                                        st.session_state.continuous_columns = continuous_columns
                                        st.session_state.categorical_columns = categorical_columns
                                        st.session_state.proceed_to_preprocessing = True
                                    else:
                                        st.warning("ì„¤ëª…ë³€ìˆ˜ë¥¼ í•œ ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.", icon="âš ï¸")

                                # Check if preprocessing should proceed
                                if st.session_state.proceed_to_preprocessing:
                                    st.divider()
                                    st.markdown("<h4 style='color:grey;'>ê²°ì¸¡ íŒŒì•…</h4>", unsafe_allow_html=True)

                                    # Initialize dictionaries to store strategies
                                    continuous_missing_value_strategies = {}
                                    categorical_missing_value_strategies = {}

                                    # Prepare data for preprocessing
                                    X_continuous = df[st.session_state.continuous_columns].copy()
                                    X_categorical = df[st.session_state.categorical_columns].copy()

                                    # Check and display missing values for the selected variables
                                    for column in st.session_state.continuous_columns:
                                        missing_count = df[column].isna().sum()
                                        st.markdown(f"<p style='color:firebrick;'>âš ï¸ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.</p>", unsafe_allow_html=True)
                                        # Select strategy for handling missing values
                                        if missing_count > 0:
                                            strategy = st.selectbox(
                                                f"- ì„ íƒí•˜ì‹  ì—°ì†í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                                ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                                key=f"{column}_strategy"
                                            )
                                            if strategy != '-- ì„ íƒ --':
                                                continuous_missing_value_strategies[column] = strategy

                                    for column in st.session_state.categorical_columns:
                                        missing_count = df[column].isna().sum()
                                        st.markdown(f"<p style='color:firebrick;'>âš ï¸ '{column}'ì— ê²°ì¸¡ì¹˜ {missing_count}ê°œê°€ ìˆìŠµë‹ˆë‹¤.</p>", unsafe_allow_html=True)
                                        if missing_count > 0:
                                            # Select strategy for handling missing values
                                            strategy = st.selectbox(
                                                f"- ì„ íƒí•˜ì‹  ë²”ì£¼í˜• ì„¤ëª…ë³€ìˆ˜ '{column}'ì˜ ê²°ì¸¡ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:",
                                                ['-- ì„ íƒ --', 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´'],
                                                key=f"{column}_strategy"
                                            )
                                            if strategy != '-- ì„ íƒ --':
                                                categorical_missing_value_strategies[column] = strategy

                                    # Apply missing value strategies for continuous columns
                                    for column, strategy in continuous_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            X_continuous = X_continuous.dropna(subset=[column])
                                        elif strategy in ['í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´', 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´']:
                                            impute_strategy = {
                                                'í•´ë‹¹ ì—´ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´': 'mean',
                                                'í•´ë‹¹ ì—´ì˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´': 'median',
                                                'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´': 'most_frequent'
                                            }[strategy]
                                            imputer = SimpleImputer(strategy=impute_strategy)
                                            X_continuous[[column]] = imputer.fit_transform(X_continuous[[column]])

                                    # Apply missing value strategies for categorical columns
                                    for column, strategy in categorical_missing_value_strategies.items():
                                        if strategy == 'ê²°ì¸¡ì´ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œê±°':
                                            X_categorical = X_categorical.dropna(subset=[column])
                                        elif strategy == 'í•´ë‹¹ ì—´ì˜ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´':
                                            imputer = SimpleImputer(strategy='most_frequent')
                                            X_categorical[[column]] = imputer.fit_transform(X_categorical[[column]])

                                    # Synchronize index changes between X_continuous and X_categorical
                                    shared_indexes = X_continuous.index.intersection(X_categorical.index)
                                    X_continuous = X_continuous.loc[shared_indexes]
                                    X_categorical = X_categorical.loc[shared_indexes]

                                    # Combine continuous and categorical data
                                    X_combined = pd.concat([X_continuous, pd.get_dummies(X_categorical, drop_first=True)], axis=1)

                                    # Proceed to survival analysis
                                    if st.button("ìƒì¡´ ë¶„ì„ ì‹œì‘"):
                                        st.divider()
                                        # Prepare data for Cox model
                                        cph = CoxPHFitter()
                                        df_for_cox = pd.concat([df[[duration_column, event_column]], X_combined], axis=1).dropna()

                                        # Fit the Cox model
                                        cph.fit(df_for_cox, duration_col=duration_column, event_col=event_column)
                                        st.markdown("<h5 style='color:grey;'>Cox ëª¨ë¸ ìš”ì•½:</h5>", unsafe_allow_html=True)
                                        summary_df = cph.summary.reset_index()  # Convert summary to a DataFrame and reset the index
                                        st.dataframe(summary_df, use_container_width=True)

                                        # Extract variable names from the index of the summary DataFrame
                                        variables = summary_df.covariate.tolist()

                                        # Plot Cox model coefficients using Plotly
                                        coef = summary_df['coef']
                                        coef_lower = summary_df['coef lower 95%']
                                        coef_upper = summary_df['coef upper 95%']

                                        # Create a Plotly figure for the coefficients
                                        fig = go.Figure()
                                        fig.add_trace(go.Scatter(
                                            x=coef,
                                            y=variables,
                                            mode='markers',
                                            name='Coefficient',
                                            error_x=dict(
                                                type='data',
                                                symmetric=False,
                                                array=coef_upper - coef,  # Upper error
                                                arrayminus=coef - coef_lower  # Lower error
                                            ),
                                            marker=dict(color='blue')
                                        ))
                                        fig.update_layout(
                                            title="Cox Model Coefficients",
                                            xaxis_title="Coefficient Value",
                                            yaxis_title="Variables",
                                            width=800,
                                            height=600
                                        )
                                        st.plotly_chart(fig)
            except ValueError as e:
                st.error("ì í•©í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ë¥¼ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            except OSError as e:  # íŒŒì¼ ì•”í˜¸í™” ë˜ëŠ” í•´ë… ë¬¸ì œ ì²˜ë¦¬
                st.error("íŒŒì¼ì´ ì•”í˜¸í™”ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤. íŒŒì¼ì˜ ì•”í˜¸ë¥¼ í‘¼ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    # elif page == "â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”":
    #     # Mailgun API Information
    #     API_KEY = '5b177fd33abf249de3f999a97688833a-5dcb5e36-e3549260'
    #     DOMAIN_NAME = 'sandbox9b0aa132fcdb42e2a35c0642808b1f8d.mailgun.org'

    #     # Email sending function via Mailgun
    #     def send_email_via_mailgun(subject, message):
    #         try:
    #             response = requests.post(
    #                 f"https://api.mailgun.net/v3/{DOMAIN_NAME}/messages",
    #                 auth=("api", API_KEY),
    #                 data={
    #                     "from": f"Excited User <mailgun@{DOMAIN_NAME}>",  # Sender address
    #                     "to": ["hui135@snu.ac.kr"],  # Recipient address
    #                     "subject": subject,  # Email subject
    #                     "text": message  # Email body
    #                 }
    #             )
    #             return response
    #         except Exception as e:
    #             st.error(f"An error occurred: {e}")
    #             return None

    #     st.markdown(
    #     """
    #     <div style="background-color: #e9f5ff; padding: 10px; border-radius: 10px;">
    #         <h2 style="color: #000000;">â›” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”</h2>
    #     </div>
    #     """,
    #     unsafe_allow_html=True
    #     )
    #     st.divider()
    #     st.write(" ")

    #     # Get user input
    #     st.markdown("<h4 style='color:grey;'>ì–´ë–¤ ì–´ë ¤ì›€ì´ ìˆìœ¼ì…¨ë‚˜ìš”?</h4>", unsafe_allow_html=True)
    #     user_input = st.text_area("ì—¬ê¸°ì— ê²ªê³ ê³„ì‹  ì–´ë ¤ì›€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ì…ë ¥í•˜ì‹  ë©”ì„¸ì§€ëŠ” ê¹€í¬ì—° ì—°êµ¬ì›ì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤.", key="user_input")

    #     # Send an email when the submit button is clicked
    #     if st.button("ì œì¶œ", key="submit_button_1"):
    #         if user_input.strip() == "":  # Check if the input is empty
    #             st.warning("ì œì¶œ ì „ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    #         else:
    #             response = send_email_via_mailgun("User Feedback", user_input)

    #             # If response is None, an error occurred during the request
    #             if response is None:
    #                 st.error("ì „ì†¡ì— ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤.")
    #             else:
    #                 # Check response status code
    #                 if response.status_code == 200:
    #                     st.success("ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
    #                 else:
    #                     st.error(f"Send failed: {response.text}")
    #                     st.write(f"Status code: {response.status_code}")

else:
    # st.markdown("<h4 style='color:grey;'>ì‹œìŠ¤í…œ ì ‘ê·¼ì„ ìœ„í•´ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.</h4>", unsafe_allow_html=True)
    # st.info('í™˜ì˜í•©ë‹ˆë‹¤!\n   ê°•ë‚¨ì„¼í„° ì—°êµ¬ì ì§€ì› ì´ìš©ì„ ìœ„í•´ì„  ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.', icon="ğŸ’¡")
    st.image(image_url, use_container_width=False)
    st.markdown(title_html, unsafe_allow_html=True)
    st.markdown(contact_info_html, unsafe_allow_html=True)
    st.divider()
    st.info('ê°•ë‚¨ì„¼í„° ì—°êµ¬ì ì§€ì› ì´ìš©ì„ ìœ„í•´ì„  ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.', icon="âœ…")
    # st.markdown(
    # """
    # <div border-radius: 10px;">
    #     <p style="font-size:20px; color: #133f91;">
    #     â˜‘ï¸  ê°•ë‚¨ì„¼í„° ì—°êµ¬ì ì§€ì› ì´ìš©ì„ ìœ„í•´ì„  ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.
    #     </p>
    # </div>
    # """,
    # unsafe_allow_html=True
    # )
